[
  {
    "author": "Gao",
    "content": "# 使用`mermaid.js`来绘制图表\n\n最近需要绘制一些流程图来做说明，大概检索了一下现在可以使用的东西。\n\n看到了`mermaid`这个图表绘制工具。\n这款软件曾经获得过OpenSource Reword 2019\n\n`mermaid`是一款使用标记语言来绘制图表的工具，可以快速的绘制出流程图来，让你的表达跟上你的思想。\n\n这款图表的实现原理是解析标记语言，再根据标记语言，使用d3来绘制图表。\n收到d3的限制，只能在dom中使用。\n\n图表可轻易嵌入markdown之中，如下：\n\n```\nflowchart LR\n  A[Jonathan]\n  B[Develop next app]\n  C[Develop phoenix app]\n  D[Develop mail server]\n  E[Develop notification server]\n  F[Develop cdn server]\n  G[Develop database]\n  Z[GSMLG Application]\n  A-->B\n  A-->C\n  A-->D\n  A-->E\n  A-->F\n  A-->G\n  B-->Z\n  C-->Z\n  D-->Z\n  E-->Z\n  F-->Z\n  G-->Z\n```\n生成的图表\n```mermaid\nflowchart LR\n  A[Jonathan]\n  B[Develop next app]\n  C[Develop phoenix app]\n  D[Develop mail server]\n  E[Develop notification server]\n  F[Develop cdn server]\n  G[Develop database]\n  Z[GSMLG Application]\n  A-->B\n  A-->C\n  A-->D\n  A-->E\n  A-->F\n  A-->G\n  B-->Z\n  C-->Z\n  D-->Z\n  E-->Z\n  F-->Z\n  G-->Z\n```\n\n\n### 支持的图表类型\n\n* Flowchart\n* Sequence diagram\n* Gantt diagram\n* Class diagram\n* State Diagram\n* Git graph\n* Entity Relationship Diagram - ! experimental\n* User Journey Diagram\n* Gantt\n* Requirement Diagram\n\n\n**配置文档**\n\n更详细的配置文档可以在 [这里](https://mermaid-js.github.io/mermaid/#/flowchart) 找到。\n\n\n### Demo\n\n```mermaid\nsequenceDiagram\n    actor A as Client\n    participant B as Front Server\n    participant C as Backen Servers\n    A ->>+ B: Get Page\n    B ->>+ C: Get Data\n    B ->>+ C: Get Resource\n    C -->>- B: Return Data\n    C -->>- B: Return Resource\n    B -->>- A: Rsponse Page\n```\n",
    "date": "2021-12-04",
    "id": 58,
    "slug": "using-mermaid-js",
    "title": "使用mermaid.js来绘制图表"
  },
  {
    "author": "Gao",
    "content": "Chrome浏览器的代码块一只显示异常。\n\n出现的问题是CSS给代码块设置的颜色无效，代码的字体一直是显示为默认的颜色。\n\n尝试修改了颜色主题，用户信息，清空了插件，都没有作用。\n\n在更换了用户档案后，发现恢复正常显示。\n\n应该是用户档案配置的问题。\n\n经过逐一排查，发现定义了等宽字体为\"Source Code Pro\"，在修改CSS字体为不存在字体时，显示正常。\n\n目前确定原因时由于字体设置问题导致的颜色异常。\n\n将chrome默认字体灯管改为一个其他的等宽字体后后，显示一切正常。\n\n这里有个问题，原先字体是`custom`，现在字体不知道如何选择，目前只用了了`Andale Mono`来代替。",
    "date": "2021-12-03",
    "id": 57,
    "slug": "chrome-font-color-issue",
    "title": "Chrome浏览器代码块的颜色显示异常"
  },
  {
    "author": "Gao",
    "content": "最近打算把服务器的内存补充上，看了一下服务器内存，发现内存有两种，一种是1Rx8一种是2Rx4的，为了避免内存不兼容，去看了一下相关的技术文档。\n\n找到了一篇镁光的文章 [What is a Memory Rank?](https://www.crucial.com/support/articles-faq-memory/what-is-a-memory-rank)\n\nThe term rank was created by JEDEC, the memory industry’s standards group, to distinguish between the number of memory banks on a module as opposed to the number of memory banks on a component, or memory chip. The concept of memory rank applies to all memory module form factors, though in general it tends to matter primarily on server platforms, due to the larger amounts of memory they manage.\n\n技术术语 `rank` 是由JEDEC创建，内存工业标准组，用于区分模块上的内存条数量与组件或内存芯片上的内存条数量。\n内存排列的概念适用于所有内存模块因素，尽管通常它往往主要在服务器平台上很重要，因为它们管理的内存量更大。\n\nA memory rank is a block or area of data that is created using some, or all, of the memory chips on a module. A rank is a data block that is 64 bits wide. On systems that support Error Correction Code (ECC) an additional 8 bits are added, which makes the data block 72 bits wide. Depending on how a memory module is engineered, it may have one, two, or four blocks of 64-bit wide data areas (or 72-bit wide in the case of ECC modules.) This is referred to as single-rank, dual-rank, and quad-rank. Crucial denotes this on the module label as 1Rx4, or 2Rx4, 2Rx8, or similar.\n\n内存排列是内存模块上的部分或全部内存芯片创建的数据块或区域。\n排列是 64bit 宽的数据块。在支持自动纠错 (ECC) 的系统上，额外添加了 8bit ，数据块为 72bit 宽。\n根据内存模块的设计方式，它可能有一个、两个或四个 64bit 宽数据区（或 ECC 模块为 72bit 宽）。\n这被称为 single-rank, dual-rank, and quad-rank.。 \nCrucial 在模块标签上将此表示为 1Rx4、或 2Rx4、2Rx8 或类似名称。\n\nThe x4 and x8 refer to the number of banks on the memory component or chip. It is this number, not the number of individual memory chips on a PCB, that determines the rank of the finished module. In other words, if a module has chips on both sides of the PCB, which makes it dual-sided, it can still be single-ranked, dual-ranked, or quad-ranked, depending on how those chips are engineered.\n\nx4 和 x8 是指内存组件或芯片上的存储体数量。正是这个数字，而不是 PCB 上单个内存芯片的数量，决定了成品模块的等级。\n换句话说，如果一个模块在 PCB 的两面都有芯片，这使得它是双面的，它仍然可以是单排、双排或四排，这取决于这些芯片的设计方式。\n\nBecause a rank is 64 or 72 bits, an ECC module made from x4 chips will need eighteen chips for one single rank (18 x 4 = 72). An ECC module made from x8 chips needs only nine of them for a rank (9 x 8 = 72). A module made from eighteen x8 chips would be dual-ranked (18 x 8 = 144, 144/72 = 2). An ECC module that has twice as many x8 chips becomes quad-ranked (36 x 8 = 288, 288/72 = 4). \n\n因为一个等级是 64 或 72 位，一个由 x4 芯片制成的 ECC 模块将需要 18 个芯片来实现一个单一的等级 (18 x 4 = 72)。\n由 x8 芯片制成的 ECC 模块只需要其中的 9 个即可获得一个等级 (9 x 8 = 72)。\n由 18 个 x8 芯片制成的模块将是双列 (18 x 8 = 144, 144/72 = 2)。\n具有两倍 x8 芯片数量的 ECC 模块变为四阶 (36 x 8 = 288, 288/72 = 4)。\n\nHaving a dual- or quad-ranked module is like having two or four DRAM modules combined onto one module. For example, you can instantly go from four single rank 4GB RDIMM modules to a single quad-rank 16GB RDIMM module (assuming the system is compatible with 16GB RDIMMs).\n\n拥有双排或四排模块就像将两个或四个 DRAM 模块组合到一个模块上。\n例如，您可以立即从四个单列 4GB RDIMM 模块转换为单个四列 16GB RDIMM 模块（假设系统与 16GB RDIMM 兼容）。\n\nThe drawback with higher ranked modules is that servers sometimes have a limit on how many ranks they can address. For example, a server with four memory slots may be limited to a total of eight ranks. This means you can install four single-ranked modules or four dual-ranked modules but only two quad-ranked modules, as installing more would exceed the amount of ranks that can be addressed.\n\n较高等级模块的缺点是服务器有时对它们可以处理的等级数有限制。\n例如，具有四个内存插槽的服务器可能限制为总共八个列。\n这意味着您可以安装四个单列模块或四个双列模块，但只能安装两个四列模块，因为安装更多模块会超过可以处理的列数。\n\nOn matters of rank and rank limitations, we recommend that you consult the manufacturer’s documentation for guidelines and directions that apply to your specific system. Additional information on ranking and the systems it typically applies to can be found here.\n\n关于等级和等级限制的问题，我们建议您查阅制造商的文档，了解适用于您的特定系统的指南和说明。可以在此处找到有关排名及其通常适用的系统的其他信息。\n\n\n\n",
    "date": "2021-11-25",
    "id": 56,
    "slug": "memory-rank",
    "title": "什么是内存排列（memory rank）？"
  },
  {
    "author": "Gao",
    "content": "# 使用Caddy，拥抱HTTP3\n\nHTTP3已经正式发布了一段时间，当前主流浏览器都已经支持http3。\n故而打算使用http3来改善当前的网络服务。\n\n查看了当前可以使用的http3的web服务器，\n当前`nginx`只有发布了测试版本，还没有正式启用，\n目前看可使用的有`traefik`和`caddy`这两个软件。\n\n经过对比选择了使用`caddy`来做web服务器。\n\n## 编译`caddy`\n\n使用caddy，caddy是使用go编写的http服务器。\n需要使用caddy的一些扩展功能的话，需要自己编译caddy，需要使用xcaddy工具来创建版本。\n\n这里我使用了docker中的xcaddy来进行创建，由于使用了golang，可以很方便的交叉编译，创建其它系统平台架构的caddy服务。\n\nxcaddy编译代码：\n\n```bash\nxcaddy build {version} \\\n    --with github.com/caddy-dns/cloudflare \\\n    --with github.com/caddy-dns/route53 \\\n    --with github.com/caddy-dns/vultr \\\n    --with github.com/mholt/caddy-webdav\n```\n\ncaddy使用go开发，可以自己开发caddy的插件来完成需要的功能。\n可以参考官方的文档 [Extending Caddy](https://caddyserver.com/docs/extending-caddy) 进行开发。\n\n这里我使用了`cloudflare`和`route53`的dns服务来进行域名解析，所以添加了这两个模块。\n\n## 使用`caddy`\n\ncaddy使用非常简单，并且可以使用api进行配置，不需要重启。\n\n启动`caddy`\n\n```bash\ncaddy start\n```\n\ncaddy 启动回自动加载当前目录下的 Caddyfile，启动服务。\n\n**常用命令**\n\n- `caddy fmt` Formats a Caddyfile\n\n- `caddy help` View help for caddy commands\n\n- `caddy list-modules` Lists the installed Caddy modules\n\n- `caddy reload` Changes the config of the running Caddy process\n\n- `caddy run` Starts the Caddy process in the foreground\n\n- `caddy start` Starts the Caddy process in the background\n\n- `caddy stop` Stops the running Caddy process\n\n- `caddy trust` Installs a certificate into local trust store(s)\n\n- `caddy untrust` Untrusts a certificate from local trust store(s)\n\n- `caddy validate` Tests whether a config file is valid\n\n- `caddy version` Prints the version\n\n\n配置文件`Caddyfile`\n\n```conf\n{\n    # General Options\n    # debug\n    http_port  80\n    https_port 443\n\n    # TLS Options\n    auto_https disable_redirects\n    email gsmlg.com@gmail.com\n\n    skip_install_trust\n\n    # acme_ca https://acme-staging-v02.api.letsencrypt.org/directory\n    # acme_ca https://acme-v02.api.letsencrypt.org/directory\n    # acme_dns cloudflare {.env.CF_API_TOKEN}\n\n    # Server Options\n    servers {\n        protocol {\n            allow_h2c\n            experimental_http3\n            # strict_sni_host\n        }\n    }\n}\n\n(cloudflare) {\n    tls {\n        ca https://acme-v02.api.letsencrypt.org/directory\n        dns cloudflare {.env.CF_API_TOKEN}\n        resolvers 8.8.8.8 1.1.1.1\n    }\n}\n\n(route53) {\n\ttls {\n        ca https://acme-v02.api.letsencrypt.org/directory\n\t\tdns route53 {\n            max_retries 3\n        }\n\t\tresolvers 8.8.8.8 1.1.1.1\n\t}\n}\n\n*.my-domain.net {\n    import route53\n    @site host some.my-domain.net\n    handle @site {\n        reverse_proxy localhost:8080\n    }\n}\n\n\n*.my-domain.com {\n    import cloudflare\n    @site host some.my-domain.com\n    handle @site {\n        reverse_proxy localhost:8080\n    }\n}\n```\n\n### 使用中遇到的问题\n\n1. `strict_sni_host` 启用后，会导致http3服务无法访问\n\n2. aws配置route53配置\n\n```\n# 环境变量\n\nAWS_ACCESS_KEY_ID='<access key>'\nAWS_SECRET_ACCESS_KEY='<secret key>'\nAWS_HOSTED_ZONE_ID='<zone id>'\nAWS_REGION='<region>'\n\n# or 配置文件放在用户目录下\n\n～/.aws\n\n```\n\n3. cloudflare 配置使用环境变量 `CF_API_TOKEN`\n\n4. 全局配置了`acme_dns`配置，那么所以域名都会默认使用这个方式。\n\n\n\n\n\n\n",
    "date": "2021-11-16",
    "id": 55,
    "slug": "using-caddy-and-hug-http3",
    "title": "使用Caddy，拥抱HTTP3"
  },
  {
    "author": "Gao",
    "content": "# 使用Mix.release代替distillery\n\nElixir在1.9中推出了mix.release功能，来发布OTP版本\n\n由于是语言本身提供的功能，在phoenix中提供了runtime config配置来处理对应参数，相对于distillery开发方便了很多。\n\n简单实用方法：\n\n初始化release\n```bash\nmix release.init\n```\n\n会生成并创建\n```\nrel/\n  env.bat.eex\n  env.sh.eex\n  remote.vm.args.eex\n  vm.args.eex\n```\n\n在`mix.exs`中添加\n```elixir\ndef project do\n    [\n      # ...\n      releases: [\n        gsmlg_umbrella: [\n          applications: [\n            gsmlg: :permanent,\n            gsmlg_web: :permanent\n          ]\n        ],\n        gsmlg_web_only: [\n          applications: [gsmlg_web: :permanent]\n        ],\n        gsmlg_only: [\n          applications: [gsmlg: :permanent]\n        ]\n      ]\n      # ...\n    ]\n  end\n```\n\n发布版本\n```bash\nMIX_ENV=prod mix release <<release name>>\n```\n\n### 相对与`distillery`的不同\n\n相对于`distillery`配置来说大大的简化了对应的配置\n\n缺点是： **不再支持erlang VM最强大的特性，热更新**\n",
    "date": "2021-10-14",
    "id": 54,
    "slug": "mix-release",
    "title": "使用Mix.release代替distillery"
  },
  {
    "author": "Gao",
    "content": "# 矩阵变换计算\n\nWeb 3d中常常用到矩阵变换，这里记录一下矩阵变换的计算方式\n\n三维变换矩阵，这种矩阵由一个4x4方阵，共16个值组成。\n在JavaScript中，可以很方便的用数组表示矩阵。比如典型的单位矩阵。\n单位阵乘上一个点或者矩阵， 其结果保持不变。\n\n**单位矩阵**\n```javascript\nconst identityMatrix = [\n  1, 0, 0, 0,\n  0, 1, 0, 0,\n  0, 0, 1, 0,\n  0, 0, 0, 1\n];\n```\n\n三维空间中的点和一个4x4矩阵并不匹配，加上了额外的第四维W。一般来说，把W设为1就可以了。\nW维度还有一些额外的用途（[WebGL model view projection - Web APIs | MDN](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection)）。\n\n矩阵与点的对齐\n```javascript\n[1, 0, 0, 0,\n 0, 1, 0, 0,\n 0, 0, 1, 0,\n 0, 0, 0, 1]\n\n[4, 3, 2, 1]\n```\n\n\n### 定义相乘函数\n\n**矩阵与点相乘**\n```javascript\nfunction multiplyMatrixAndPoint(matrix, point) {\n\n  // 给矩阵的每一部分一个简单的变量名, 列数（c）与行数（r）\n  var c0r0 = matrix[ 0], c1r0 = matrix[ 1], c2r0 = matrix[ 2], c3r0 = matrix[ 3];\n  var c0r1 = matrix[ 4], c1r1 = matrix[ 5], c2r1 = matrix[ 6], c3r1 = matrix[ 7];\n  var c0r2 = matrix[ 8], c1r2 = matrix[ 9], c2r2 = matrix[10], c3r2 = matrix[11];\n  var c0r3 = matrix[12], c1r3 = matrix[13], c2r3 = matrix[14], c3r3 = matrix[15];\n\n  // 定义点坐标\n  var x = point[0];\n  var y = point[1];\n  var z = point[2];\n  var w = point[3];\n\n  // 点坐标和第一列对应相乘, 再求和\n  var resultX = (x * c0r0) + (y * c0r1) + (z * c0r2) + (w * c0r3);\n\n  // 点坐标和第二列对应相乘, 再求和\n  var resultY = (x * c1r0) + (y * c1r1) + (z * c1r2) + (w * c1r3);\n\n  // 点坐标和第三列对应相乘, 再求和\n  var resultZ = (x * c2r0) + (y * c2r1) + (z * c2r2) + (w * c2r3);\n\n  // 点坐标和第四列对应相乘, 再求和\n  var resultW = (x * c3r0) + (y * c3r1) + (z * c3r2) + (w * c3r3);\n\n  return [resultX, resultY, resultZ, resultW]\n}\n\n```\n\n可以使用这个函数将任意点乘以单位矩阵，还会返回这个点\n\n```javascript\n// identityResult等于[4,3,2,1]\nconst identityResult = multiplyMatrixAndPoint(identityMatrix, [4,3,2,1]);\n```\n\n**两个矩阵相乘**\n\n```javascript\nfunction multiplyMatrices(matrixA, matrixB) {\n\n  // 将第二个矩阵按列切片\n  var column0 = [matrixB[0], matrixB[4], matrixB[8], matrixB[12]];\n  var column1 = [matrixB[1], matrixB[5], matrixB[9], matrixB[13]];\n  var column2 = [matrixB[2], matrixB[6], matrixB[10], matrixB[14]];\n  var column3 = [matrixB[3], matrixB[7], matrixB[11], matrixB[15]];\n\n  // 将每列分别和矩阵相乘\n  var result0 = multiplyMatrixAndPoint( matrixA, column0 );\n  var result1 = multiplyMatrixAndPoint( matrixA, column1 );\n  var result2 = multiplyMatrixAndPoint( matrixA, column2 );\n  var result3 = multiplyMatrixAndPoint( matrixA, column3 );\n\n  // 把结果重新组合成矩阵\n  return [\n    result0[0], result1[0], result2[0], result3[0],\n    result0[1], result1[1], result2[1], result3[1],\n    result0[2], result1[2], result2[2], result3[2],\n    result0[3], result1[3], result2[3], result3[3]\n  ]\n}\n```\n\n实际计算\n```javascript\nconst someMatrix = [\n  4, 0, 0, 0,\n  0, 3, 0, 0,\n  0, 0, 5, 0,\n  4, 8, 4, 1\n]\n\nconst identityMatrix = [\n  1, 0, 0, 0,\n  0, 1, 0, 0,\n  0, 0, 1, 0,\n  0, 0, 0, 1\n];\n\n// 返回someMatrix的数组表示\nconst someMatrixResult = multiplyMatrices(identityMatrix, someMatrix);\n```\n\n> 这些函数是为了介绍计算方式而创建的，计算过程创建了大量的数组，性能很差，真实场景计算需要使用TypedArray来做计算。可以使用矩阵计算库 [GitHub - toji/gl-matrix: Javascript Matrix and Vector library for High Performance WebGL apps](https://github.com/toji/gl-matrix)\n\n\n### 平移矩阵\n\n平移矩阵基于单位矩阵。它将一个对象沿x，y，z其中一个方向进行移动。最简单的想象平移的方式是设想拿起一个咖啡杯。咖啡杯必须保持直立和朝向以免咖啡洒出来。它可以离开桌子在空间中移动。\n\n现在我们还喝不到这个杯子里的咖啡，因为在平移矩阵的单独作用下杯子并不能倾斜。在之后的部分，我们会讨论新的矩阵，来解决这个问题。\n\n```javascript\nconst x = 50;\nconst y = 100;\nconst z = 0;\n\nconst translationMatrix = [\n    1,    0,    0,   0,\n    0,    1,    0,   0,\n    0,    0,    1,   0,\n    x,    y,    z,   1\n];\n```\n\n### 缩放矩阵\n\n缩放矩阵使对象的高度、宽度和深度三个维度的其中之一变大或变小。在典型（笛卡尔）坐标系中， 这将使得x，y，z坐标拉伸或收缩。\n\n```javascript\nvar w = 1.5; // width  (x)\nvar h = 0.7; // height (y)\nvar d = 1;   // depth  (z)\n\nvar scaleMatrix = [\n    w,    0,    0,   0,\n    0,    h,    0,   0,\n    0,    0,    d,   0,\n    0,    0,    0,   1\n];\n```\n\n### 旋转矩阵\n\n```javascript\nconst { sin, cos } = Math;\n\nfunction rotateAroundXAxis(a) {\n\n  return [\n       1,       0,        0,     0,\n       0,  cos(a),  -sin(a),     0,\n       0,  sin(a),   cos(a),     0,\n       0,       0,        0,     1\n  ];\n}\n\nfunction rotateAroundYAxis(a) {\n\n  return [\n     cos(a),   0, sin(a),   0,\n          0,   1,      0,   0,\n    -sin(a),   0, cos(a),   0,\n          0,   0,      0,   1\n  ];\n}\n\nfunction rotateAroundZAxis(a) {\n\n  return [\n    cos(a), -sin(a),    0,    0,\n    sin(a),  cos(a),    0,    0,\n         0,       0,    1,    0,\n         0,       0,    0,    1\n  ];\n}\n```\n\n### 矩阵组合\n\n矩阵的真正厉害之处在于矩阵的组合。当一组特定类型的矩阵连乘起来，它们保留了变换的经过并且是可逆的。这意味着如果平移、旋转和缩放矩阵组合在一起，当我们使用逆变换并颠倒应用的顺序，可以得到原来的点。\n\n矩阵相乘的结果与顺序有关。两个数相乘时，a * b = c, 和 b * a = c 都是正确的。例如，3 * 4 = 12, 和 4 * 3 = 12。在数学上这些数被称为**可交换**。矩阵不能保证交换顺序后的运算结果，所以矩阵是**不可交换**的。\n\n另一个需要记住的点是在WebGL和CSS3中的矩阵相乘需要和变换发生的顺序相反。例如，缩放对象到80%，向下移动200像素，然后绕原点旋转90度在伪代码中应该像下面这样。\n\n```javascript\ntransformation = rotate * translate * scale\n```\n\n",
    "date": "2021-10-09",
    "id": 53,
    "slug": "matrix-math",
    "title": "Web中的矩阵变换计算"
  },
  {
    "author": "Gao",
    "content": "### 简介\n\nOpenSSL 是一款自由开源的加密库, 提供了一些命令行工具来处理数字证书. 其中的一些工\n具可以作为证书权威机构来使用.\n\n证书权威(CA)是一个认证证书实体的证书机构. 许多 Web 站点需要让他们的客户清楚他们\n的连接是安全的, 他们通过向一些国际性的可信 CA(eg. VeriSign, DigiCert)为他们的站\n点去购买一个证书.\n\n在一些时候, 相比于去购买一个证书,更需要去实现一自己的 CA. 通常是需要内部网络使用\n的安全连接, 或者是需要向客户发布一个证书来让他们通过服务器的认证(eg, Apache,\nOpenVPN)\n\n### 创建 root pair\n\n成为一个 CA 意味着需要处理加密密钥对, 私钥和证书. 首先需要第一步创建的是 root\npair. 它包含 root key(ca.key.pem)和 root certificate(ca.cert.pem). 这对迷药就是\nCA 的身份认证.\n\n通常, root CA 不会给任何服务器或客户端签名. root CA 只被用来创建更多的二级 CA,\n二级 CA 被 root CA 签名, 作为 root CA 的代表. 这是最佳实践, 可以让 root key 保持\n离线和尽量少的被使用, 以保证 root key 有最小的泄漏风险.\n\n```\n⚠️注意\n最佳实践是在一个安全的环境里创建root pair. 理想情况下, 在一个完全保密的环境, 并且和互联网完全隔离, 并拔除无线和有线网卡.\n```\n\n#### 准备目录\n\n选择目录来保存所有的 keys 和 certificates\n\n```\n# mkdir /root/ca\n```\n\n创建目录结构. 其中 `index.txt` 和 `serial` 文件是用来保存已经签名证书的记录的文\n件数据库.\n\n```\n# cd /root/ca\n# mkdir certs crl newcerts private\n# chmod 700 private\n# touch index.txt\n# echo 1000 > serial\n```\n\n#### 准备配置文件\n\n我们需要创建一个 OpenSSL 配置文件来使用. 复制 root CA 的配置文件到\n`/root/ca/openssl.cnf`.\n\nroot CA 配置文件\n\n```\n# OpenSSL root CA configuration file.\n# Copy to `/root/ca/openssl.cnf`.\n\n[ ca ]\n# `man ca`\ndefault_ca = CA_default\n\n[ CA_default ]\n# Directory and file locations.\ndir               = /root/ca\ncerts             = $dir/certs\ncrl_dir           = $dir/crl\nnew_certs_dir     = $dir/newcerts\ndatabase          = $dir/index.txt\nserial            = $dir/serial\nRANDFILE          = $dir/private/.rand\n\n# The root key and root certificate.\nprivate_key       = $dir/private/ca.key.pem\ncertificate       = $dir/certs/ca.cert.pem\n\n# For certificate revocation lists.\ncrlnumber         = $dir/crlnumber\ncrl               = $dir/crl/ca.crl.pem\ncrl_extensions    = crl_ext\ndefault_crl_days  = 30\n\n# SHA-1 is deprecated, so use SHA-2 instead.\ndefault_md        = sha256\n\nname_opt          = ca_default\ncert_opt          = ca_default\ndefault_days      = 375\npreserve          = no\npolicy            = policy_strict\n\n[ policy_strict ]\n# The root CA should only sign intermediate certificates that match.\n# See the POLICY FORMAT section of `man ca`.\ncountryName             = match\nstateOrProvinceName     = match\norganizationName        = match\norganizationalUnitName  = optional\ncommonName              = supplied\nemailAddress            = optional\n\n[ policy_loose ]\n# Allow the intermediate CA to sign a more diverse range of certificates.\n# See the POLICY FORMAT section of the `ca` man page.\ncountryName             = optional\nstateOrProvinceName     = optional\nlocalityName            = optional\norganizationName        = optional\norganizationalUnitName  = optional\ncommonName              = supplied\nemailAddress            = optional\n\n[ req ]\n# Options for the `req` tool (`man req`).\ndefault_bits        = 2048\ndistinguished_name  = req_distinguished_name\nstring_mask         = utf8only\n\n# SHA-1 is deprecated, so use SHA-2 instead.\ndefault_md          = sha256\n\n# Extension to add when the -x509 option is used.\nx509_extensions     = v3_ca\n\n[ req_distinguished_name ]\n# See <https://en.wikipedia.org/wiki/Certificate_signing_request>.\ncountryName                     = Country Name (2 letter code)\nstateOrProvinceName             = State or Province Name\nlocalityName                    = Locality Name\n0.organizationName              = Organization Name\norganizationalUnitName          = Organizational Unit Name\ncommonName                      = Common Name\nemailAddress                    = Email Address\n\n# Optionally, specify some defaults.\ncountryName_default             = GB\nstateOrProvinceName_default     = England\nlocalityName_default            =\n0.organizationName_default      = Alice Ltd\norganizationalUnitName_default  =\nemailAddress_default            =\n\n[ v3_ca ]\n# Extensions for a typical CA (`man x509v3_config`).\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer\nbasicConstraints = critical, CA:true\nkeyUsage = critical, digitalSignature, cRLSign, keyCertSign\n\n[ v3_intermediate_ca ]\n# Extensions for a typical intermediate CA (`man x509v3_config`).\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer\nbasicConstraints = critical, CA:true, pathlen:0\nkeyUsage = critical, digitalSignature, cRLSign, keyCertSign\n\n[ usr_cert ]\n# Extensions for client certificates (`man x509v3_config`).\nbasicConstraints = CA:FALSE\nnsCertType = client, email\nnsComment = \"OpenSSL Generated Client Certificate\"\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer\nkeyUsage = critical, nonRepudiation, digitalSignature, keyEncipherment\nextendedKeyUsage = clientAuth, emailProtection\n\n[ server_cert ]\n# Extensions for server certificates (`man x509v3_config`).\nbasicConstraints = CA:FALSE\nnsCertType = server\nnsComment = \"OpenSSL Generated Server Certificate\"\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer:always\nkeyUsage = critical, digitalSignature, keyEncipherment\nextendedKeyUsage = serverAuth\n\n[ crl_ext ]\n# Extension for CRLs (`man x509v3_config`).\nauthorityKeyIdentifier=keyid:always\n\n[ ocsp ]\n# Extension for OCSP signing certificates (`man ocsp`).\nbasicConstraints = CA:FALSE\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer\nkeyUsage = critical, digitalSignature\nextendedKeyUsage = critical, OCSPSigning\n```\n\n其中 `[ca]` 部分是必须的. 这里我们告诉 OpenSSL 使用选项 `[CA_default]` 部分\n\n```\n[ ca ]\n# `man ca`\ndefault_ca = CA_default\n```\n\n而 `[CA_default]` 部分包含一类设置配置. 确保之前配置的目录 `/root/ca` 有效\n\n```\n[ CA_default ]\n# Directory and file locations.\ndir               = /root/ca\ncerts             = $dir/certs\ncrl_dir           = $dir/crl\nnew_certs_dir     = $dir/newcerts\ndatabase          = $dir/index.txt\nserial            = $dir/serial\nRANDFILE          = $dir/private/.rand\n\n# The root key and root certificate.\nprivate_key       = $dir/private/ca.key.pem\ncertificate       = $dir/certs/ca.cert.pem\n\n# For certificate revocation lists.\ncrlnumber         = $dir/crlnumber\ncrl               = $dir/crl/ca.crl.pem\ncrl_extensions    = crl_ext\ndefault_crl_days  = 30\n\n# SHA-1 is deprecated, so use SHA-2 instead.\ndefault_md        = sha256\n\nname_opt          = ca_default\ncert_opt          = ca_default\ndefault_days      = 375\npreserve          = no\npolicy            = policy_strict\n```\n\n我们应用 `policy_strict` 到所有的 root CA 签名, 使 root CA 仅被用来创建二级 CA.\n\n```\n[ policy_strict ]\n# The root CA should only sign intermediate certificates that match.\n# See the POLICY FORMAT section of `man ca`.\ncountryName             = match\nstateOrProvinceName     = match\norganizationName        = match\norganizationalUnitName  = optional\ncommonName              = supplied\nemailAddress            = optional\n```\n\n我们应用 `policy_loose` 到所有二级 CA 签名, 二级 CA 会给所有的 Server 和 Client\n签名, 它们会有很多的种类变化.\n\n```\n[ policy_loose ]\n# Allow the intermediate CA to sign a more diverse range of certificates.\n# See the POLICY FORMAT section of the `ca` man page.\ncountryName             = optional\nstateOrProvinceName     = optional\nlocalityName            = optional\norganizationName        = optional\norganizationalUnitName  = optional\ncommonName              = supplied\nemailAddress            = optional\n```\n\n`[req]` 部分会被使用到所有的证书请求和证书创建\n\n```\n[ req ]\n# Options for the `req` tool (`man req`).\ndefault_bits        = 2048\ndistinguished_name  = req_distinguished_name\nstring_mask         = utf8only\n\n# SHA-1 is deprecated, so use SHA-2 instead.\ndefault_md          = sha256\n\n# Extension to add when the -x509 option is used.\nx509_extensions     = v3_ca\n```\n\n`[req_distinguished_name]` 部分包含了一般证书请求签名信息. 可以手动添加一些默认\n值来配置.\n\n```\n[ req_distinguished_name ]\n# See <https://en.wikipedia.org/wiki/Certificate_signing_request>.\ncountryName                     = Country Name (2 letter code)\nstateOrProvinceName             = State or Province Name\nlocalityName                    = Locality Name\n0.organizationName              = Organization Name\norganizationalUnitName          = Organizational Unit Name\ncommonName                      = Common Name\nemailAddress                    = Email Address\n\n# Optionally, specify some defaults.\ncountryName_default             = GB\nstateOrProvinceName_default     = England\nlocalityName_default            =\n0.organizationName_default      = Alice Ltd\n#organizationalUnitName_default =\n#emailAddress_default           =\n```\n\n之后的几个部分是一些扩展, 这些扩展可以在证书签名的时候使用. 例如: 使用\n`-extensions v3_ca` 命令行参数会应用在 `[v3_ca]` 下的选项.\n\n在创建根证书的时候, 我们使用 `v3_ca`\n\n```\n[ v3_ca ]\n# Extensions for a typical CA (`man x509v3_config`).\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer\nbasicConstraints = critical, CA:true\nkeyUsage = critical, digitalSignature, cRLSign, keyCertSign\n```\n\n在创建二级 CA 时, 使用 `v3_intermediate_ca`, 其中额外增加了 `pathlen:0` 来确保二\n级 CA 下可以再创建 CA\n\n```\n[ v3_intermediate_ca ]\n# Extensions for a typical intermediate CA (`man x509v3_config`).\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer\nbasicConstraints = critical, CA:true, pathlen:0\nkeyUsage = critical, digitalSignature, cRLSign, keyCertSign\n```\n\n在签发客户端证书时, 我们使用 `usr_cert`, 这些被使用做远程用户认证.\n\n```\n[ usr_cert ]\n# Extensions for client certificates (`man x509v3_config`).\nbasicConstraints = CA:FALSE\nnsCertType = client, email\nnsComment = \"OpenSSL Generated Client Certificate\"\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer\nkeyUsage = critical, nonRepudiation, digitalSignature, keyEncipherment\nextendedKeyUsage = clientAuth, emailProtection\n```\n\n在创建服务器证书时, 使用 `server_cert` 选项, 这些被用于 Web 服务器.\n\n```\n[ server_cert ]\n# Extensions for server certificates (`man x509v3_config`).\nbasicConstraints = CA:FALSE\nnsCertType = server\nnsComment = \"OpenSSL Generated Server Certificate\"\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer:always\nkeyUsage = critical, digitalSignature, keyEncipherment\nextendedKeyUsage = serverAuth\n```\n\n在创建证书废除列表时, `crl_ext` 选项会被自动应用\n\n```\n[ crl_ext ]\n# Extension for CRLs (`man x509v3_config`).\nauthorityKeyIdentifier=keyid:always\n```\n\n在签名在线证书状态协议(Online Certificate Status Protocol (OCSP))证书时, 使用选\n项 `ocsp`\n\n```\n[ ocsp ]\n# Extension for OCSP signing certificates (`man ocsp`).\nbasicConstraints = CA:FALSE\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer\nkeyUsage = critical, digitalSignature\nextendedKeyUsage = critical, OCSPSigning\n```\n\n#### 创建 root key\n\n创建 root key( `ca.key.pem` )并保证它的绝对安全. 任何拥有 root key 的人都可以创\n建受信任的证书. 使用 AES 256-bit 来加密 root key, 并创建一个健壮的密码.\n\n```\n⚠️注意\n使用4096位创建所有的根CA和二级CA的keys.\n你仍然可以使用更短的长度来创建服务器和客户端证书.\n```\n\n```\n# cd /root/ca\n# openssl genrsa -aes256 -out private/ca.key.pem 4096\n\nEnter pass phrase for ca.key.pem: secretpassword\nVerifying - Enter pass phrase for ca.key.pem: secretpassword\n\n# chmod 400 private/ca.key.pem\n```\n\n#### 创建根证书(Root certificate)\n\n使用 root key(ca.key.pem)来创建根证书(ca.cert.pem). 给根证书设置一个比较长的有效\n期, 比如 20 年. 一旦根证书失效, 所有被根证书签名的证书都会失效.\n\n```\n⚠️警告\n当使用`req`工具时, 必须使用`-config`选项来指定一个配置文件, 否则OpenSSL会默认使用`/etc/pki/tls/openssl.cnf`\n```\n\n```\n# cd /root/ca\n# openssl req -config openssl.cnf \\\n      -key private/ca.key.pem \\\n      -new -x509 -days 7300 -sha256 -extensions v3_ca \\\n      -out certs/ca.cert.pem\n\nEnter pass phrase for ca.key.pem: secretpassword\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\n-----\nCountry Name (2 letter code) [XX]:GB\nState or Province Name []:England\nLocality Name []:\nOrganization Name []:Alice Ltd\nOrganizational Unit Name []:Alice Ltd Certificate Authority\nCommon Name []:Alice Ltd Root CA\nEmail Address []:\n\n# chmod 444 certs/ca.cert.pem\n```\n\n#### 验证根证书\n\n```\n# openssl x509 -noout -text -in certs/ca.cert.pem\n```\n\n输出会显示\n\n- `Signature Algorithm` 签名算法\n- `Validity` 证书的有效期\n- `Public-Key` 公钥长度\n- `Issuer`, 签发证书的实体\n- `Subject`, 指向证书自己\n\n当 `Issuer` 和 `Subject` 相同时, 说明证书是自签名的. 明确所有根证书都是自签名的.\n\n```\nSignature Algorithm: sha256WithRSAEncryption\n    Issuer: C=GB, ST=England,\n            O=Alice Ltd, OU=Alice Ltd Certificate Authority,\n            CN=Alice Ltd Root CA\n    Validity\n        Not Before: Apr 11 12:22:58 2015 GMT\n        Not After : Apr  6 12:22:58 2035 GMT\n    Subject: C=GB, ST=England,\n             O=Alice Ltd, OU=Alice Ltd Certificate Authority,\n             CN=Alice Ltd Root CA\n    Subject Public Key Info:\n        Public Key Algorithm: rsaEncryption\n            Public-Key: (4096 bit)\n```\n\n输出还会显示 _X509v3 extensions_. 我们创建证书时应用的选项 `v3_ca`, 所以\n`[v3_ca]` 下的配置项会被反映出来.\n\n```\nX509v3 extensions:\n    X509v3 Subject Key Identifier:\n        38:58:29:2F:6B:57:79:4F:39:FD:32:35:60:74:92:60:6E:E8:2A:31\n    X509v3 Authority Key Identifier:\n        keyid:38:58:29:2F:6B:57:79:4F:39:FD:32:35:60:74:92:60:6E:E8:2A:31\n\n    X509v3 Basic Constraints: critical\n        CA:TRUE\n    X509v3 Key Usage: critical\n        Digital Signature, Certificate Sign, CRL Sign\n```\n\n### 创建二级 CA, intermediate pair\n\n二级 CA 作为 Root CA 代表的实体. Root CA 签署中间证书, 来达成一个信任链.\n\n使用二级 CA 的主要目的是为了安全. 这样 root key 可以被保存在一个离线环境, 并尽可\n能少的被使用. 如果二级 CA 的 key 泄漏, root CA 可以废弃二级 CA 证书并创建一个新\n的二级密钥对.\n\n#### 准备目录\n\nRoot CA 文件保存在目录 `/root/ca` 下. 选择一个不同的目录(\n`/root/ca/intermediate` )来保存二级 CA 文件\n\n```\n# mkdir /root/ca/intermediate\n```\n\n创建和 root CA 相同的目录结构来保存文件. 增加了一个新的目录 `csr` 来保存证书签名\n请求\n\n```\n# cd /root/ca/intermediate\n# mkdir certs crl csr newcerts private\n# chmod 700 private\n# touch index.txt\n# echo 1000 > serial\n```\n\n添加一个 `crlnumber` 文件到二级 CA 目录树. 使用 `crlnumber` 来对证书废除列表\n(certificate revocation lists)进行追踪.\n\n```\n# echo 1000 > /root/ca/intermediate/crlnumber\n```\n\n复制二级 CA 配置文件到 `/root/ca/intermediate/openssl.cnf` 文件.\n\n二级 CA 配置文件内容:\n\n```\n# OpenSSL intermediate CA configuration file.\n# Copy to `/root/ca/intermediate/openssl.cnf`.\n\n[ ca ]\n# `man ca`\ndefault_ca = CA_default\n\n[ CA_default ]\n# Directory and file locations.\ndir               = /root/ca/intermediate\ncerts             = $dir/certs\ncrl_dir           = $dir/crl\nnew_certs_dir     = $dir/newcerts\ndatabase          = $dir/index.txt\nserial            = $dir/serial\nRANDFILE          = $dir/private/.rand\n\n# The root key and root certificate.\nprivate_key       = $dir/private/intermediate.key.pem\ncertificate       = $dir/certs/intermediate.cert.pem\n\n# For certificate revocation lists.\ncrlnumber         = $dir/crlnumber\ncrl               = $dir/crl/intermediate.crl.pem\ncrl_extensions    = crl_ext\ndefault_crl_days  = 30\n\n# SHA-1 is deprecated, so use SHA-2 instead.\ndefault_md        = sha256\n\nname_opt          = ca_default\ncert_opt          = ca_default\ndefault_days      = 375\npreserve          = no\npolicy            = policy_loose\n\n[ policy_strict ]\n# The root CA should only sign intermediate certificates that match.\n# See the POLICY FORMAT section of `man ca`.\ncountryName             = match\nstateOrProvinceName     = match\norganizationName        = match\norganizationalUnitName  = optional\ncommonName              = supplied\nemailAddress            = optional\n\n[ policy_loose ]\n# Allow the intermediate CA to sign a more diverse range of certificates.\n# See the POLICY FORMAT section of the `ca` man page.\ncountryName             = optional\nstateOrProvinceName     = optional\nlocalityName            = optional\norganizationName        = optional\norganizationalUnitName  = optional\ncommonName              = supplied\nemailAddress            = optional\n\n[ req ]\n# Options for the `req` tool (`man req`).\ndefault_bits        = 2048\ndistinguished_name  = req_distinguished_name\nstring_mask         = utf8only\n\n# SHA-1 is deprecated, so use SHA-2 instead.\ndefault_md          = sha256\n\n# Extension to add when the -x509 option is used.\nx509_extensions     = v3_ca\n\n[ req_distinguished_name ]\n# See <https://en.wikipedia.org/wiki/Certificate_signing_request>.\ncountryName                     = Country Name (2 letter code)\nstateOrProvinceName             = State or Province Name\nlocalityName                    = Locality Name\n0.organizationName              = Organization Name\norganizationalUnitName          = Organizational Unit Name\ncommonName                      = Common Name\nemailAddress                    = Email Address\n\n# Optionally, specify some defaults.\ncountryName_default             = GB\nstateOrProvinceName_default     = England\nlocalityName_default            =\n0.organizationName_default      = Alice Ltd\norganizationalUnitName_default  =\nemailAddress_default            =\n\n[ v3_ca ]\n# Extensions for a typical CA (`man x509v3_config`).\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer\nbasicConstraints = critical, CA:true\nkeyUsage = critical, digitalSignature, cRLSign, keyCertSign\n\n[ v3_intermediate_ca ]\n# Extensions for a typical intermediate CA (`man x509v3_config`).\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer\nbasicConstraints = critical, CA:true, pathlen:0\nkeyUsage = critical, digitalSignature, cRLSign, keyCertSign\n\n[ usr_cert ]\n# Extensions for client certificates (`man x509v3_config`).\nbasicConstraints = CA:FALSE\nnsCertType = client, email\nnsComment = \"OpenSSL Generated Client Certificate\"\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer\nkeyUsage = critical, nonRepudiation, digitalSignature, keyEncipherment\nextendedKeyUsage = clientAuth, emailProtection\n\n[ server_cert ]\n# Extensions for server certificates (`man x509v3_config`).\nbasicConstraints = CA:FALSE\nnsCertType = server\nnsComment = \"OpenSSL Generated Server Certificate\"\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer:always\nkeyUsage = critical, digitalSignature, keyEncipherment\nextendedKeyUsage = serverAuth\n\n[ crl_ext ]\n# Extension for CRLs (`man x509v3_config`).\nauthorityKeyIdentifier=keyid:always\n\n[ ocsp ]\n# Extension for OCSP signing certificates (`man ocsp`).\nbasicConstraints = CA:FALSE\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid,issuer\nkeyUsage = critical, digitalSignature\nextendedKeyUsage = critical, OCSPSigning\n```\n\n相对于 root CA, 有 5 个选项发生了变化\n\n```\n[ CA_default ]\ndir             = /root/ca/intermediate\nprivate_key     = $dir/private/intermediate.key.pem\ncertificate     = $dir/certs/intermediate.cert.pem\ncrl             = $dir/crl/intermediate.crl.pem\npolicy          = policy_loose\n```\n\n#### 创建二级 CA 的 Key\n\n创建二级 CA 的 key( `intermediate.key.pem` ) 使用 AES 256-bit 来加密并设置强密码\n.\n\n```\n# cd /root/ca\n# openssl genrsa -aes256 \\\n      -out intermediate/private/intermediate.key.pem 4096\n\nEnter pass phrase for intermediate.key.pem: secretpassword\nVerifying - Enter pass phrase for intermediate.key.pem: secretpassword\n\n# chmod 400 intermediate/private/intermediate.key.pem\n```\n\n### 创建二级 CA 证书\n\n使用二级 CA 的 key 来创建证书签名请求(CSR). 详细信息和 CA 大致相同. 尽管如此,\nCommon Name 选项必须不同.\n\n```\n⚠️警告\n确保你指定的配置文件是`intermediate/openssl.cnf`\n```\n\n```\n# cd /root/ca\n# openssl req -config intermediate/openssl.cnf -new -sha256 \\\n      -key intermediate/private/intermediate.key.pem \\\n      -out intermediate/csr/intermediate.csr.pem\n\nEnter pass phrase for intermediate.key.pem: secretpassword\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\n-----\nCountry Name (2 letter code) [XX]:GB\nState or Province Name []:England\nLocality Name []:\nOrganization Name []:Alice Ltd\nOrganizational Unit Name []:Alice Ltd Certificate Authority\nCommon Name []:Alice Ltd Intermediate CA\nEmail Address []:\n```\n\n创建二级 CA 证书, 使用 root CA 签名 CSR 并使用选项 `v3_intermediate_ca`. 二级证\n书需要设置一个比 root CA 证书更短的有效期. 10 年是一个比较好的选项.\n\n```\n⚠️警告\n这次, 指定root CA配置文件`/root/ca/openssl.cnf`\n```\n\n```\n# cd /root/ca\n# openssl ca -config openssl.cnf -extensions v3_intermediate_ca \\\n      -days 3650 -notext -md sha256 \\\n      -in intermediate/csr/intermediate.csr.pem \\\n      -out intermediate/certs/intermediate.cert.pem\n\nEnter pass phrase for ca.key.pem: secretpassword\nSign the certificate? [y/n]: y\n\n# chmod 444 intermediate/certs/intermediate.cert.pem\n```\n\n`index.txt` 文件是 OpenSSL `ca` 工具用来保存证书的数据库. 不要删除或手动修改这个\n文件. 现在它应该包含了二级 CA 证书的信息\n\n```\nV 250408122707Z 1000 unknown ... /CN=Alice Ltd Intermediate CA\n```\n\n#### 验证二级 CA 证书\n\n和验证根证书一样, 使用相同的方式来验证二级 Ca 证书的有效性.\n\n```\n# openssl x509 -noout -text \\\n      -in intermediate/certs/intermediate.cert.pem\n```\n\n验证二级 CA 证书紧靠着根证书. 返回 `OK` 指示这个信任链是正确的.\n\n```\n# openssl verify -CAfile certs/ca.cert.pem \\\n      intermediate/certs/intermediate.cert.pem\n\nintermediate.cert.pem: OK\n```\n\n#### 创建证书链文件\n\n当应用(比如, web 浏览器)尝试去对二级 CA 签名的证书做验证, 它必须也验证根证书和二\n级 CA 的信任链. 完成信任链, 就需要创建一个证书链来给应用.\n\n创建证书链, 把二级 CA 证书和根证书连接起来, 我们随后会使用这个文件来演正被二级\nCA 证书的签名.\n\n```\n# cat intermediate/certs/intermediate.cert.pem \\\n      certs/ca.cert.pem > intermediate/certs/ca-chain.cert.pem\n# chmod 444 intermediate/certs/ca-chain.cert.pem\n```\n\n```\n⚠️提示\n我们的证书链文件必须包含根证书, 因为当前所有的客户端应用都没雨配置这个根证书. 更好的选项是, 比如你是一个内网的管理者, 可以把根证书安装到所有需要验证的客户端. 用这种方式, 证书链文件只需要包含你的二级CA证书\n```\n\n### 签名 Server 和 Client 证书\n\n我们接下来使用我们的二级 CA 来签名. 你可以在多种情况时使用这些签名证书, 比如创建\n安全的浏览器连接, 或者客户端到 server 的认证.\n\n```\n⚠️注意\n接下来的步骤揭示你作为certificate authority(CA). 第三方, 尽管可以自己创建自己的私钥和证书请求(CSR), 不需要把它们的私钥(private key)显示给你. 他们只想你提供CSR, 然后你签署一个签名的证书给他们. 在这种情况下, 忽略`genrsa`和`req`命令.\n```\n\n#### 创建 key\n\n我们的根 CA 和二级 CA 都是 4096bit 的. Server 和 Client 证书通常在一年内失效, 所\n以我们安全的使用 2048 位密钥对.\n\n```\n⚠️注意\n尽管4096bits略微安全于2048bits, 它会减慢TLS握手并且显著的增加握手时的处理器负载. 基于这个原因, 大多数websites都适用2048bit密钥对\n```\n\n如果你为一个 web 服务器(如: Apache)创建密钥对, 你需要在每次重启服务时都输入密码.\n可以删除掉 `-aes256` 选项来创建一个没有密码的 key.\n\n```\n# cd /root/ca\n# openssl genrsa -aes256 \\\n      -out intermediate/private/www.example.com.key.pem 2048\n# chmod 400 intermediate/private/www.example.com.key.pem\n```\n\n#### 创建证书 certificate\n\n使用私钥(private key)来创建证书请求(CSR). CSR 详情不需要匹配到二级 CA. 对 Server\n证书, 配置的 Common Name 必须是一个 FQDN(full qualified domain name,\n如www.example.com), 然而对 Client 证书它可以是任何唯一的识别码(如, 一个邮件地址\n). 记住 Comman Name 不能和你的根证书或二级 CA 证书相同.\n\n```\n# cd /root/ca\n# openssl req -config intermediate/openssl.cnf \\\n      -key intermediate/private/www.example.com.key.pem \\\n      -new -sha256 -out intermediate/csr/www.example.com.csr.pem\n\nEnter pass phrase for www.example.com.key.pem: secretpassword\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\n-----\nCountry Name (2 letter code) [XX]:US\nState or Province Name []:California\nLocality Name []:Mountain View\nOrganization Name []:Alice Ltd\nOrganizational Unit Name []:Alice Ltd Web Services\nCommon Name []:www.example.com\nEmail Address []:\n```\n\n使用二级 CA 去签名 CSR 来创建一个证书. 如果证书是被用于一个 server, 那么使用\n`server_cert` 扩展. 如果证书时给用户做用户认证, 使用 `user_cert` 扩展. 证书通常\n给予指定一年的有效期, 尽管通常 CA 会额外给于几天时间方便.\n\n```\n# cd /root/ca\n# openssl ca -config intermediate/openssl.cnf \\\n      -extensions server_cert -days 375 -notext -md sha256 \\\n      -in intermediate/csr/www.example.com.csr.pem \\\n      -out intermediate/certs/www.example.com.cert.pem\n# chmod 444 intermediate/certs/www.example.com.cert.pem\n```\n\n`intermediate/index.txt` 文件应该会包含一行内容指向新的证书\n\n```\nV 160420124233Z 1000 unknown ... /CN=www.example.com\n```\n\n#### 验证证书\n\n```\n# openssl x509 -noout -text \\\n      -in intermediate/certs/www.example.com.cert.pem\n```\n\n_Issuer_ 就是二级 CA. _Subject_ 就是证书自己\n\n```\nSignature Algorithm: sha256WithRSAEncryption\n    Issuer: C=GB, ST=England,\n            O=Alice Ltd, OU=Alice Ltd Certificate Authority,\n            CN=Alice Ltd Intermediate CA\n    Validity\n        Not Before: Apr 11 12:42:33 2015 GMT\n        Not After : Apr 20 12:42:33 2016 GMT\n    Subject: C=US, ST=California, L=Mountain View,\n             O=Alice Ltd, OU=Alice Ltd Web Services,\n             CN=www.example.com\n    Subject Public Key Info:\n        Public Key Algorithm: rsaEncryption\n            Public-Key: (2048 bit)\n```\n\n输出会显示 _X509v3 extensions_. 当创建证书, 选择的是 `server_cert` 或者\n`usr_cert`. 这个选项的内容就会在这里被反射出来\n\n```\nX509v3 extensions:\n    X509v3 Basic Constraints:\n        CA:FALSE\n    Netscape Cert Type:\n        SSL Server\n    Netscape Comment:\n        OpenSSL Generated Server Certificate\n    X509v3 Subject Key Identifier:\n        B1:B8:88:48:64:B7:45:52:21:CC:35:37:9E:24:50:EE:AD:58:02:B5\n    X509v3 Authority Key Identifier:\n        keyid:69:E8:EC:54:7F:25:23:60:E5:B6:E7:72:61:F1:D4:B9:21:D4:45:E9\n        DirName:/C=GB/ST=England/O=Alice Ltd/OU=Alice Ltd Certificate Authority/CN=Alice Ltd Root CA\n        serial:10:00\n\n    X509v3 Key Usage: critical\n        Digital Signature, Key Encipherment\n    X509v3 Extended Key Usage:\n        TLS Web Server Authentication\n```\n\n使用之前创建的 CA 证书链文件(ca-chain.cert.pem), 我们可以验证新的证书在被信任链\n上是正确的\n\n```\n# openssl verify -CAfile intermediate/certs/ca-chain.cert.pem \\\n      intermediate/certs/www.example.com.cert.pem\n\nwww.example.com.cert.pem: OK\n```\n\n#### 部署证书\n\n现在可以讲证书部署到 server, 或者发布证书给客户. 当部署到服务器应用(如, Apache)\n时, 你需要确保下边的文件可用:\n\n- `ca-chain.cert.pem`\n- `www.example.com.key.pem`\n- `www.example.com.cert.perm`\n\n如果你是给第三方的证书请求(CSR)做签名, 你不需要获取他们的私钥(private key), 所以\n你需要返回给他们证书链文件( `ca-chain.cert.pem` )和证书文件(\n`www.example.com.cert.pem` )\n\n#### 证书废除列表(Certificate revocation lists)\n\n证书废除列表(Certificate revocation lists(CRL))提供了一个证书的列表, 表明其中的\n证书都是被废除的. 客户端应用, 比如 web 浏览器, 可以使用 CRL 去检查服务器真实性.\n服务器应用, 比如 Apache 和 OpenVPN, 可以使用 CRL 来禁止不被信任的客户端的访问.\n\n发布 CRL 到一个可以公开访问的地方(如: http://example.com/intermediate.crl.pem).\n第三方可以根据地址获取到 CRL, 他们可以根据这个来检测他们依赖的证书是否被废除.\n\n```\n⚠️注意\n一些应用废除了CRLs, 他们使用在线证书状态协议(Online Certificate Status Protocol (OCSP))来代替.\n```\n\n#### 准备配置文件\n\n当一个 CA 签名证书, 他们通常会写入 CRL 地址到证书里. 添加\n`crlDistributionPoints` 到对应的部分. 在这里, 我们添加到 `[server_cert]` 部分中\n\n```\n[ server_cert ]\n# ... snipped ...\ncrlDistributionPoints = URI:http://example.com/intermediate.crl.pem\n```\n\n#### 创建 CRL\n\n```\n# cd /root/ca\n# openssl ca -config intermediate/openssl.cnf \\\n      -gencrl -out intermediate/crl/intermediate.crl.pem\n```\n\n```\n⚠️注意\n在ca man page中的`CRL OPTIONS`部分包含了更多关于如何创建CRLs的信息\n```\n\n可以使用 `crl` 工具来检查 CRL 的内容\n\n```\n# openssl crl -in intermediate/crl/intermediate.crl.pem -noout -text\n```\n\n现在没有被吊销的证书, 所以输出是 `No Revoked Certificates`.\n\n你应该定期的重新创建 CRL. 在默认情况下, CRL 在 30 天后失效. 这个值由\n`[CA_default]` 部分中的 `default_crl_days` 选项控制.\n\n#### 吊销证书\n\n通过一个例子来看看这个过程. Alice 有一个 web 服务器和一个私有的目录存放一些暖心\n的可爱小猫图片. Alice 想授权她的朋友 Bob 来访问这个集合.\n\nBob 创建了一个私钥和证书请求文件 CSR\n\n```\n$ cd /home/bob\n$ openssl genrsa -out bob@example.com.key.pem 2048\n$ openssl req -new -key bob@example.com.key.pem \\\n      -out bob@example.com.csr.pem\n\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\n-----\nCountry Name [XX]:US\nState or Province Name []:California\nLocality Name []:San Francisco\nOrganization Name []:Bob Ltd\nOrganizational Unit Name []:\nCommon Name []:bob@example.com\nEmail Address []:\n```\n\nBob 发送他的 CSR 给 Alice, Alice 给他签名.\n\n```\n# cd /root/ca\n# openssl ca -config intermediate/openssl.cnf \\\n      -extensions usr_cert -notext -md sha256 \\\n      -in intermediate/csr/bob@example.com.csr.pem \\\n      -out intermediate/certs/bob@example.com.cert.pem\n\nSign the certificate? [y/n]: y\n1 out of 1 certificate requests certified, commit? [y/n]: y\n```\n\nAlice 验证证书有效\n\n```\n# openssl verify -CAfile intermediate/certs/ca-chain.cert.pem \\\n      intermediate/certs/bob@example.com.cert.pem\n\nbob@example.com.cert.pem: OK\n```\n\n`index.txt` 文件包含一个新的连接\n\n```\nV 160420124740Z 1001 unknown ... /CN=bob@example.com\n```\n\nAlice 发送证书给 Bob. Bob 安装证书到浏览器, 现在可以访问到 Alice 的小猫图片.\n\n坏事, 随着 Bob 的不端行为而来. Bob 把 Alice 的小猫图片发送到了 Hack News, 说了他\n是这些的拥有者, 并获得了大量的赞. Alice 发现了这事摒弃要立即吊销他的访问权限.\n\n```\n# cd /root/ca\n# openssl ca -config intermediate/openssl.cnf \\\n      -revoke intermediate/certs/bob@example.com.cert.pem\n\nEnter pass phrase for intermediate.key.pem: secretpassword\nRevoking Certificate 1001.\nData Base Updated\n```\n\n`index.txt` 中 Bob 的证书这行开始现在使用字符 `R` 标示, 这表示证书已经被吊销\n(Revoked).\n\n```\nR 160420124740Z 150411125310Z 1001 unknown ... /CN=bob@example.com\n```\n\n在吊销了 Bob 的证书后, Alice 必须重新创建 CRL\n\n#### 服务端使用 CRL\n\n对于客户端证书, 一般时候服务器应用(如, Apache)来进行验证. 服务应用需要可以访问\nCRL.\n\n在 Alice 的例子中, 他可以添加 `SSLCARevocationPath` 直接到她的 Apache 配置文件中\n并复制 CRL 到她的 web 服务器. 下次 Bob 再进行访问时, Apache 会检查他的证书存在于\nCRL 中并禁止访问.\n\n相似的, OpenVPN 也使用 `crl-verify` 指向了被禁用的客户端证书.\n\n#### 客户端使用 CRL\n\n对于服务器证书, 一般是由客户端应用(如,浏览器)来进行验证. 这时, 应用必须可以远程\n访问 CRL.\n\n如果证书被签名的扩展中包含了 `crlDistributionPoints`, 客户端应用能够根据地址读取\n到 CRL 信息.\n\nCRL 地址信息可以在证书的 x509v3 详情中看到.\n\n```\n# openssl x509 -in cute-kitten-pictures.example.com.cert.pem -noout -text\n\n    X509v3 CRL Distribution Points:\n\n        Full Name:\n          URI:http://example.com/intermediate.crl.pem\n```\n\n### 在线证书状态协议 (Online Certificate Status Protocol)\n\n在线证书状态协议 (Online Certificate Status Protocol)(OCSP) 被创建用于替代证书吊\n销列表(CRL). 和 CRLs 相似, OCSP 运行访问查询出证书的吊销状态.\n\n当服务器签名证书时, 他们一般会包含一个 OSCP 服务器地址(如,\nhttp://ocsp.example.com)在证书中. 这个功能和 CRL 的 `crlDistributionPoints` 功能\n作用相似.\n\n示例, 当 web 浏览器接受到一个服务器证书, 它立即想请求证书中的 OSCP 服务器地址.\n在这个地址中, OCSP 响应程序监听请求和响应证书的吊销状态.\n\n```\n⚠️注意\n  虽然推荐尽可能的使用OCSP, 尽管实际上你应该趋向于只需要OCSP来给web站点证书. 一些web浏览器已经废弃或移除了对CRL的支持.\n```\n\n#### 准备配置文件\n\n要使用 OCSP, CA 必须要编码 OCSP 服务器地址到签名的证书中. 使用\n`authorityInfoAccess` 选项到合适的部分, 在这里应该是 `[server_cert]` 部分\n\n```\n[ server_cert ]\n# ... snipped ...\nauthorityInfoAccess = OCSP;URI:http://ocsp.example.com\n```\n\n#### 创建 OCSP 密钥对\n\nOCSP 响应程序必须要一个加密密钥对来签名发送给请求的响应内容. OSCP 密钥对必须由和\n证书签名相同的 CA 签名.\n\n创建私钥并使用 AES-256 加密\n\n```\n# cd /root/ca\n# openssl genrsa -aes256 \\\n      -out intermediate/private/ocsp.example.com.key.pem 4096\n```\n\n创建证书签名请求 CSR. 详细信息默认需要和签名 CA 相同. Common Name, 需要是 FQDN.\n\n```\n# cd /root/ca\n# openssl req -config intermediate/openssl.cnf -new -sha256 \\\n      -key intermediate/private/ocsp.example.com.key.pem \\\n      -out intermediate/csr/ocsp.example.com.csr.pem\n\nEnter pass phrase for intermediate.key.pem: secretpassword\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\n-----\nCountry Name (2 letter code) [XX]:GB\nState or Province Name []:England\nLocality Name []:\nOrganization Name []:Alice Ltd\nOrganizational Unit Name []:Alice Ltd Certificate Authority\nCommon Name []:ocsp.example.com\nEmail Address []:\n```\n\n使用 CA 签署 CSR\n\n```\n# openssl ca -config intermediate/openssl.cnf \\\n      -extensions ocsp -days 375 -notext -md sha256 \\\n      -in intermediate/csr/ocsp.example.com.csr.pem \\\n      -out intermediate/certs/ocsp.example.com.cert.pem\n```\n\n验证证书的 _x509v3 extensions_ 正确性\n\n```\n# openssl x509 -noout -text \\\n      -in intermediate/certs/ocsp.example.com.cert.pem\n\n    X509v3 Key Usage: critical\n        Digital Signature\n    X509v3 Extended Key Usage: critical\n        OCSP Signing\n```\n\n#### 吊销证书\n\nOpenSSL 的 `ocsp` 工具实现了一个 OCSP responder, 但只为了做测试使用. 生产级别的\nOCSP responder 也有, 但是超越了这个指引的范围.\n\n创建一个 server 证书测试.\n\n```\n# cd /root/ca\n# openssl genrsa -out intermediate/private/test.example.com.key.pem 2048\n# openssl req -config intermediate/openssl.cnf \\\n      -key intermediate/private/test.example.com.key.pem \\\n      -new -sha256 -out intermediate/csr/test.example.com.csr.pem\n# openssl ca -config intermediate/openssl.cnf \\\n      -extensions server_cert -days 375 -notext -md sha256 \\\n      -in intermediate/csr/test.example.com.csr.pem \\\n      -out intermediate/certs/test.example.com.cert.pem\n```\n\n在 `localhost` 上运行 OCSP responder . 有别于 CRL 保存吊销状态于各个文件中, OCSP\nresponder 直接读取 `index.txt` . 响应被 OCSP 密钥对签名(使用 `-rkey` 和\n`-rsigner` 选项)\n\n```\n# openssl ocsp -port 127.0.0.1:2560 -text -sha256 \\\n      -index intermediate/index.txt \\\n      -CA intermediate/certs/ca-chain.cert.pem \\\n      -rkey intermediate/private/ocsp.example.com.key.pem \\\n      -rsigner intermediate/certs/ocsp.example.com.cert.pem \\\n      -nrequest 1\n\nEnter pass phrase for ocsp.example.com.key.pem: secretpassword\n```\n\n在另一个终端中, 发送一个请求给 OCSP responder. 指定的 `-cert` 选项指定了请求的证\n书.\n\n```\n# openssl ocsp -CAfile intermediate/certs/ca-chain.cert.pem \\\n      -url http://127.0.0.1:2560 -resp_text \\\n      -issuer intermediate/certs/intermediate.cert.pem \\\n      -cert intermediate/certs/test.example.com.cert.pem\n```\n\n开始的输出显示如下:\n\n- 是否接收到成功的响应 (OCSP Response Status)\n- responder 的身份 (Responder Id)\n- 证书的吊销状态 (Cert Status)\n\n```\nOCSP Response Data:\n    OCSP Response Status: successful (0x0)\n    Response Type: Basic OCSP Response\n    Version: 1 (0x0)\n    Responder Id: ... CN = ocsp.example.com\n    Produced At: Apr 11 12:59:51 2015 GMT\n    Responses:\n    Certificate ID:\n      Hash Algorithm: sha1\n      Issuer Name Hash: E35979B6D0A973EBE8AEDED75D8C27D67D2A0334\n      Issuer Key Hash: 69E8EC547F252360E5B6E77261F1D4B921D445E9\n      Serial Number: 1003\n    Cert Status: good\n    This Update: Apr 11 12:59:51 2015 GMT\n```\n\n吊销证书\n\n```\n# openssl ca -config intermediate/openssl.cnf \\\n      -revoke intermediate/certs/test.example.com.cert.pem\n\nEnter pass phrase for intermediate.key.pem: secretpassword\nRevoking Certificate 1003.\nData Base Updated\n```\n\n之后, 运行 OCSP responder 并在另一个终端中发请求. 这次, 输出会显示\n`Cert Status: revoked` 和 `Revocation Time` .\n\n```\nOCSP Response Data:\n    OCSP Response Status: successful (0x0)\n    Response Type: Basic OCSP Response\n    Version: 1 (0x0)\n    Responder Id: ... CN = ocsp.example.com\n    Produced At: Apr 11 13:03:00 2015 GMT\n    Responses:\n    Certificate ID:\n      Hash Algorithm: sha1\n      Issuer Name Hash: E35979B6D0A973EBE8AEDED75D8C27D67D2A0334\n      Issuer Key Hash: 69E8EC547F252360E5B6E77261F1D4B921D445E9\n      Serial Number: 1003\n    Cert Status: revoked\n    Revocation Time: Apr 11 13:01:09 2015 GMT\n    This Update: Apr 11 13:03:00 2015 GMT\n```\n",
    "date": "2021-08-17",
    "id": 52,
    "slug": "openssl-ca",
    "title": "OpenSSL Certificate Authority"
  },
  {
    "author": "Gao",
    "content": "# Using semantic release\n\n在介绍`semantic release`之前, 首先介绍`semantic versioning`\n\n## Semantic Versioning\n\n语义化版本 [链接](https://semver.org)\n\n### 摘要\n\n版本格式：主版本号.次版本号.修订号，版本号递增规则如下：\n\n1. 主版本号：当你做了不兼容的 API 修改，\n2. 次版本号：当你做了向下兼容的功能性新增，\n3. 修订号：当你做了向下兼容的问题修正。先行版本号及版本编译元数据可以加到“主版本\n   号.次版本号.修订号”的后面，作为延伸。\n\n### 简介\n\n在软件管理的领域里存在着被称作“依赖地狱”的死亡之谷，系统规模越大，加入的包越多，\n你就越有可能在未来的某一天发现自己已深陷绝望之中。在依赖高的系统中发布新版本包可\n能很快会成为噩梦。如果依赖关系过高，可能面临版本控制被锁死的风险（必须对每一个依\n赖包改版才能完成某次升级）。而如果依赖关系过于松散，又将无法避免版本的混乱（假设\n兼容于未来的多个版本已超出了合理数量）。当你专案的进展因为版本依赖被锁死或版本混\n乱变得不够简便和可靠，就意味着你正处于依赖地狱之中。作为这个问题的解决方案之一，\n我提议用一组简单的规则及条件来约束版本号的配置和增长。这些规则是根据（但不局限于\n）已经被各种封闭、开放源码软件所广泛使用的惯例所设计。为了让这套理论运作，你必须\n先有定义好的公共 API 。这可以透过文件定义或代码强制要求来实现。无论如何，这套\nAPI 的清楚明了是十分重要的。一旦你定义了公共 API，你就可以透过修改相应的版本号来\n向大家说明你的修改。考虑使用这样的版本号格式：X.Y.Z （主版本号.次版本号.修订号）\n修复问题但不影响 API 时，递增修订号；API 保持向下兼容的新增及修改时，递增次版本\n号；进行不向下兼容的修改时，递增主版本号。我称这套系统为“语义化的版本控制”，在这\n套约定下，版本号及其更新方式包含了相邻版本间的底层代码和修改内容的信息。\n\n### 为什么要使用语义化的版本控制？\n\n这并不是一个新的或者革命性的想法。实际上，你可能已经在做一些近似的事情了。问题在\n于只是“近似”还不够。如果没有某个正式的规范可循，版本号对于依赖的管理并无实质意义\n。将上述的想法命名并给予清楚的定义，让你对软件使用者传达意向变得容易。一旦这些意\n向变得清楚，弹性（但又不会太弹性）的依赖规范就能达成。举个简单的例子就可以展示语\n义化的版本控制如何让依赖地狱成为过去。假设有个名为“救火车”的函式库，它需要另一个\n名为“梯子”并已经有使用语义化版本控制的包。当救火车创建时，梯子的版本号为 3.1.0。\n因为救火车使用了一些版本 3.1.0 所新增的功能， 你可以放心地指定依赖于梯子的版本号\n大等于 3.1.0 但小于 4.0.0。这样，当梯子版本 3.1.1 和 3.2.0 发布时，你可以将直接\n它们纳入你的包管理系统，因为它们能与原有依赖的软件兼容。作为一位负责任的开发者，\n你理当确保每次包升级的运作与版本号的表述一致。现实世界是复杂的，我们除了提高警觉\n外能做的不多。你所能做的就是让语义化的版本控制为你提供一个健全的方式来发行以及升\n级包，而无需推出新的依赖包，节省你的时间及烦恼。如果你对此认同，希望立即开始使用\n语义化版本控制，你只需声明你的函式库正在使用它并遵循这些规则就可以了。请在你的\nREADME 文件中保留此页连结，让别人也知道这些规则并从中受益。\n\n## Semantic Release\n\nSemantic release, 中文大意是语义发布, 作用是实现完全自动化的版本管理和发布.\n\n`Semantic-release` 会自动完成整个发布流程, 包括: 自动查明下一个版本号, 生成\nrelease note 和 进行包的发布.\n\n这消除了人类情感和版本号之间的直接联系, 严格的遵循`Semantic Versioning` 规范.\n\n![kill-all-humans](semantic-release/kill-all-humans.png)\n\n### 亮点\n\n- 完全自动发布\n- 确保语义版本(Semantic Versioning)规范\n- 新特性和修复可以立即对用户可用\n- 提醒维护者和用户新的发布\n- 在代码库中使用格式化的提交信息变化并生成文档\n- 基于 git merges 可以创建不同的发布频道\n- 和 CI 工作流集成\n- 和手动发布相比避免潜在的说明错误\n- 经由插件支持任何版本能管理和语言\n- 使用`共享配置(shareable configurations)`来方便和复用配置\n\n### How it works?\n\n#### 提交信息格式 (commit message format)\n\n`Semantic Release`使用用户提交信息(commit message) 查出更新变化的类型. 通过\ncommit message 的格式约定, semantic-release 自动查出下一个 semantic version 版本\n号, 生成更新日志并发布版本.\n\nSemantic-release 默认使用 Angular Commit message conventions. 提交信息格式可以通\n过修\n改`@semantic-release/commit-analyzer`和`@semantic-release/release-notes-generator`的`preset`和`config`选\n项来改变.\n\n通过像 commitzen 和 commitlint 之类的工具可以帮助确保验证提交信息符合约定.\n\n提交示例:\n\n```markdown\nfix(pencil): stop graphite breaking when too much pressure applied Patch Release\nfeat(pencil): add 'graphiteWidth' option Minor Feature Release perf(pencil):\nremove graphiteWidth option Major Breaking Release\n\nBREAKING CHANGE: The graphiteWidth option has been removed. The default graphite\nwidth of 10mm is always used for performance reasons.\n```\n\n### 现实中的项目示例\n\n```yaml\nname: nodejs-scripts-validate-and-release\non:\n  push:\n    paths:\n      - 'nodejs/packages/scripts/**'\n      - '.github/workflows/nodejs-scripts-validate-and-release.yml'\n    branches:\n      - '+([0-9])?(.{+([0-9]),x}).x'\n      - 'master'\n      - 'next'\n      - 'next-major'\n      - 'beta'\n      - 'alpha'\n      - '!all-contributors/**'\n  pull_request: {}\njobs:\n  main:\n    # ignore all-contributors PRs\n    if: ${{ !contains(github.head_ref, 'all-contributors') }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest]\n        node: [12, 14, 15]\n    runs-on: ${{ matrix.os }}\n    steps:\n      - name: 🛑 Cancel Previous Runs\n        uses: styfle/cancel-workflow-action@0.6.0\n        with:\n          access_token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: ⬇️ Checkout repo\n        uses: actions/checkout@v2\n\n      - name: ⎔ Setup node\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node }}\n\n      - name: 📥 Download deps\n        uses: bahmutov/npm-install@v1\n        with:\n          useLockFile: false\n          working-directory: 'nodejs/packages/scripts'\n\n      - name: ▶️ Run validate script\n        working-directory: 'nodejs/packages/scripts'\n        run: npm run validate\n\n      - name: ⬆️ Upload coverage report\n        uses: codecov/codecov-action@v1\n        with:\n          directory: 'nodejs/packages/scripts/coverage/'\n\n  release:\n    needs: main\n    runs-on: ubuntu-latest\n    if:\n      ${{ github.repository == 'gsmlg-dev/Foundation' &&\n      contains('refs/heads/master,refs/heads/beta,refs/heads/next,refs/heads/alpha',\n      github.ref) && github.event_name == 'push' }}\n    steps:\n      - name: 🛑 Cancel Previous Runs\n        uses: styfle/cancel-workflow-action@0.6.0\n        with:\n          access_token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: ⬇️ Checkout repo\n        uses: actions/checkout@v2\n\n      - name: ⎔ Setup node\n        uses: actions/setup-node@v1\n        with:\n          node-version: 14\n\n      - name: 📥 Download deps\n        uses: bahmutov/npm-install@v1\n        with:\n          useLockFile: false\n          working-directory: 'nodejs/packages/scripts'\n\n      - name: 🏗 Run build script\n        working-directory: 'nodejs/packages/scripts'\n        run: npm run build\n\n      - name: 🚀 Release\n        uses: gsmlg/semantic-release-action@v2\n        with:\n          working-directory: 'nodejs/packages/scripts'\n          semantic_version: 17\n          branches: |\n            [\n              '+([0-9])?(.{+([0-9]),x}).x',\n              'master',\n              'next',\n              'next-major',\n              {name: 'beta', prerelease: true},\n              {name: 'alpha', prerelease: true}\n            ]\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n```\n",
    "date": "2021-02-25",
    "id": 51,
    "slug": "semantic-release",
    "title": "语义化版本发布"
  },
  {
    "author": "Gao",
    "content": "# 组件驱动的用户界面\n\n- 翻译自 [componentdriven.org](https://componentdriven.org)\n\n使用模块化的组件来进行开发和设计. UI 界面“自上而下”开始构建, 从基本组件开始, 然\n后逐步组合以组装成为一个视图.\n\n## 为什么使用组件?\n\n现代用户界面越来越复杂, 远超过去. 人们期望更加个性化的体验, 并且在设备之间还可以\n保证统一的体验. 这意味前端开发和设计需要嵌入大量的逻辑在 UI 界面中.\n\n随着应用的增长, UI 变得越来越重. 大型的 UI 项目很容容易出问题, debug 非常困难,\n需要花费大量的时间. 需要把他们拆分成模块构建成强壮的弹性的 UI 组件.\n\n自建可以在内部封装交互逻辑, 让这些状态和应用业务逻辑脱离. 这样, 可以分解复杂的视\n图到简单的组件中. 每一个组件有一个定义好的完整的 API, 和一系列的设置好的状态, 这\n样可以让组件被拆解和使用在不同的 UI 之中.\n\n> **历史**: 软件工程师[Tom Coleman](https://twitter.com/tmeasday)\n> 在[2017]([Component-Driven Development](https://blog.hichroma.com/component-driven-development-ce1109d56c8e)\n> 年描述了 UI 开发中引入组件架构的过程. 关于模块化 UI 的概念来自于软件开发的其它\n> 平面, 如: 微服务和容器化. 同样原理的可以在 20 世界初期的工业批量生产中出现.\n\n## 什么是组件\n\n组件是标准化, 可交互的 UI 构建块. 他们表现了 UI 的展示和功能. 向乐高积木一样, 乐\n高可以构建出各种东西, 从城堡到星际飞船, 组件可以被组合并增加新的特性.\n\n## 如何使用组件驱动\n\n![](./component-driven-ui/component-layers.jpg)\n\n- **构建组件**\n\n构建每一个独立的组件并且定义他们自己相关的状态. 从最基本的开始\n\n`Avatar` `Button` `Input` `Tooltip`\n\n- **组件组合**\n\n组合小的组件组合在一起并添加新的功能, 逐步添加组件的复杂度.\n\n`Form` `Header` `List` `Table`\n\n- **汇合成页面**\n\n使用复合的组件组合成为一个复杂的页面. 使用模拟数据和模拟页面来出发一些很难碰到的\n状态和边界.\n\n`Home page` `Setting page` `Profile page`\n\n- **集成页面到项目中**\n\n添加页面到 App 中并连接数据并结合业务逻辑. 这就是 UI 和后端 API 和服务做连接.\n\n`Web app` `Marketing site` `Docs site`\n\n## 好处\n\n- **质量** 在不同的场景中验证 UI 的工作情况, 分离的组件和相关的状态可以很好的进\n  行测试\n- **耐用** 一些小 bug 被限制在组件层面, 这样更好的测试, 并且被限制在一个很低的层\n  面.\n- **速度** 可以从 UI 组件库或设计系统中, 使用已经构成的组件快速的构建页面.\n- **效率** 并行开发与设计, 被分解的组件, 可以在不同的小组之间分享和使用.\n\n## 那些 UI 不是组件驱动的\n\n- **基于页面的** 开发与设计过程处理一组页面为一个 website. 不需要设计页面间通用\n  的组件.\n- **工具生成的页面** 像`Wordpress`和`Drupal`一样工具被设计用来展示文档. 后端框架\n  向`Rails`, `Django` 和 `PHP` 处理 UI 重用作为外部物品, 并且阻止了组件的重用.\n\n## 互相补充与影响\n\n**设计系统**: 设计更加的贴近用户的使用, 包含 UI 的设计模式的文档与资源(Sketch,\nFigma, etc), 设计原则, 管理和组件库.\n\n**JAMStack**: 一种通过预渲染的方式构建好页面并通过 CDN 分发. JAMStack 站点的 UI\n需要通过组件化的 Javascript 框架来构建.\n\n**敏捷开发**: 一种可促进焦段反馈循环和快速迭代的方法. 组件可以通过重用来帮助团队\n快速的构建和发布. 已更好的适应用户需求.\n",
    "date": "2021-02-07",
    "id": 50,
    "slug": "component-driven-ui",
    "title": "组件驱动的用户界面"
  },
  {
    "author": "Gao",
    "content": "### 起因\n\n今天在搭建一个递归服务器, 想要测试一下递归结果, 根据 ECS 来判断相关的递归服务器\n结果\n\n结果在进行递归查询的时候, 发现一个问题, 递归携带了 subnet, 查询后再更换 subnet,\n递归直接读取了缓存, 而不是带着新的 subnet 去递归.\n\n### 排查\n\n为了对比这个问题,使用了不同的域名来进行递归,发现一个问题,两个域名在递归服务器有\n不同的结果. 域名 z.gsmiot.com 在第一次递归后会一直缓存, aws.amazon.com 域名会根\n据子网变换每次都会递归.\n\n我对比里查询的结果, 发现了一个区别:\n\nz.gsmiot.com\n\n```text\n[root@10-9-104-141 unbound]#  dig z.gsmiot.com @127.0.0.1 +subnet=178.24.161.99/16\n\n; <<>> DiG 9.11.4-P2-RedHat-9.11.4-16.P2.el7_8.6 <<>> z.gsmiot.com @127.0.0.1 +subnet=178.24.161.99/16\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 36175\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n; CLIENT-SUBNET: 178.24.0.0/16/0\n;; QUESTION SECTION:\n;z.gsmiot.com.\t\t\tIN\tA\n\n;; ANSWER SECTION:\nz.gsmiot.com.\t\t3600\tIN\tA\t8.8.8.8\n\n;; Query time: 994 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1)\n;; WHEN: Tue Nov 03 11:03:27 CST 2020\n;; MSG SIZE  rcvd: 67\n```\n\naws.amazon.com\n\n```text\n[root@10-9-104-141 unbound]# dig aws.amazon.com @127.0.0.1 +subnet=178.24.161.99/16\n\n; <<>> DiG 9.11.4-P2-RedHat-9.11.4-16.P2.el7_8.6 <<>> aws.amazon.com @127.0.0.1 +subnet=178.24.161.99/16\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 2145\n;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n; CLIENT-SUBNET: 178.24.0.0/16/24\n;; QUESTION SECTION:\n;aws.amazon.com.\t\t\tIN\tA\n\n;; ANSWER SECTION:\naws.amazon.com.\t\t300\tIN\tCNAME\ttp.8e49140c2-frontier.amazon.com.\ntp.8e49140c2-frontier.amazon.com. 300 IN CNAME\tdr49lng3n1n2s.cloudfront.net.\ndr49lng3n1n2s.cloudfront.net. 300 IN\tA\t54.230.150.74\n\n;; Query time: 420 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1)\n;; WHEN: Tue Nov 03 11:03:53 CST 2020\n;; MSG SIZE  rcvd: 147\n```\n\n对比发现了响应的结果有区别, 在`OPT PSEUDOSECTION`这个部分,有一个地方有区别:\n\n```text\nAWS 权威\n; CLIENT-SUBNET: 178.24.0.0/16/24\nZDNS 权威\n; CLIENT-SUBNET: 178.24.0.0/16/0\n```\n\n又测试了 subnet 生效的 aws 域名, 递归会根据发现子网这个地\n址`178.24.0.0/[A]/[B]`中的 A 和 B 两个 prefix 来做判断, 如果携带的 A 范围较大,\n就是用 A, 而 B 范围较大, 就使用 B. 现在猜测这里的 B 可能是由权威返回的.\n\n查询了一下相关文档\n[RFC7871 Client Subnet in DNS Queries](https://tools.ietf.org/html/rfc7871#section-7.2.1)\n\n其中在 7.2.1 节中内容:\n\n```text\n7.2.1.  Authoritative Nameserver\n\n   When a query containing an ECS option is received, an Authoritative\n   Nameserver supporting ECS MAY use the address information specified\n   in the option to generate a tailored response.\n\n   Authoritative Nameservers that have not implemented or enabled\n   support for the ECS option ought to safely ignore it within incoming\n   queries, per [RFC6891], Section 6.1.2.  Such a server MUST NOT\n   include an ECS option within replies to indicate lack of support for\n   it.  Implementers of Intermediate Nameservers should be aware,\n   however, that some nameservers incorrectly echo back unknown EDNS0\n   options.  In this protocol, that should be mostly harmless, as the\n   SCOPE PREFIX-LENGTH should come back as 0, thus marking the response\n   as covering all networks.\n\n   A query with a wrongly formatted option (e.g., an unknown FAMILY)\n   MUST be rejected and a FORMERR response MUST be returned to the\n   sender, as described in [RFC6891], \"Transport Considerations\".\n```\n\n其中一段\n`In this protocol, that should be mostly harmless, as the SCOPE PREFIX-LENGTH should come back as 0, thus marking the response as covering all networks.`\n这里`SCOPE PREFIX-LENGTH`如果为 0 的话, 响应就会应用到所有网络. 目前猜测 ZDNS 的\n权威可能属于这个问题的范围.\n\n查询了一下文档, 找到了 IETF 上有一个相关文档\n[A Look at the ECS Behavior of DNS Resolvers](https://www.ietf.org/proceedings/106/slides/slides-106-maprg-a-look-at-the-ecs-behavior-of-dns-resolvers-kyle-schomp-01)\n\n有如下一段内容:\n\n```text\nECS Purpose\n• Enable CDN server selection by ADNS based on client subnet\n• ECS Option in DNS queries from resolvers to ADNS includes\n• Client IP address prefix\n• Source prefix length\n• ECS Option in DNS responses from ADNS to resolvers includes\n• Scope prefix length\n```\n\n现在可以推断极大概率是因为这个 scop prefix length 的问题了\n\n### 验证\n\n使用 tcpudump 抓包两次递归服务的递归结果\n\n```shell\ntcpdump -i eth0 port 53 -w zcloud.cap\ntcpdump -i eth0 port 53 -w aws.cap\n```\n\n在 wireshark 中打开看到结果\n\n在响应结果的记录中\n\n- 打开 Domain Name System (response)\n- 打开 Addional records\n- 打开<Root>: type OPT\n- 打开<Option: CSUBNET - Client subnet\n\n对比看到 Scope Netmask 有区别, aws 返回为 24, zdns 返回为 0\n\n问题确认, 是由于权威返回结果的问题导致的\n",
    "date": "2020-11-03",
    "id": 49,
    "slug": "about-ecs-prefix",
    "title": "ECS递归与权威的prefix"
  },
  {
    "author": "Gao",
    "content": "### OpenAPI Specification 使用\n\nOpen API Specification 是由社区驱动的一套开放标准定义了一套面向 Rest API 的不和\n编程语言绑定的接口规范\n\n我们可以通过 Open API 定义的规范来生成对应的文档, Mock Server, Test,\nServer/Client 代码模版\n\n方便的快速开发和分享, 可以直接给客户看到对应的文档来解决问题.\n\n### OpenAPI 开发工具\n\n**Swagger Editor**\n\n可以编辑 OpenAPI 文档\n\n### OpenAPI 基本介绍\n\n文档格式为 yaml 的 OpenAPI\n\n```yaml\n# API版本\nopenapi: 3.0.0\n# APP信息\ninfo:\n  # App 版本\n  version: 1.0.0\n  title: gsmlg-web\n  description: GSMLG Web API\n  # A URL to the Terms of Service for the API\n  termsOfService: https://www.gsmiot.com/termOfService\n  # contact info\n  contact:\n    name: Jonathan\n    url: https://www.gsmlg.org\n    email: me@gsmlg.org\n  # License\n  license:\n    name: 'GPL 3.0'\n    url: 'https://www.gnu.org/licenses/GPL-3.0.html'\n# Added by API Auto Mocking Plugin\nservers:\n  - description: SwaggerHub API Auto Mocking\n    url: https://virtserver.swaggerhub.com/gsmlg/gsmlg-web/1.0.0\n  - description: Production API\n    url: https://www.gsmiot.com/apis/gsmlg.com/v1\n  - url: https://{username}.gsmlg.org:{port}/{basePath}\n    description: aboard\n    variables:\n      username:\n        default: Josh\n        description: value for username\n      port:\n        enum:\n          - '443'\n          - '8443'\n        default: '8443'\n      basePath:\n        default: v2\n# 标签, 分类使用\ntags:\n  - name: blog\n    description: blog\n    externalDocs:\n      url: https://blog.gsmlg.org/docs\n      description: Blog Description\n# 服务路径, 揭示API\npaths:\n  '/blogs':\n    get:\n      tags:\n        - blog\n      summary: blogs list\n      operationId: listBlogs\n      responses:\n        200:\n          description: Success\n          content:\n            application/json:\n              schema:\n                type: object\n                properties:\n                  date:\n                    type: array\n                    items:\n                      $ref: '#/components/schemas/Blog'\n\n    post:\n      tags:\n        - blog\n      summary: Create Blog\n      description: create blog\n      operationId: createBlog\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/Blog'\n      responses:\n        201:\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Blog'\n\n  '/blogs/{blogId}':\n    get:\n      tags:\n        - blog\n      summary: Get a Blog content\n      operationId: getBlogById\n      parameters:\n        - name: blogId\n          in: path\n          required: true\n          description: id of blog\n          schema:\n            type: string\n      responses:\n        200:\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Blog'\n    put:\n      tags:\n        - blog\n      summary: Update a Blog\n      operationId: updateBlog\n      parameters:\n        - name: blogId\n          in: path\n          required: true\n          description: id of blog\n          schema:\n            type: string\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/Blog'\n      responses:\n        201:\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Blog'\n# 组建, 共享资源时, 引用定义在这里\ncomponents:\n  schemas:\n    Blog:\n      type: object\n      properties:\n        id:\n          type: string\n        name:\n          type: string\n        title:\n          type: string\n        date:\n          type: string\n        author:\n          type: string\n        content:\n          type: string\n  securitySchemes:\n    auth:\n      type: http\n      description: auth api key\n      scheme: bearer\n      bearerFormat: JWT\nsecurity:\n  - auth:\n      - write:blog\nexternalDocs:\n  url: https://docs.gsmlg.org\n  description: API Documents\n```\n\n### 其它工具资源\n\n- [AWESOME OpenAPI3](https://apis.guru/awesome-openapi3/)\n\n- [Swagger Editor](https://editor.swagger.io)\n\n- [OpenAPI Tools](https://openapi.tools)\n",
    "date": "2020-09-08",
    "id": 48,
    "slug": "openapi-intro",
    "title": "OpenAPI使用"
  },
  {
    "author": "Gao",
    "content": "构建一个简单的编译器, 将 List 格式的代码转换成 C 格式的\n\n原始代码\n\n```lisp\n(plus 3 (abstract 9 6))\n```\n\n### 编译器\n\n一个编译器的前端模型\n\n![A Compiler's Frontend](./tiny-compiler/compiler-frontend.jpg)\n\n根据编译过程来解决这个问题\n\n1. 生成`tokens`\n2. 根据`tokens`生成`ast`\n3. 转换`ast`到`newAst`\n4. 从`newAst`生成代码\n\n### Tokenizer\n\n将源代码转换为`token`流\n\n```js\nconst tokenizer = (input) => {\n  let pos = 0;\n  let tokens = [];\n  while (pos < input.length) {\n    let char = input[pos];\n\n    const PAREN_MATCH = /[\\(\\)]/;\n    if (PAREN_MATCH.test(char)) {\n      tokens.push({type: 'paren', value: char});\n      pos++;\n      continue;\n    }\n\n    const NAME_MATCH = /[a-zA-Z_]/;\n    const NAME_MATCH_ = /[a-zA-Z0-9_]/;\n    if (NAME_MATCH.test(char)) {\n      let verb = char;\n      while (NAME_MATCH_.test(input[++pos])) {\n        verb += input[pos];\n      }\n      tokens.push({type: 'name', value: verb});\n      continue;\n    }\n\n    const NUM_MATCH = /[0-9]/;\n    if (NUM_MATCH.test(char)) {\n      let verb = char;\n      while (NUM_MATCH.test(input[++pos])) {\n        verb += input[pos];\n      }\n      tokens.push({type: 'number', value: verb});\n      continue;\n    }\n\n    const WHITE_SPACE = /\\s/;\n    if (WHITE_SPACE.test(char)) {\n      pos++;\n      continue;\n    }\n    throw new Error(`Unexpect token at ${pos}`);\n  }\n  return tokens;\n};\n\nmodule.exports = tokenizer;\n```\n\n### Parser\n\n将`token`流转换为`AST`\n\n```js\nconst parser = (tokens) => {\n  let current = 0;\n\n  const walk = () => {\n    let token = tokens[current];\n\n    if (token.type === 'number') {\n      current++;\n\n      return {\n        type: 'NumberLiteral',\n        value: token.value,\n      };\n    }\n\n    if (token.type === 'paren' && token.value === '(') {\n      token = tokens[++current];\n\n      let node = {\n        type: 'CallExpression',\n        name: token.value,\n        params: [],\n      };\n\n      token = tokens[++current];\n\n      while (\n        token.type !== 'paren' ||\n        (token.type === 'paren' && token.value !== ')')\n      ) {\n        node.params.push(walk());\n        token = tokens[current];\n      }\n\n      current++;\n\n      return node;\n    }\n    throw new TypeError(token.type);\n  };\n\n  let ast = {\n    type: 'Program',\n    body: [],\n  };\n\n  while (current < tokens.length) {\n    ast.body.push(walk());\n  }\n\n  return ast;\n};\n\nmodule.exports = parser;\n```\n\n### Traverser and Transformer\n\n`Traverser` 提供了遍历 AST 的方法\n\n`Transformer` 通过 `Traverser` 遍历语法树来修改 `AST`\n\n#### Traverser\n\n```js\nconst traverser = (ast, visitor) => {\n  const traverseArray = (array, parent) => {\n    array.forEach((child) => {\n      traverseNode(child, parent);\n    });\n  };\n\n  const traverseNode = (node, parent) => {\n    let methods = visitor[node.type];\n\n    if (methods && methods.enter) {\n      methods.enter(node, parent);\n    }\n\n    switch (node.type) {\n      case 'Program':\n        traverseArray(node.body, node);\n        break;\n\n      case 'CallExpression':\n        traverseArray(node.params, node);\n        break;\n\n      case 'NumberLiteral':\n        break;\n\n      default:\n        throw new TypeError(node.type);\n    }\n\n    if (methods && methods.exit) {\n      methods.exit(node, parent);\n    }\n  };\n\n  traverseNode(ast, null);\n};\n\nmodule.exports = traverser;\n```\n\n#### Transformer\n\n```js\nconst traverser = require('./traverser');\n\nconst transformer = (ast) => {\n  let newAst = {\n    type: 'Program',\n    body: [],\n  };\n\n  ast._context = newAst.body;\n\n  traverser(ast, {\n    NumberLiteral: {\n      enter(node, parent) {\n        parent._context.push({\n          type: 'NumberLiteral',\n          value: node.value,\n        });\n      },\n    },\n    CallExpression: {\n      enter(node, parent) {\n        let expression = {\n          type: 'CallExpression',\n          callee: {\n            type: 'Identifier',\n            name: node.name,\n          },\n          arguments: [],\n        };\n\n        node._context = expression.arguments;\n\n        if (parent.type !== 'CallExpression') {\n          expression = {\n            type: 'ExpressionStatement',\n            expression: expression,\n          };\n        }\n\n        parent._context.push(expression);\n      },\n    },\n  });\n\n  return newAst;\n};\n\nmodule.exports = transformer;\n```\n\n### Code Generator\n\n将`AST`重新生成为代码\n\n```js\nconst codeGenerator = (node) => {\n  switch (node.type) {\n    case 'Program':\n      return node.body.map(codeGenerator).join('\\n');\n\n    case 'ExpressionStatement':\n      return codeGenerator(node.expression) + ';';\n\n    case 'CallExpression':\n      return (\n        codeGenerator(node.callee) +\n        '(' +\n        node.arguments.map(codeGenerator).join(', ') +\n        ')'\n      );\n\n    case 'Identifier':\n      return node.name;\n\n    case 'NumberLiteral':\n      return node.value;\n\n    default:\n      throw new TypeError(node.type);\n  }\n};\n\nmodule.exports = codeGenerator;\n```\n",
    "date": "2020-08-02",
    "id": 47,
    "slug": "tiny-compiler",
    "title": "了解Compiler, Tiny compiler"
  },
  {
    "author": "Gao",
    "content": "### 简介：什么是 `Service Worker`\n\n`Service workers` 本质上充当 Web 应用程序与浏览器之间的代理服务器，也可以在网络\n可用时作为浏览器和网络间的代理。它们旨在（除其他之外）使得能够创建有效的离线体验\n，拦截网络请求并基于网络是否可用以及更新的资源是否驻留在服务器上来采取适当的动作\n。他们还允许访问推送通知和后台同步 API。\n\n### Service Worker 概念和用法\n\nService worker 是一个注册在指定源和路径下的事件驱动 worker。它采用 JavaScript 控\n制关联的页面或者网站，拦截并修改访问和资源请求，细粒度地缓存资源。你可以完全控制\n应用在特定情形（最常见的情形是网络不可用）下的表现。\n\nService worker 运行在 worker 上下文，因此它不能访问 DOM。相对于驱动应用的主\nJavaScript 线程，它运行在其他线程中，所以不会造成阻塞。它设计为完全异步，同步\nAPI（如 XHR 和 localStorage）不能在 service worker 中使用。\n\n出于安全考量，Service workers 只能由 HTTPS 承载，毕竟修改网络请求的能力暴露给中\n间人攻击会非常危险。在 Firefox 浏览器的用户隐私模式，Service Worker 不可用。\n\n      注意：Service workers之所以优于以前同类尝试（如AppCache），是因为它们无法支持当操作出错时终止操作。Service workers可以更细致地控制每一件事情。\n\n      注意：Service workers大量使用Promise，因为通常它们会等待响应后继续，并根据响应返回一个成功或者失败的操作。Promise非常适合这种场景。\n\n**注册：**\n\n使用 ServiceWorkerContainer.register() 方法首次注册 service worker。如果注册成功\n，service worker 就会被下载到客户端并尝试安装或激活（见下文），这将作用于整个域\n内用户可访问的 URL，或者其特定子集。\n\n**下载、安装和激活**\n\n此时，你的服务工作者(service worker)将遵守以下生命周期：\n\n1. 下载\n2. 安装\n3. 激活\n\n用户首次访问 service worker 控制的网站或页面时，service worker 会立刻被下载。\n\n之后，在以下情况将会触发更新:\n\n一个前往作用域内页面的导航在 service worker 上的一个事件被触发并且过去 24 小时没\n有被下载无论它与现有 service worker 不同（字节对比），还是第一次在页面或网站遇到\nservice worker，如果下载的文件是新的，安装就会尝试进行。\n\n如果这是首次启用 service worker，页面会首先尝试安装，安装成功后它会被激活。\n\n如果现有 service worker 已启用，新版本会在后台安装，但不会被激活，这个时序称为\nworker in waiting。直到所有已加载的页面不再使用旧的 service worker 才会激活新的\nservice worker。只要页面不再依赖旧的 service worker，新的 service worker 会被激\n活（成为 active worker）。\n\n你可以监听`InstallEvent`，事件触发时的标准行为是准备 service worker 用于使用，例\n如使用内建的 storage API 来创建缓存，并且放置应用离线时所需资源。\n\n还有一个 activate 事件，触发时可以清理旧缓存和旧的 service worker 关联的东西。\n\nServcie worker 可以通过 `FetchEvent` 事件去响应请求。通过使用\n`FetchEvent.respondWith` 方法，你可以任意修改对于这些请求的响应。\n\n      注意: 因为oninstall和onactivate完成前需要一些时间，service worker标准提供一个waitUntil方法，当oninstall或者onactivate触发时被调用，接受一个promise。在这个 promise被成功resolve以前，功能性事件不会分发到service worker。\n\n### 其他使用场景\n\nService workers 也可以用来做这些事情：\n\n- 后台数据同步\n- 响应来自其它源的资源请求\n- 集中接收计算成本高的数据更新，比如地理位置和陀螺仪信息，这样多个页面就可以利用\n  同一组数据\n- 在客户端进行 CoffeeScript，LESS，CJS/AMD 等模块编译和依赖管理（用于开发目的）\n- 后台服务钩子\n- 自定义模板用于特定 URL 模式\n- 性能增强，比如预取用户可能需要的资源，比如相册中的后面数张图片\n\n未来 service workers 能够用来做更多使 web 平台接近原生应用的事。 值得关注的是，\n其他标准也能并且将会使用 service worker，例如:\n\n- 后台同步：启动一个 service worker 即使没有用户访问特定站点，也可以更新缓存\n- 响应推送：启动一个 service worker 向用户发送一条信息通知新的内容可用\n- 对时间或日期作出响应\n- 进入地理围栏\n\n### 接口\n\n- Cache\n\n表示用于 Request/Response 对象对的存储，作为 ServiceWorker 生命周期的一部分被缓\n存。\n\n- CacheStorage\n\n表示 Cache 对象的存储。提供一个所有命名缓存的主目录，ServiceWorker 可以访问并维\n护名字字符串到 Cache 对象的映射。\n\n- Client\n\n表示 service worker client 的作用域。一个 service worker client 可以是浏览器上下\n文的一个文档，也可以是一个由活动 worker 控制的 SharedWorker。\n\n- Clients\n\n表示一个 Client 对象容器，是访问当前源的活动 service worker clients 的主要途径。\n\n- ExtendableEvent\n\n扩展被分发到 ServiceWorkerGlobalScope 的 install 和 activate 事件时序，作为\nservice worker 生命周期的一部分。这会确保任何功能型事件（如 FetchEvent）不被分发\n到 ServiceWorker，直到它更新了数据库架构、删除过期缓存项等等以后。\n\n- ExtendableMessageEvent\n\nThe event object of a message event fired on a service worker (when a channel\nmessage is received on the ServiceWorkerGlobalScope from another context) —\nextends the lifetime of such events.\n\n- FetchEvent\n\n传递给 ServiceWorkerGlobalScope.onfetch 处理函数的参数，FetchEvent 代表一个在\nServiceWorker 的 ServiceWorkerGlobalScope 中分发的请求动作。它包含关于请求和响应\n的结果信息，并且提供 FetchEvent.respondWith()方法，这个方法允许我们提供任意的响\n应返回到控制页面。\n\n- InstallEvent\n\n传递给 oninstall 处理函数的参数，InstallEvent 接口代表一个在 ServiceWorker 的\nServiceWorkerGlobalScope 中分发的安装动作，作为 ExtendableEvent 的子事件，它保证\n诸如 FetchEvent 的功能性事件在安装过程中不会被分发。\n\n- NavigationPreloadManager\n\nProvides methods for managing the preloading of resources with a service worker.\n\n- Navigator.serviceWorker\n\n返回一个 ServiceWorkerContainer 对象，可以提供入口用于注册，删除，更新以及与在相\n关 document 中 ServiceWorker 通信的对象。\n\n- NotificationEvent\n\n传递给 onnotificationclick 处理函数的参数，NotificationEvent 接口代表在\nServiceWorker 里 ServiceWorkerGlobalScope 中分发的单击事件通知。\n\n- ServiceWorker\n\n表示一个 service worker。多个浏览的上下文(例如 pages,workers 等等)都能通过相同的\nServiceWorker 对象相关联。\n\n- ServiceWorkerContainer\n\n提供一个在网络生态中把 service worker 作为一个整体的对象，包括辅助注册，反注册以\n及更新服务工作者，并且访问 service worker 的状态以及他们的注册信息。\n\n- ServiceWorkerGlobalScope\n\n表示 service worker 的全局执行上下文。\n\n- ServiceWorkerMessageEvent\n\n包含关于一个发送给以 navigator.serviceWorker 为目标的事件信息。Note that this\ninterface is deprecated in modern browsers. Service worker messages will now use\nthe MessageEvent interface, for consistency with other web messaging features.\n\n- ServiceWorkerRegistration\n\n表示 service worker 的注册。\n\n- ServiceWorkerState\n\nAssociated with its ServiceWorker's state.\n\n- SyncEvent\n\n传递给同步函数的参数，SyncEvent 接口代表在 ServiceWorker 里\nServiceWorkerGlobalScope 分发的同步动作。\n\n- SyncManager\n\n提供一个接口用于注册和返回 SyncRegistration 对象。\n\n- WindowClient\n\n表示在浏览器上下文中记录的 service worker 客户端的作用域，被活动的工作者控制。是\nClient 对象的特殊类型，包含一些附加的方法和可用的属性。\n",
    "date": "2020-07-02",
    "id": 46,
    "slug": "service-worker",
    "title": "Service Worker"
  },
  {
    "author": "Gao",
    "content": "### `libcluster`\n\n之前看了**Elixir Conf**上演示的集群自动扩展和发现，一直很想试试\n\n有空在博客上实现了这个功能，使用`libcluster`来完成集群中的节点自动发现\n\n`libcluster` 提供了很多自动发现的方式，有：\n\n- Cluster.Strategy.Epmd, which relies on epmd to connect to a configured set of\n  hosts.\n- Cluster.Strategy.ErlangHosts, which uses the .hosts.erlang file to determine\n  which hosts to connect to.\n- Cluster.Strategy.Gossip, which uses multicast UDP to form a cluster between\n  nodes gossiping a heartbeat.\n- Cluster.Strategy.Kubernetes, which uses the Kubernetes Metadata API to query\n  nodes based on a label selector and basename.\n- Cluster.Strategy.Kubernetes.DNS, which uses DNS to join nodes under a shared\n  headless service in a given namespace.\n- Cluster.Strategy.Kubernetes.DNSSRV, which uses DNS SRV to join nodes under a\n  shared headless service in a given namespace.\n- Cluster.Strategy.Rancher, which like the Kubernetes strategy, uses a metadata\n  API to query nodes to cluster with.\n\n根据我的情况，使用 Kubernetes 的发现机制来实现\n\nKuberntes 有几种，DNS 和 DNSSRV 比较适合 statefulset 来控制，由于我使用的是\ndeployment，所以就使用了`Cluster.Strategy.Kubernetes`\n\n### 使用中的一些问题\n\n官方版本的服务发现写死了 cluster domain 为 cluster.local，由于我自己使用了公开域\n名来做 cluster domain，所以我 fork 了一个版本做了修改\n\n修改过程还发现一个问题，Module 的 attribute 值是编译时决定的，我错误的使用系统\nenv 导致每次都失败，后来排查发现了问题。\n\n这里是我的 topoogies 配置\n\n```elixir\ntopologies = [\n  gsmlg: [\n    strategy: Cluster.Strategy.Kubernetes,\n    config: [\n      mode: :ip,\n      kubernetes_ip_lookup_mode: :pods,\n      kubernetes_node_basename: \"#{GSMLG.name}\",\n      kubernetes_selector: System.get_env(\"SELECTOR\", \"gsmlg.org/app=blog\"),\n      kubernetes_namespace: System.get_env(\"NAMESPACE\", \"#{GSMLG.name}\"),\n      polling_interval: 10_000\n    ]\n  ]\n]\n```\n\n我选用的是 IP 模式，是根据 selector，来选取 endpoint 和 pod 来连接服务\n\n这里的 node_basename 是 opt app name，不是 domain 的 basename，区别于\ndns/hostname 模式\n\n### 完成总结\n\n最后实现成功后发现原先写的小程序有问题，因为原先的服务发现是自己手动调整的，处理\n时间有问题，还需要重新调整一下。\n",
    "date": "2020-06-24",
    "id": 45,
    "slug": "libcluster",
    "title": "Cluster中自动发现erlang node"
  },
  {
    "author": "Gao",
    "content": "# 内容发布与分发\n\n## 主机托管服务\n\n对内容资源的存储、协调以及管理的职责统称为 Web 主机托管。\n\n主机托管是 Web 服务器的主要功能之一。\n\n### Web 主机托管\n\n#### 主机托管服务\n\n- 简单例子--专用托管\n\n例如：\n\n- DigitalOcean Bare Metal Server\n- Vultr Bare Metal Server\n- 华为云 裸金属服务器\n\n* 虚拟主机托管\n\n例如：\n\n- Google App Engine\n- Sina App Engine\n- Github Pages\n\n#### 虚拟服务器请求缺乏主机信息\n\n不幸的是，HTTP/1.0 中的一个设计缺陷会使虚拟主机托管者抓狂。 HTTP/1.0 规范中没有\n为共享的 Web 服务器提供任何方法来识别要访问的是所托管的哪个虚拟网站。\n\n#### 设法让虚拟主机托管正常工作\n\n- 通过 URL 路径进行虚拟主机托管\n\n在 URL 中增添专门的路径部分，以便服务器判断是哪个网站。\n\n- 通过端口号进行主机托管\n\n为每个站点分配不同的端口号，这样请求就由 Web 服务器的单独实例来处理。\n\n- 通过 IP 地址进行主机托管\n\n为不同的虚拟站点分配专门的 IP 地址，把这些地址都绑定到一台单独的机器上。这样\n，Web 服务器就可以通过 IP 地址来识别网站名了。\n\n- 通过 Host 首部进行主机托管\n\n很多 Web 托管者向 HTTP 的设计者施压，要求解决这个问题。 HTTP/1.0 的增强 版和\nHTTP/1.1 的正式版定义了 Host 请求首部来携带网站名称。 Web 服务器可 以通过 Host\n首部识别虚拟站点。\n\n#### HTTP/1.1 的 Host 首部\n\nHost 首部是 HTTP/1.1 的请求首部，定义在 RFC 2068 中。\n\n1. **语法与用法**\n\nHost 首部描述了所请求的资源所在的因特网主机和端口号，和原始的 URL 中得到 的一样:\n\n    Host = \"Host\" \":\" host [ \":\" port ]\n\n需要注意 ⚠️：\n\n- 如果 Host 首部不包含端口，就使用地址方案中默认的端口。\n\n- 如果 URL 中包含 IP 地址，Host 首部就应当包含同样的地址。\n\n- 如果 URL 中包含主机名，Host 首部就必须包含同样的名字。\n\n- 如果 URL 中包含主机名，Host 首部就不应当包含 URL 中这个主机名对应的 IP 地址，\n  因为这样会扰乱虚拟主机托管服务器的工作，它在同一个 IP 地址上堆叠了很多虚拟站点\n  。\n\n- 如果 URL 中包含主机名，Host 首部就不应当包含这个主机名的其他别名，因为这样也会\n  扰乱虚拟主机托管服务器的工作。\n\n- 如果客户端显式地使用代理服务器，客户端就必须把原始服务器，而不是代理服务器的名\n  字和端口放在 Host 首部中。以往，若干个 Web 客户端在启用客户端代理设置时，错误\n  地把发出的 Host 首部设置成代理的主机名。这种错误行为会使代理和原始服务器都无法\n  正常处理请求。\n\n- Web 客户端必须在所有请求报文中包含 Host 首部。\n\n- Web 代理必须在转发请求报文之前，添加 Host 首部。\n\n- HTTP/1.1 的 Web 服务器必须用 400 状态码来响应所有缺少 Host 首部字段的 HTTP/1.1\n  请求报文。\n\n2. **缺失 Host 首部**\n\n过去有老式浏览器不会发送 Host 首部，现在默认不会出现这个问题。\n\n但是如果缺失 Host 的话，服务器可能会返回默认页面，或者返回错误页面。\n\n3. **解释 Host 首部**\n\n1. 如果 HTTP 请求报文中的 URL 是绝对的(也就是说，包含方案和主机部分)， 就忽略\n   Host 首部的值。\n\n1. 如果 HTTP 请求报文中的 URL 没有主机部分，而该请求带有 Host 首部，则主 机 / 端\n   口的值就从 Host 首部中取。\n\n1. 如果通过第(1)步或第(2)步都无法获得有效的主机，就向客户端返回 400 Bad Request\n   响应。\n\n4) **Host 首部与代理**\n\n某些版本的浏览器发送的 Host 首部不正确，尤其是配置使用代理的时候。例如，配置使用\n代理时，一些老版本的 Apple 和 PointCast 客户端会错误地把代理的名字，而不是原始服\n务器的名字放在 Host 首部里发送。\n\n### 使网站更可靠\n\n在下面列出的这些时间段内，网站通常是无法运作的。\n\n- 服务器宕机的时候。\n\n- 交通拥堵:突然间很多人都要看某个特别的新闻广播或涌向某个大甩卖网店。突然的拥堵\n  可以使 Web 服务器过载，降低其响应速度，甚至使它彻底停机。\n\n- 网络中断或掉线。\n\n#### 镜像的服务器集群\n\n![](http-publish-distribution/mirror.png)\n\n有以下两种方法把客户端的请求导向特定的服务器。\n\n- HTTP 重定向\n\n该内容的 URL 会解析到主服务器的 IP 地址，然后它会发送重定向到复制服务器。\n\n- DNS 重定向\n\n该内容的 URL 会解析到 4 个 IP 地址，DNS 服务器可以选择发送给客户端的 IP 地址。\n\n#### 内容分发网络\n\n简单地说，内容分发网络(CDN)就是对特定内容进行分发的专门网络。\n\n这个网络中的节点可以是 Web 服务器、反向代理或缓存。\n\n#### CDN 中的反向代理缓存\n\n具体实现可以参考`varnish`\n\n#### CDN 中的代理缓存\n\n与反向代理不同，传统的 代理缓存能收到发往任何 Web 服务器的请求。 (在代理缓存与原\n始服务器之间不需 要有任何工作关系或 IP 地址约定。) 但是与反向代理比起来，代理缓\n存的内容一般 都是按需驱动的，不能指望它是对原始服务器内容的精确复制。某些代理缓\n存也可以预先载入热点内容。\n\n按需驱动的代理缓存可以部署在其他环境中——尤其是拦截环境，在这种情况下，2 层 或 3\n层设备(交换机或路由器)会拦截 Web 流量并将其发送给代理缓存。\n\n![](http-publish-distribution/proxy-cache.png)\n\n### 让网站更快\n\n服务器集群和分布式代理缓存 或反向代理服务器分散了网络流量，可以避免拥塞。\n\n分发内容使之更靠近终端用户，这样从服务器到客户端的传输时间就更短了。\n\n请求和响应穿过因特网，在客户端和服务器间传输的方式是影响资源访问速度最主要的因素\n。\n\n### 更多信息\n\n- http://www.ietf.org/rfc/rfc3040.txt\n\nRFC 3040，“Internet Web Replication and Caching Taxonomy”(“因特网 Web 复 制和缓\n存分类法”)，这份文档是关于 Web 复制与缓存应用术语的参考文献。\n\n- http://search.ietf.org/internet-drafts/draft-ietf-cdi-request-routing-reqs-00.txt\n\n“Request-Routing Requirements for Content Internetworking”(“内容网际互连的请求路\n由需求”)。\n\n- Apache: The Definitive Guide1(《Apache 权威指南》)\n\nBen Laurie 和 Peter Laurie 著，O’Reilly & Associates 公司出版。这本书讲述如何运\n行开源的 Apache Web 服务器。\n\n## 发布系统\n\n许多支持远程发布内容的工具都使用了扩展的 HTTP 协议。\n\n以 HTTP 为 基础的两种重要的 Web 内容发布技术:FrontPage 和 DAV。\n\n### FrontPage 为支持发布而做的服务器扩展\n\nFrontPage(FP)是微软公司提供的一种通用 Web 写作和发布工具包。\n\n    Microsoft FrontPage（全名Microsoft Office FrontPage）是Microsoft停止提供的Microsoft Windows系列操作系统的WYSIWYG HTML编辑器和网站管理工具。\n    从1997年到2003年，它被商标为Microsoft Office套件的一部分。\n    此后，Microsoft FrontPage被Microsoft Expression Web和SharePoint Designer所取代，\n    后者于2006年12月与Microsoft Office 2007一起首次发布，但这两款产品也不再支持基于Web的SharePoint Designer版本，因为这三个HTML编辑器是桌面应用程序。\n\n### WebDAV 与协作写作\n\nWebDAV(作为 RFC 2518 发表)专注于对 HTTP 进行扩展，以提供协作写作的适宜平台。\n\nWebDAV 提供了许多的 HTTP 请求方法和首部集，并定义了一些 HTTP 状态响应码。\n\nWebDAV 数据交换使用 XML 格式。\n\n在 RFC 3253 中为 WebDAV 加入了版本管理功能。\n\n现在可以将 WebDAV 资源直接挂在到文件系统上，出于安全原因，macOS 仅支持基于 https\n的 WebDAV。\n\n## 重定向与负载均衡\n\n重定向技术:\n\n- HTTP 重定向;\n- DNS 重定向;\n- 任播路由;\n- 策略路由;\n- IP MAC 转发;\n- IP 地址转发;\n- WCCP (Web 缓存协调协议);\n- ICP (缓存间通信协议);\n- HTCP (超文本缓存协议);\n- NECP (网元控制协议);\n- CARP (缓存阵列路由协议);\n- WPAD (Web 代理自动发现协议)。\n\n### 重定向协议概览\n\n- 配置创建客户端报文的浏览器应用程序，使其将报文发送给代理服务器。\n\n- DNS 解析程序会选择用于报文寻址的 IP 地址。对不同物理地域的不同客户端来说，这个\n  IP 地址可能不同。\n\n- 报文经过网络传输时，会被划分为一些带有地址的分组;交换机和路由器会检查分组中的\n  TCP/IP 地址，并据此来确定分组的发送路线。\n\n- Web 服务器可以通过 HTTP 重定向将请求反弹给不同的 Web 服务器。\n\n#### 通用的重定向方法\n\n##### HTTP 重定向\n\n最初，HTTP 请求先到第一台 Web 服务器，这台服务器会选 择一台“最佳”的 Web 服务器\n为其提供内容。第一台 Web 服 务器会向客户端发送一条到指 定服务器的 HTTP 重定向。\n客 户端会将请求重新发送到选中 的服务器上\n\n选择最短路径时可用的选项很多， 包括轮转 (round-robin) 负载均衡和最小化时延等\n\n可能会很慢——每个事务都包含了附加的重定向步骤。而且，第一台服务器一定要能够处理请\n求负载\n\n##### DNS 重定向\n\nDNS 服务器决定在 URL 的主机名中返回多个 IP 地址中的哪一个\n\n选择最短路径时可用的选项很多， 包括轮转 (round-robin) 负载均衡和最小化时延等\n\n需要配置 DNS 服务器\n\n##### 任播寻址\n\n几台服务器使用相同的 IP 地 址。每台服务器都会伪装成一个骨干路由器。其他路由器会\n将共享 IP 地址分组发送给最近的服务器(认为它们将分组发送给最近的路由器)\n\n路由器有内建的最短路径路由功能\n\n需要拥有 / 配置路由器。 有地址冲突的风险。如果路由变化了，与已建立的 TCP 连接相\n关的分组会被发送到其他的服务器，可能会使 TCP 连接断裂\n\n##### IP MAC 转发\n\n交换机或路由器这样的网元会读取分组的目的地址。如果应该将分组重定向，交换机会将服\n务器或代理的目标 MAC 地址赋予分组\n\n节省带宽，提高 QOS。负载均衡\n\n服务器或代理的跳距必 须是 1\n\n##### IP 地址转发\n\n第四层交换机会评估分组的目的端口并将重定向分组的 IP 地址改成代理或镜像服务器的\nIP 地址\n\n节省带宽，提高 QOS。负载均衡\n\n服务器或代理可能看不到真正的客户端 IP 地址\n\n#### 代理与缓存重定向技术\n\n##### 显式浏览器配置\n\n配置 Web 浏览器，使其将 HTTP 报文发送给附近的一 个代理，通常是缓存。可以 由终端\n用户或管理浏览器的 服务进行配置\n\n##### 代理自动配置(PAC)\n\nWeb 浏览器从配置服务器 中解析出 PAC 文件。这个 PAC 文件会告诉浏览器为每 个 URL\n使用什么代理\n\n[Wiki](https://en.wikipedia.org/wiki/Proxy_auto-config)\n\n##### Web Proxy 代理自动发现协议(WPAD)\n\nWeb 浏览器向配置服务器查询一个 PAC 文件的 URL。 与单独使用 PAC 不同，不需要将浏\n览器配置为使用特定的配置服务器\n\n[Wiki](https://en.wikipedia.org/wiki/Web_Proxy_Auto-Discovery_Protocol)\n\n##### Web 缓存协调协议(WCCP)\n\n路由器会评估一个分组的目的地址，并用代理或镜像服务器的 IP 地址将重定向分组封装起\n来。可以与很多现有路由器共同工作。可以将分组封装起来，这样客户端的 IP 地址就不会\n丢失了\n\n[Wiki](https://en.wikipedia.org/wiki/Web_Cache_Communication_Protocol)\n\n##### 因特网缓存协议(ICP)\n\n代理缓存会在一组兄弟代理 缓存中查询所请求的内容。 还支持缓存的分层结构\n\n[Wiki](https://en.wikipedia.org/wiki/Internet_Cache_Protocol)\n\n##### 缓存分组路由协议(CARP)\n\n一种代理缓存散列协议。允许缓存将请求转发给一个父 缓存。与 ICP 不同的是，高速缓存\n上的内容是不相交的，这组缓存会像一个大型缓存那样工作\n\n[Wiki](https://en.wikipedia.org/wiki/Cache_Array_Routing_Protocol)\n\n##### 超文本缓存协议(HTCP)\n\n参与的代理缓存可以向一组兄弟缓存查询所请求的内容。支持 HTTP 1.0 和 1.1 首部，以\n便精细地调整缓存查询\n\n[Wiki](https://en.wikipedia.org/wiki/Hypertext_caching_protocol)\n\n## 日志记录与使用情况跟踪\n\n### 记录内容\n\n通常会记录下来的几个字段示例为:\n\n- HTTP 方法;\n- 客户端和服务器的 HTTP 版本;\n- 所请求资源的 URL;\n- 响应的 HTTP 状态码;\n- 请求和响应报文的尺寸(包含所有的实体主体部分);\n- 事务开始时的时间戳;\n- Referer 首部和 User-Agent 首部的值。\n\n### 日志格式\n\n大部分商用和开源的 HTTP 应用程序都支持以一种或多种常用格式进行日志记录。很多这样\n的应用程序都支持管理者配置日志格式，创建自定义的格式。\n\n应用程序支持管理者使用这些更标准的格式的主要好处之一就在于，可以充分利用 那些已\n构建好的工具处理这些日志，并产生基本的统计信息。\n\n#### 常见日志格式\n\n最常见的日志格式之一就是常用日志格式。这种日志格式最初由 NCSA 定义，很多服务器在\n默认情况下都会使用这种日志格式。\n\n#### 组合日志格式\n\n另一种常用日志格式为组合日志格式(Combined Log Format)。\n\n组合日志格式与常用日志格式很类似。实际上，它就是常用日志格式的精确镜像，只是添加\n了 `Referer` 和 `User-Agent` 两个字段。\n\n#### 网景扩展 2 日志格式\n\n网景的格式是基于 NCSA 的常用日志格式的，但它们扩展了该格式，以支持与代理和 Web\n缓存这样的 HTTP 应用程序相关的字段。\n\n另一种网景日志格式，网景扩展 2 日志格式采用了扩展日志格式，并添加了一些与 HTTP\n代理和 Web 缓存应用程序有关的附加信息。这些附加字段有助于更好地描绘 HTTP 客户端\n和 HTTP 代理应用程序间的交互图景。\n\n#### Squid 代理日志格式\n\nSquid 代理缓存(http://www.squid-cache.org)是 Web 上一个很古老的部分。\n\n有很多工具可以用来辅助管理 Squid 应用程序，包括一些有助于处理、审核及开发 其日志\n的工具。很多后继代理缓存都为自己的日志使用了 Squid 格式，这样才能更好地利用这些\n工具。\n\n### 命中率测量\n\n原始服务器通常会出于计费的目的保留详细的日志记录。内容提供者需要知道 URL 的受访\n频率，广告商需要知道广告的出现频率，网站作者需要知道所编写的内容的受欢迎程度。客\n户端直接访问 Web 服务器时，日志记录可以很好地跟踪这些信息。\n\n但是，缓存服务器位于客户端和服务器之间，用于防止服务器同时处理大量访问请求(这正\n是缓存的目的)。缓存要处理很多 HTTP 请求，并在不访问原始服务器的情况下满足它们的\n请求，服务器中没有客户端访问其内容的记录，导致日志文件中出现遗漏。\n\n由于日志数据会遗失，所以，内容提供者会对其最重要的页面进行缓存清除(cache bust)。\n缓存清除是指内容提供者有意将某些内容设置为无法缓存，这样，所有对此内容的请求都会\n被导向原始服务器。于是，原始服务器就可以记录下访问情况了。 不使用缓存可能会生成\n更好的日志，但会减缓原始服务器和网络的请求速度，并增加其负荷。\n\n由于代理缓存(及一些客户端)都会保留自己的日志，所以如果服务器能够访问这些日志(或\n者至少有一种粗略的方式可以判断代理缓存会以怎样的频率提供其内 容)，就可以避免使用\n缓存清除。命中率测量协议是对 HTTP 的一种扩展，它为这个问题提供了一种解决方案。命\n中率测量协议要求缓存周期性地向原始服务器汇报缓存访问的统计数据。\n\nRFC 2227 详细定义了命中率测量协议。\n\n#### 概述\n\n命中率测量协议定义了一种 HTTP 扩展，它提供了一些基本的功能，缓存和服务器可以实现\n这些功能来共享访问信息，规范已缓存资源的可使用次数。\n\n缓存给日志访问带来了问题，命中率测量并不是这个问题的完整解决方案，但它确实提供了\n一种基本方式，以获取服务器希望跟踪的度量值。命中率测量协议并没有(而且可能永远都\n不会)得到广泛的实现或应用。\n\n#### Meter 首部\n\n命中率测量扩展建议使用新增加的首部 Meter，缓存和服务器可以通过它在相互间传输与用\n法和报告有关的指令，这与用来进行缓存指令交换的 Cache-Control 首部很类似。\n\n![](http-publish-distribution/meter.png)\n\n### 关于隐私的考虑\n\n日志记录实际上就是服务器和代理执行的一项管理功能，所以整个操作对用户来说 都是透\n明的。通常，用户甚至都不清楚他们的 HTTP 事务已被记录--实际上，很 多用户可能甚至\n都不知道他们访问 Web 上的内容时是在使用 HTTP 协议。\n\nWeb 应用程序的开发者和管理者要清楚跟踪用户的 HTTP 事务可能带来的影响。他可以根据\n获取的信息收集很多有关用户的情况。很显然，这些信息可以用于不良目的--歧视、骚扰、\n勒索等。进行日志记录的 Web 服务器和代理一定要注意保护其 终端用户的隐私。\n\n### 更多信息\n\n- http://httpd.apache.org/docs/logs.html\n\n“Apache HTTP Server: Log Files”(“Apache HTTP 服务器:日志文件”)。 ApacheHTTP 服务\n器项目网站。\n\n- http://www.squid-cache.org/Doc/FAQ/FAQ-6.html\n\n“Squid Log Files”(“Squid 日志文件”)。Squid 代理缓存网站。\n\n- http://www.w3.org/Daemon/User/Config/Logging.html#common-logfile-format\n\n“Logging Control in W3C httpd”(“W3C httpd 中的日志记录控制”)。\n\n- http://www.w3.org/TR/WD-logfile.html\n\n“Extended Log File Format”(“扩展日志文件格式”)。\n\n- http://www.ietf.org/rfc/rfc2227.txt\n\nRFC 2227，J. Mogul 和 P. Leach 编写的“Simple Hit-Metering and Usage- Limiting\nfor HTTP”(“简单的 HTTP 命中率测量和使用限制”)。\n",
    "date": "2020-06-09",
    "id": 44,
    "slug": "http-publish-distribution",
    "title": "HTTP 发布与分发"
  },
  {
    "author": "Gao",
    "content": "## 内容协商与转码\n\n一个 URL 常常需要代表若干不同的资源。例如那种需要以多种语言提供其内容的网站站点\n。\n\nHTTP 提 供了内容协商方法，允许客户端和服务器作这样的决定。通过这些方法，单一的\nURL 就可以代表不同的资源(比如，同一个网站页面的法语版和英语版)。这些不同的版本称\n为变体。\n\n### 内容协商技术\n\n共有 3 种不同的方法可以决定服务器上哪个页面最适合客户端:\n\n- 让客户端来选择\n- 服务器自动判定\n- 让中间代理来选\n\n这 3 种技术分别称为\n\n- 客户端驱动的协商\n- 服务器驱动的协商\n- 透明协商\n\n| 技术       | 工作原理                                             | 优点                                                                                                                          | 缺点                                                 |\n| ---------- | ---------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- |\n| 客户端驱动 | 客户端发起请求，服务器发送可选项的列表，客户端选择   | 在服务器端的实现最容易。客户端可以选择最合适的内容                                                                            | 增加了时延:为了获得正确的内容，至少要发送两次请求    |\n| 服务器驱动 | 服务器检查客户端的请求首部集并决定提供哪个版本的页面 | 比客户端驱动的协商方式要快。 HTTP 提供了 q 值机制，允许服务器近似匹配，还提供了 Vary 首部供服务器告知下游的设备如何对请求估值 | 如果结论不是很明确(比如首部集不匹配)，服务器要做猜测 |\n| 透明       | 某个中间设备(通常是缓存代理)代表客户端进行请求协商   | 免除了 Web 服务器的协商开销。比客户端驱动的协商要快                                                                           | 关于如何进行透明协商，还没有正式的规范               |\n\n### 客户端驱动的协商\n\n从实现原理上来说，服务器实际上有两种方法为客户端提供选项:\n\n- 一是发送回一个 HTML 文档，里面有到该页面的各种版本的链接和每个版本的描述信息;\n\n- 另一种方法是发送回 HTTP/1.1 响应时，使用 300 Multiple Choices 响应代码。客户端\n  浏览器 收到这种响应时，在前一种情况下，会显示一个带有链接的页面; 在后一种情况\n  下，可能会弹出对话窗口，让用户做选择。不管怎么样，决定是由客户端的浏览器用户\n  作出的。\n\n### 服务器驱动的协商\n\n有以下两种机制可供 HTTP 服务器评估发送什么响应给客户端比较合适。\n\n- 检查内容协商首部集。服务器察看客户端发送的 Accept 首部集，设法用相应的 响应首\n  部与之匹配。\n\n- 根据其他(非内容协商)首部进行变通。例如，服务器可以根据客户端发送的 User-Agent\n  首部来发送响应。\n\n#### 内容协商首部集\n\n| 首部            | 描述                       |\n| --------------- | -------------------------- |\n| Accept          | 告知服务器发送何种媒体类型 |\n| Accept-Language | 告知服务器发送何种语言     |\n| Accept-Charset  | 告知服务器发送何种字符集   |\n| Accept-Encoding | 告知服务器采用何种编码     |\n\n注意，由于 HTTP 是无状态的协议(表示服务器不会在不同的请求之间追踪客户端 的偏好\n)，所以客户端必须在每个请求中都发送其偏好信息。\n\n#### 内容协商首部中的质量值\n\n客户端可以发送下列形式的 Accept-Language 首部:\n\n```http\nAccept-Language: en;q=0.5, fr;q=0.0, nl;q=1.0, tr;q=0.0\n```\n\n其中 q 值的范围从 0.0 ~ 1.0(0.0 是优先级最低的，而 1.0 是优先级最高的)。上面 列\n出的那个首部，说明该客户端最愿意接收荷兰语(缩写为 nl)文档，但英语(缩 写为 en)文\n档也行;无论如何，这个客户端都不愿意收到法语(缩写为 fr)或土耳 其语(缩写为 tr)的版\n本。\n\n#### 随其他首部集而变化\n\n服务器也可以根据其他客户端请求首部集来匹配响应，比如 User-Agent 首部。\n\n在这种情况下，没有 q 值机制可供查找“最近似”的匹配。服务器或者去找完全匹配，或者\n简单地有什么就给什么，这取决于服务器的实现。\n\n由于缓存需要尽力提供所缓存文档中正确的“最佳”版本，HTTP 协议定义了服务器在响应中\n发送的 Vary 首部。这个首部告知缓存(还有客户端和所有下游的代理)服务器根据哪些首部\n来决定发送响应的最佳版本。\n\n#### Apache 中的内容协商\n\n1. 使用 type-map 文件\n\n可以在服务器的配置文件中设 置 handler 来说明 type-map 文件的后缀名。\n\n```apache\nAddHandler type-map .var\n```\n\n这里给出一个 type-map 文件示例:\n\n```apache\nURI: joes-hardware.html\n\nURI: joes-hardware.en.html\nContent-type: text/html\nContent-language: en\nURI: joes-hardware.fr.de.html\nContent-type: text/html;charset=iso-8859-2\nContent-language: fr, de\n```\n\n根据这个 type-map 文件， Apache 服务器就知道要发送 joes-hardware.en.html 给请求\n英语版的客户端，发送 joes-hardware.fr.de.html 给请求法语版的客户端。 Apache 服务\n器也支持质量值，具体信息请参阅它的文档。\n\n2. 使用 MultiView\n\n为了使用 MultiView，必须在网站目录下的 `access.conf` 文件中的适当小节\n(<Directory>、 <Location>，或 <Files>)使用 OPTION 指令来启用它。\n\n如果启用了 MultiView，而浏览器又请求了名为 joes-hardware 的资源，服务器就会查找\n所有名字中含有 joes-hardware 的文件，并为它们创建 type-map 文件。服务器会 根据名\n字猜测其对应的内容协商首部集。例如，法语版的 joes-hardware 应当含有 .fr。\n\n#### 服务器端扩展\n\n另一种在服务器端实现内容协商的方法是使用服务器端扩展\n\n### 透明协商\n\n透明协商机制试图从服务器上去除服务器驱动协商所需的负载，并用中间代理来代表客户端\n以使与客户端的报文交换最小化。假定代理了解客户端的预期，这样就可以代表客户端与服\n务器协商(在客户端请求内容的时候，代理已经收到了客户端的预期)。为了支持透明内容协\n商，服务器必须有能力告知代理，服务器需要检查哪些请求首部，以便对客户端的请求进行\n最佳匹配。 HTTP/1.1 规范中没有定义任何透明协商机制，但定义了 Vary 首部。服务器在\n响应中发送了 Vary 首部，以告知中间节点需要使用哪些请求首部进行内容协商。\n\n代理缓存可以为通过单个 URL 访问的文档保存不同的副本。如果服务器把它们的决 策过程\n传给缓存，这些代理就能代表服务器与客户端进行协商。缓存同时也是进行 内容转码的好\n地方，因为部署在缓存里的通用转码器能对任意服务器，而不仅仅是 一台服务器传来的内\n容进行转码。\n\n#### 进行缓存与备用候选\n\n对内容进行缓存的时候是假设内容以后还可以重用。然而，为了确保对客户端请求 回送的\n是正确的已缓存响应，缓存必须应用服务器在回送响应时所用到的大部分决 策逻辑。\n\n#### Vary 首部\n\nHTTP 的 Vary 响应首部中列出了所有客户端请求首部，服务器可用这些首部来选择文档或\n产生定制的内容(在常规的内容协商首部集之外的内容)。\n\n例如，若所提供的 文档取决于 User-Agent 首部，Vary 首部就必须包含 User-Agent。\n\n当新的请求到达时，缓存会根据内容协商首部集来寻找最佳匹配。但在把文档提供 给客户\n端之前，它必须检查服务器有没有在已缓存响应中发送 Vary 首部。如果有 Vary 首部，那\n么新请求中那些首部的值必须与旧的已缓存请求里相应的首部相同。因为服务器可能会根据\n客户端请求的首部来改变响应，为了实现透明协商，缓存必须为每个已缓存变体保存客户端\n请求首部和相应的服务器响应首部。\n\n### 转码\n\n如果服务器没有能满足客户端需求的文档会怎么样呢?服务器可以给出一个错误响应。但理\n论上，服务器可以把现存的文档转换成某种客户端可用的文档。这种选项称为转码。\n\n#### 格式转换\n\n格式转换是指将数据从一种格式转换成另一种格式，使之可以被客户端查看。\n\n- 通过 HTML 到 WML 的转换，无线设备就可以访问通常供桌面客户端查看的文档了。\n- 通过慢速连接访问 Web 页面的客户端并不需要接收高分辨率图像，如果通过格式转换降\n  低图像分辨率和颜色来减小图像文件大小的话，这类客户端就能更容易地查看图像比较丰\n  富的页面了。\n\n格式转换可以由内容协商首部集来驱动，但也能由 User-Agent 首部来驱动。\n\n#### 信息综合\n\n从文档中提取关键的信息片段称为信息综合(information synthesis)，这是一种有用的转\n码操作。这种操作的例子包括根据小节标题生成文档的大纲，或者从页面中删除广告和商标\n。\n\n根据内容中的关键字对页面分类是更精细的技术，有助于总结文档的精髓。这种技术常用于\nWeb 页面分类系统中，比如门户网站的 Web 页面目录。\n\n#### 内容注入\n\n前面描述的两类转码通常会减少 Web 文档的内容，但还有另一类转换会增加文档的内容，\n即内容注入转码。\n\n内容注入转码的例子有自动广告生成器和用户追踪系统。\n\n#### 转码与静态预生成的对比\n\n转码的替代做法是在 Web 服务器上建立 Web 页面的不同副本，例如一个是 HTML，一个是\nWML; 一个图像分辨率高，一个图像分辨率低; 一个有多媒体内容，一个没有。\n\n对单一的根页面进行即时转换，是比静态的预生成更容易的解决方案。不过有时候其中一些\n计算可以由第三方进行，这样就减少了 Web 服务器上的计算负荷——比如可以由代理或缓存\n中的外部 Agent 完成转换。\n\n### 下一步计划\n\n- HTTP 中的内容协商受到一些性能方面的限制。在各种变体中搜索合适的内容，或尽力“猜\n  测”最佳匹配，都会有很大开销。有没有什么办法能专注内容协商协议以使这个过程更高\n  效? RFC 2295 和 RFC2296 尝试着对这个问题进行了研究，以提供透明的 HTTP 内容协商\n  。\n\n- HTTP 不是唯一需要进行内容协商的协议。在其他一些情况下，客户端也需要和服务器交\n  互以便获得对客户端请求来说最好的答案，流媒体和传真就是另外两个 例子。能否在\n  TCP/IP 应用层协议之上开发出通用的内容协商协议呢?内容协商工作组(Content\n  Negotiation Working Group)就是专门为这个问题而成立的。这个工作组目前已经停止工\n  作了，不过它提出了若干个 RFC。\n\n### 更多信息\n\n- http://www.ietf.org/rfc/rfc2616.txt\n\nRFC 2616，“Hypertext Transfer Protocol-HTTP/1.1”(“超文本传输协议 HTTP/1.1”)，这\n是 HTTP 协议的当前版本，也是 HTTP/1.1 的官方规范。这份规范行文流畅、 组织良好，\n是份详实的 HTTP 参考文献。不过对那些希望学习 HTTP 背后的各种 概念和决策动机、弄\n清理论与实践不同之处的读者来说，它就不是很理想了。我们希望本书能补足背后的这些概\n念，使读者能更好地利用这份规范。\n\n- http://www.ietf.org/rfc/rfc2295.txt\n\nRFC 2295，“Transparent Content Negotiation in HTTP”(“HTTP 中的透明内容协 商”)，\n这是一份备忘录，描述了建立在 HTTP 之上的透明内容协商协议。这份备忘录目前还是实验\n性的。\n\n- http://www.ietf.org/rfc/rfc2296.txt\n\nRFC 2296,“HTTP Remote Variant Selection Algorithm RVSA 1.0”(“HTTP 远程变体选择算\n法 RVSA1.0”)，这份备忘录描述了为特定的 HTTP 请求透明地选择“最佳”内容的算法。这份\n备忘录目前还是实验性的。\n\n- http://www.ietf.org/rfc/rfc2936.txt\n\nRFC 2936,“HTTP MIME Type Handler Detection”(“HTTP MIME 类型处理器检 测”)，这份备\n忘录描述了一种用来判定浏览器支持的 MIME 类型处理器的方法。如果 Accept 首部不够明\n确的话，这种方法就能派上用场。\n\n- http://www.imc.org/ietf-medfree/index.htm\n\n这个链接指向内容协商(简称 CONNEG)工作组网站。该工作组专注于 HTTP、 传真和打印方\n面的透明内容协商。这个工作组目前已停止工作。\n",
    "date": "2020-06-09",
    "id": 43,
    "slug": "http-content-negotiation",
    "title": "HTTP 内容协商与转码"
  },
  {
    "author": "Gao",
    "content": "## 国际化\n\n每天有上亿的人用数百种语言写着各种文档。为了真正实现万维网的目标，HTTP 要能够传\n输和处理用多种语言和字母表编写的国际性文档。\n\n### HTTP 对国际性内容的支持\n\n服务器通过 HTTP 协议的 Content-Type 首部中的 charset 参数和 Content- Language 首\n部告知客户端文档的字母表和语言。\n\n客户端发送 Accept-Charset 首部和 Accept-Language 首部，告知服务器 它理解哪些字符\n集编码算法和语言以及其中的优先顺序。\n\n下面的 HTTP 报文中的这些 Accept 首部可能是母语为法语的人发出的。他喜欢 使用母语\n，但也会说一点儿英语，他的浏览器支持 iso-8859-1 西欧字符集编码和 UTF-8 Unicode\n字符集编码:\n\n```http\nAccept-Language: fr, en;q=0.8\nAccept-Charset: iso-8859-1, utf-8\n```\n\n参数“q=0.8”是质量因子(quality factor)，说明英语的优先级(0.8)比法语低 (默认值是\n1.0)。\n\n### 字符集与 HTTP\n\n#### 字符集是把字符转换为二进制码的编码\n\nHTTP 字符集的值说明如何把实体内容的二进制码转换为特定字母表中的字符。每个字符集\n标记都命名了一种把二进制码转换为字符的算法(反之亦然)。字符集标记在由 IANA 维护\n([参见](http://www.iana.org/assignments/character-sets))的 MIME 字 符集注册机构\n进行了标准化。\n\n#### 字符集和编码如何工作\n\n把二进制码转换为字符要经过两个步骤\n\n- 文档中的二进制码被转换成字符代码，它表示了特定编码字符集中某个特定编号的字符。\n- 字符代码用于从编码的字符集中选择特定的元素。\n\n![](http-i18n/how-charset-work.png)\n\n#### 标准化的 MIME charset 值\n\n特定的字符编码方案和特定的已编码字符集组合成一个 MIME 字符集(MIME charset)。\nHTTP 在 Content-Type 和 Accept-Charset 首部中使用标准化的 MIME charset 标记。\nMIME charset 的值都会在 IANA 注册。\n\n#### Content-Type 首部和 Charset 首部以及 META 标志\n\nWeb 服务器通过在 Content-Type 首部中使用 charset 参数把 MIME 字符集标记发送给客\n户端:\n\n```http\nContent-Type: text/html; charset=gb2312\n```\n\n对于 HTML 内容来说， 可以在描述 charset 的\n\n```html\n<meta http-equiv=\"Content-Type\" />\n```\n\n标记中找到字符集。\n\n#### Accept-Charset 首部\n\nHTTP 客户端可以使用 Accept-Charset 请求首部来明确告知服务器它支持哪些字 符系统。\nAccept-Charset 首部的值列出了客户端支持的字符编码方案。\n\n```http\nAccept-Charset: iso-8859-1, utf-8\n```\n\n### 多语言字符编码入门\n\n对于工作中要开发大量国际化应用的 HTTP 程序员来说，为了能理解技术规范和相应的实现\n软件，需要深入地理解多语言字符系统。\n\n#### Terminology\n\n电子化字符系统的 8 个术语\n\n- 字符\n\n字符是指字母、数字、标点、表意文字(比如汉语)、符号，或其他文本形式的书写“原子”。\n由统一字符集(Universal Character Set，UCS, 它的非正式的名字是 Unicode3)首创，为\n多种语言中的很多字符开发了一系列标准化的文本名称，它们常用来便捷地命名字符，而且\n不会与其他字符冲突。\n\n- 字形\n\n描述字符的笔画图案或唯一的图形化形状。如果一个字符有多种不同的写法，就 有多个字\n形(参见图 16-3)。\n\n- 编码后的字符\n\n分配给字符的唯一数字编号，这样我们就可以操作它了。\n\n- 代码空间\n\n计划用于字符代码值的整数范围。\n\n- 代码宽度\n\n每个(固定大小的)字符代码所用的位数。\n\n- 字符库\n\n特定的工作字符集(全体字符的一个子集)。\n\n- 编码后的字符集\n\n组成字符库(从全球的字符中选出若干字符)的已编码字符集，并为每个字符 分配代码空间\n中的一个代码。换句话说，它把数字化的字符代码映射为实际的 字符。\n\n- 字符编码方案\n\n把数字化的字符代码编码成一系列二进制码(并能相应地反向解码)的算法。字 符编码方案\n可用来减少识别字符所需要的数据总量(压缩)、解决传输限制、统 一重叠编码字符集。\n\n### 语言标记与 Http\n\n语言标记是命名口语的标准化字符串短语。\n\n#### Content-Language 首部\n\n实体的 Content-Language 首部字段描述实体的目标受众语言。\n\n```http\nContent-Language: zh-CN\n```\n\nContent-Language 首部不仅限于文本文档。音频片段、电影以及应用程序都有可 能是面向\n特定语言受众的。任何面向特定语言受众的媒体类型都可以有 Content- Language 首部。\n\n如果内容是面向多种语言受众的，可以列出多种语言。\n\n```http\nContent-Language: zh-CN, zh-TW, zh-HK\n```\n\n#### Accept-Language 首部\n\nHTTP 允许我们把语言方面的限制和优先选择都发送给网站服务器。如果网站服务器有以多\n种语言表示的资源版本，它就能把内容用我们最优选的语言表示出来。\n\n    服务器也可以根据 Accept-Language 首部生成适合用户语言的动态内容，或据此选择图像，或选择适合目标语言的商业促销等。\n\n#### 语言标记的类型\n\n在 RFC3066，“Tags for the Identification of Languages”(标识语言的标记)中记录了语\n言标记的标准化语法。\n\n可以用语言标记来表示:\n\n- 一般的语言分类(比如 es 代表西班牙语);\n- 特定国家的语言(比如 en-GB 代表英国英语);\n- 语言的方言(比如 no-bok 指挪威的书面语);\n- 地区性的语言(比如 sgn-US-MA 代表美国马撒葡萄园岛上的手语);\n- 标准化的非变种语言(比如 i-navajo);\n- 非标准的语言(比如 x-snowboarder-slang)。\n\n#### 子标记\n\n语言标记有一个或多个部分，用连字号分隔，称为子标记:\n\n- 第一个子标记称为主子标记，其值是标准化的;\n- 第二个子标记是可选的，遵循它自己的命名标准;\n- 其他尾随的子标记都是未注册的。\n\n主子标记中只能含有字母(A ~ Z)。其后的子标记可以含有字母和数字，长度最多 8 个字符\n。\n\nExample:\n\n```text\n马撒葡萄园岛上的手语\n\nsgn-US-MA\n\nsgn -> 第一个子标记 （手语）\nUS -> 第二个子标记 （美国）\nMA -> 第三个子标记 （马萨诸塞州的地区性变体）\n\n```\n\n#### 大小写\n\n所有的标记都是不区分大小写的，也就是说，标记 en 和 eN 是等价的。但是，习惯上用全\n小写来表示一般的语言，而用全大写来表示特定的国家。\n\n#### IANA 语言标记注册\n\n第一个和第二个语言子标记的值由各种标准文档以及相关的维护组织定义。 IANA20 依据\nRFC 3066 中概括的规则来管理标准的语言标记列表。\n\n如果语言标记由标准的国家和语言值组成，标记就不需要专门注册。只有那些无法 用标准\n的国家和语言值构成的语言标记才需要专门向 IANA 注册 21。\n\n#### 第一个子标记--名字空间\n\n第一个子标记通常是标准化的语言记号，选自 ISO 639 中的语言标准集合。不过也可以用\n字母 i 来标识在 IANA 中注册的名字，或用 x 表示私有的或者扩展的名字。\n\n- 2 个字符，那就是来自 ISO 63922 和 639-1 标准的语言代码;\n- 3 个字符，那就是来自 ISO 639-2 标准及其扩展的语言代码;\n- 字母 i，该语言标记是在 IANA 显式注册的;\n- 字母 x，该语言标记是私有的、非标准的，或扩展的子标记。\n\n#### 第二个子标记--名字空间\n\n第二个子标记通常是标准化的国家记号，选自 ISO 3166 中的国家代码和地区标准集合。不\n过也可以是在 IANA 注册过的其他字符串。\n\n- 2 个字符，那就是 ISO 3166 中定义的国家 / 地区;\n- 3~8 个字符，可能是在 IANA 中注册的值;\n- 单个字符，这是非法的情况。\n\n#### 其余子标记--名字空间\n\n除了最长可以到 8 个字符(字母和数字)之外，第三个和其后的子标记没有特殊规则。\n\n### 国际化的 URI\n\n直到今天，URI 还没有为国际化提供足够的支持。\n\n#### 全球性的可转抄能力与有意义的字符的较量\n\nURI 的设计者们希望世界上每个人都能通过电子邮件、电话、公告板，甚至无线电来共享\nURI。他们还希望 URI 容易使用和记忆，但这两个目标是相互冲突的。\n\nURI 的设计者们觉得确保资源标识符的可转抄能力(transcribability)和共享能力比让它们\n由最有意义的字符组成更加重要，因此(如今的)URI 基本上是由 ASCII 字符的受限子集构\n成的。\n\n#### URI 字符集合\n\nURI 中允许出现的 US-ASCII 字符的子集，可以被分成保留、未保留以及转义字符 这几类\n。\n\n未保留的字符可用于 URI 允许其出现的任何部分。保留的字符在很多 URI 中都有特殊的含\n义，因此一般来说不能使用它们。\n\n| 字符类别 | 字符列表                        |\n| -------- | ------------------------------- |\n| 未保留   | [A-Za-z0-9] - \\_ . ! ~ \\* ' ( ) |\n| 保留     | ; / ? : @ & = \" \\$ ,            |\n| 转义     | %<hex><hex>                     |\n\n#### 转义国际化字符\n\n需要注意的是，要转义的值本身应该在 US-ASCII 代码值的范围内(0 ~ 127)。\n\n#### URI 中的模态切换\n\n有些 URI 也用 ASCII 字符的序列来表示其他字符集中的字符。这在一些本地化的环境中可\n以工作，但这种方式没有进行良好的定义，而且没有标准化的方案来识别 URL 所使用的特\n定编码。\n\n### 其他需要考虑的地方\n\n#### 首部和不合规范的数据\n\nHTTP 首部必须由 US-ASCII 字符集中的字符构成。不过，并不是所有的客户端和服务器都\n正确地实现了这一点，你可能会时不时收到一些代码值大于 127 的非法字符。\n\n#### 日期\n\nHTTP 的规范中明确定义了合法的 GMT 日期格式，但要知道并非所有 Web 服务器和客户端\n都遵守这些规则。\n\n例如，我们曾见过 Web 服务器发送的无效 HTTP Date (日期)首部中的月份是用本地语言表\n示的。\n\nHTTP 应用程序应当尝试容忍一些不合规矩的日期，不能在接收的时候崩溃。\n\n#### 域名\n\nDNS 目前还不支持在域名中使用国际化的字符。现在正在进行支持多语言的域名的相关标准\n化工作，但还没有被广泛部署。\n\n实际国际化域名应该是你用 IDN 来编码，但是在本地 mDNS 时，可能会发送非 ascii 字符\n。\n\n### 更多信息\n\n#### 互联网的国际化\n\n- http://www.w3.org/International/\n\n“Making the WWW Truly World Wide”(“使 WWW 真正遍布全球”)——W3C 国际化和本地化网站\n。\n\n- http://www.ietf.org/rfc/rfc2396.txt\n\nRFC 2396，“Uniform Resource Identifiers(URI):Generic Syntax”(“统一资源 描述符:一\n般语法”)，是 URI 的定义文档。该文档中包括了描述国际化 URI 中 的字符集限制方面的\n章节。\n\n- CJKV Information Processing(《中日韩越信息处理》)\n\nKen Lunde 著，由 O'Reilly & Associates 公司出版。CJKV 是亚洲语言的电子化 字符处\n理方面的权威经典。亚洲语言的字符集多种多样、复杂难懂，但这本书详 细介绍了大型字\n符集的各种标准技术。\n\n- http://www.ietf.org/rfc/rfc2277.txt\n\nRFC 2277，“IETF Policy on Character Sets and Languages”(“IETF 关于字符集 和语言\n的策略”)，其中记录了互联网工程指导组(Internet Engineering Steering Group，IESG)\n应用的当前策略，这些策略是为了配合互联网工程任务组 (Internet Engineering Task\nForce，IETF)帮助各种互联网协议使用多种语言和字符交换数据而做的标准化努力。\n\n#### 国际标准\n\n- http://www.iana.org/numbers.htm\n\nIANA 中有已注册的各种名字和数字编号的库。其中的 Protocol Numbers and Assignments\nDirectory(协议编号和分配目录)中包含了因特网上使用的已注册 字符集记录。因为有关国\n际间通信的大部分工作都是在 ISO 的领域内，而不是因 特网的团体完成的，所以 IANA 的\n这份列表算不上详尽。\n\n- http://www.ietf.org/rfc/rfc3066.txt\n\nRFC 3066，“Tags for the Identification of Languages”(“标识语言的标记”)，描 述了\n语言标记、它们的值，以及如何构造这些标记。\n\n- “Codes for the representation of names of languages”(“表示语言名称的代码”)\n\nISO 639:1988 (E/F)，国际标准化组织，第 1 版。\n\n- “Codes for the representation of names of languages—Part 2: Alpha-3 code”(“表\n  示语言名称的代码，第 2 部分:Alpha-3 代码”)\n\nISO 639-2:1998，ISO TC46/SC4 和 TC37/SC2 联合工作组，第 1 版。\n\n- “Codes for the representation of names of countries”(“表示国家名称的代码”)\n\nISO 3166:1988 (E/F)，国际标准化组织，第 3 版。\n",
    "date": "2020-06-09",
    "id": 42,
    "slug": "http-i18n",
    "title": "HTTP 国际化"
  },
  {
    "author": "Gao",
    "content": "## 实体和编码\n\n报文是箱子，实体是货物\n\n- Example\n\n```http\nhttp/1.0 200 ok\nserver: GWS\nContent-Type: text/plain\nContent-length: 18\n\nHi! I'm a message!\n```\n\n从 Content-type 开始到结束都是实体， header 部分是实体首部， body 部分是实体主体\n\nHTTP 实体首部描述了 HTTP 报文的内容。 HTTP/1.1 版定义了以下 10 个基本字体首部字\n段。\n\n- Content-Type 实体中所承载对象的类型。\n- Content-Length 所传送实体主体的长度或大小。\n- Content-Language 与所传送对象最相配的人类语言。\n- Content-Encoding 对象数据所做的任意变换(比如，压缩)。\n- Content-Location 一个备用位置，请求时可通过它获得对象。\n- Content-Range 如果这是部分实体，这个首部说明它是整体的哪个部分。\n- Content-MD5 实体主体内容的校验和。\n- Last-Modified 所传输内容在服务器上创建或最后修改的日期时间。\n- Expires 实体数据将要失效的日期时间。\n- Allow 该资源所允许的各种请求方法，例如，GET 和 HEAD。\n- ETag 这份文档特定实例(参见 15.7 节)的唯一验证码。ETag 首部没有正式定义为实 体\n  首部，但它对许多涉及实体的操作来说，都是一个重要的首部。\n- Cache-Control 指出应该如何缓存该文档。和 ETag 首部类似，Cache-Control 首部也没\n  有正 式定义为实体首部。\n\n### 确定实体主体长度的规则\n\n1. 如果特定的 HTTP 报文类型中不允许带有主体，就忽略 Content-Length 首 部，它是对\n   (没有实际发送出来的)主体进行计算的。这种情况下，Content- Length 首部是提示性\n   的，并不说明实际的主体长度。(考虑不周的 HTTP 应用 程序会认为有了\n   Content-Length 就有主体存在，这样就会出问题。)\n\n最重要的例子就是 HEAD 响应。HEAD 方法请求服务器发送等价的 GET 请 求中会出现的首\n部，但不要包括主体。因为对 GET 的响应会带有 Content- Length 首部，所以 HEAD 响应\n里面也有;但和 GET 响应不同的是，HEAD 响应中不会有主体。1XX、204 以及 304 响应也\n可以有提示性的 Content- Length 首部，但是也都没有实体主体。那些规定不能带有实体\n主体的报文， 不管带有什么首部字段，都必须在首部之后的第一个空行终止。\n\n2. 如果报文中含有描述传输编码的 Transfer-Encoding 首部(不采用默认的 HTTP“恒等”编\n   码)，那实体就应由一个称为“零字节块”(zero-byte chunk) 的特殊模式结束，除非报文\n   已经因连接关闭而结束。我们将在本章后面讨论传 输编码和分块编码。\n\n3. 如果报文中含有 Content-Length 首部(并且报文类型允许有实体主体)，而且没有非恒\n   等的 Transfer-Encoding 首部字段，那么 Content-Length 的值就是主体的长度。如果\n   收到的报文中既有 Content-Length 首部字段又有非恒等的 Transfer-Encoding 首部字\n   段，那就必须忽略 Content-Length，因为 传输编码会改变实体主体的表示和传输方式(\n   因此可能就会改变传输的字节数\n\n4. 如果报文使用了 multipart/byteranges(多部分 / 字节范围)媒体类型，并且没有用\n   Content-Length 首部指出实体主体的长度，那么多部分报文中的每个部 分都要说明它\n   自己的大小。这种多部分类型是唯一的一种自定界的实体主体类 型，因此除非发送方知\n   道接收方可以解析它，否则就不能发送这种媒体类型。\n\n- 因为 Range 首部可能会被不理解多部分 / 字节范围的更原始的代理所转发，所以如果发\n  送方不能确 定接收方是否理解这种自定界的格式的话，就必须用本节的方法(1)、(3)或\n  (5)来对报文定界。\n\n5. 如果上面的规则都不匹配，实体就在连接关闭的时候结束。实际上，只有服务 器可以使\n   用连接关闭来指示报文的结束。客户端不能用关闭连接来指示客户端\n\n- 客户端可以使用半关闭，也就是只把连接的输出端关闭，但很多服务器应用程序设计的时\n  候没有考虑 到处理这种情况，会把半关闭当作客户端要从服务器断开连接来处理。HTTP\n  没有对连接管理进行良 好的规范。详情请参见第 4 章。\n\n### 媒体类型和字符集\n\nContent-Type 首部字段说明了实体主体的 MIME 类型。 MIME 类型是标准化的名字，用以\n说明作为货物运载实体的基本媒体类型。客户端应用程序使用 MIME 类型来解释和处理其\n内容。\n\nContent-Type 的值是标准化的 MIME 类型，都在互联网号码分配机构(Internet Assigned\nNumbers Authority，简称 IANA)中注册。 MIME 类型由一个主媒体类 型(比如\n:text、image 或 audio 等)后面跟一条斜线以及一个子类型组成，子类 型用于进一步描述\n媒体类型。\n\n### 内容编码\n\n![](http-entities-encoding/content-encoding.jpg)\n\n#### 内容编码类型\n\nHTTP 定义了一些标准的内容编码类型，并允许用扩展编码的形式增添更多的编码。由互联\n网号码分配机构(IANA)对各种编码进行标准化，它给每个内容编码算法分 配了唯一的代号\n。\n\n- gzip RFC1952 gzip 编码\n- compress Unix 文件压缩\n- deflate RFC1950 和 1951 讲解 zlib 和 deflate\n- identity 没有编码\n\n#### Accept-Encoding\n\n为了避免服务器使用客户端不支持的编码方式，客户端就把自己支持的内容编码方式列表放\n在请求的 Accept-Encoding 首部里发出去。如果 HTTP 请求中没有包含 Accept-Encoding\n首部，服务器就可以假设客户端能够接受任何编码方式(等价 于发送 Accept-Encoding:\n\\*)。\n\nExample:\n\n```http\nAccept-Encoding: compress, gzip\nAccept-Encoding:\nAccept-Encoding: *\nAccept-Encoding: compress;q=0.5, gzip;q=1.0\nAccept-Encoding: gzip;q=1.0, identity; q=0.5, *;q=0\n```\n\nQ 值的范围从 0.0 到 1.0，0.0 说明客户端不想接受所说明的编码，1.0 则表明最希望使\n用的编码。 “\\*”表示“任何其他方法”。\n\n### 传输编码和分块编码\n\n传输编码也是作用在实体主体上的可逆变换，但使用它们是由 于架构方面的原因，同内容\n的格式无关。\n\n![](http-entities-encoding/transfer-encoding.png)\n\n#### 可靠传输\n\n- 未知尺寸如果不先生成内容，某些网关应用程序和内容编码器就无法确定报文主体的最终\n  大小。通常，这些服务器希望在知道大小之前就开始传输数据。因为 HTTP 协议 354 要\n  求 Content-Length 首部必须在数据之前，有些服务器就使用传输编码来发送数据，并用\n  特别的结束脚注表明数据结束。\n- 安全性你可以用传输编码来把报文内容扰乱，然后在共享的传输网络上发送。\n\n#### Transfer-Encoding Headers\n\n- Transfer-Encoding 告知接收方为了可靠地传输报文，已经对其进行了何种编码。\n- TE 用在请求首部中，告知服务器可以使用哪些传输编码扩展。\n\n请求使用了 TE 首部来告诉服务器它可以接受分块编码(如果是 HTTP/1.1 应用程序的话，\n这就是必须的)并且愿意接受附在分块编码的报文结尾上的拖挂:\n\n```http\nGET /new_products.html HTTP/1.1\nHost: www.gsmiot.com\nUser-Agent: Mozilla/4.61 [en] (WinNT; I)\nTE: trailers, chunked\n...\n```\n\n#### 分块编码\n\n分块编码把报文分割为若干个大小已知的块。块之间是紧挨着发送的，这样就不需要在发送\n之前知道整个报文的大小了。\n\n![](http-entities-encoding/chunked.png)\n\n### 随时间变化的实例\n\nHTTP 协议规定了称为实例操控(instance manipulations)的一系列请求和响应操 作，用以\n操控对象的实例。两个主要的实例操控方法是范围请求和差异编码。这两 种方法都要求客\n户端能够标识它所拥有(如果有的话)的资源的特定副本，并在一定的条件下请求新的实例。\n\n### 验证码和新鲜度\n\n服务器应当告知客户端能够将内容缓存多长时间，在这个时间之内就是新鲜的。服务器可以\n用这两个首部之一来提供这种信息:\n\n- Expires(过期)\n- Cache- Control(缓存控制)\n\n#### 有条件的请求与验证码\n\n| 请求类型            | 验证码        | 描述                                                                                     |\n| ------------------- | ------------- | ---------------------------------------------------------------------------------------- |\n| If-Modified-Since   | Last-Modified | 如果在前一条响应的 Last-Modified 首部中说明的 时间之后，资源的版本发生变化，就发送其副本 |\n| If-Unmodified-Since | Last-Modified | 仅在前一条响应的 Last-Modified 首部中说明的时 间之后，资源的版本没有变化，才发送其副本   |\n| If-Match            | ETag          | 如果实体的标记与前一次响应首部中的 ETag 相同， 就发送该资源的副本                        |\n| If-None-Match       | ETag          | 如果实体的标记与前一次响应首部中的 ETag 不同， 就发送该资源的副本                        |\n\n### 范围请求\n\n有了范围请求，HTTP 客户端可以通过请求曾获取失败的实体的一个范围(或者说 一部分)，\n来恢复下载该实体。\n\nExample:\n\n```http\nGET /bigfile.html HTTP/1.1\nHost: www.gsmiot.com\nRange: bytes=4000-\nUser-Agent: Mozilla/4.61 [en] (WinNT; I)\n...\n```\n\n对于客户端在一个请求内请求多个不同范围的情况，返回的响应也是单个实体，它有一个多\n部分主体及 Content-Type: multipart/byteranges 首部。\n\n服务器可以通过在响应中包含 Accept-Ranges 首部的形式向客户端说明可以接受的范围请\n求。这个首部的值是计算范围的单位，通常是以字节计算的。\n\n### 差异编码\n\n差异编码也是一类实例操控，因为它依赖客户端和服务器之间针对特定的对象实例来交换信\n息。RFC 3229 描述了差异编码。\n\n如果客户端想告诉服务器它愿意接受该页面的差异，只要发送 A-IM 首部就可以了。 A-IM\n是 Accept-Instance-Manipulation(接受实例操控)的缩写。形象比喻的话，客户端相当于\n这样说:“哦对了，我能接受某些形式的实例操控，如果你会其中一种的话，就不用发送完整\n的文档给我了。” 在 A-IM 首部中，客户端会说明它知道哪些算法可以把差异应用于老版本\n而得到最新版本。服务端发送回下面这些内容: 一个特殊的响应代码——226 IM Used，告知\n客户端它正在发送的是所请求对象的实例操控，而不是那个完整的对象自身; 一个\nIM(Instance-Manipulation 的缩写) 首部，说明用于计算差异的算法; 新的 ETag 首部和\nDelta-Base 首部，说明用于计算差异的基线文档的 ETag(理论上，它应该和客户端之前请\n求里的 If-None- Match 首部中的 ETag 相同!)。\n\n差异编码所用的首部\n\n| 首部          | 描述                                                                                                             |\n| ------------- | ---------------------------------------------------------------------------------------------------------------- |\n| ETag          | 文档每个实例的唯一标识符。由服务器在响应中发送;客户端在后继请求的 If-Match 首部和 If-None-Match 首部中可以使用它 |\n| If-None-Match | 客户端发送的请求首部，当且仅当客户端的文档版本与服务器不同时，才向服务 器请求该文档                              |\n| A-IM          | 客户端请求首部，说明可以接受的实例操控类型                                                                       |\n| IM            | 服务器响应首部，说明作用在响应上的实例操控的类型。当响应代码是 226 IM Used 时，会发送这个首部                    |\n| Delta-Base    | 服务器响应首部，说明用于计算差异的基线文档的 ETag 值(应当与客户端请求中的 If-None-Match 首部里的 ETag 相同)      |\n\n**实例操控、差异生成器和差异应用器**\n\n客户端可以使用 A-IM 首部说明可以接受的一些实例操控的类型。一些在 IANA 注册的实例\n操控类型。\n\n| 类型     | 说明                                                                        |\n| -------- | --------------------------------------------------------------------------- |\n| vcdiff   | 用 vcdiff 算法计算差异 (vcdiff 的规范由 RFC3284 发布)                       |\n| diffe    | 用 Unix 系统的 diff-e 命令计算差异                                          |\n| gdiff    | 用 gdiff 算法计算差异 [link](http://www.w3.org/TR/NOTE-gdiff-19970901.html) |\n| gzip     | 用 gzip 算法压缩                                                            |\n| deflate  | 用 deflate 算法压缩                                                         |\n| range    | 用在服务器的响应中，说明响应是针对范围选择得到的部分内容                    |\n| identity | 用在客户端请求中的 A-IM 首部中，说明客户端愿意接受恒等实例操控              |\n\n### 更多信息\n\n关于实体和编码方面的更多信息，请参考以下资源。\n\n- http://www.ietf.org/rfc/rfc2616.txt RFC 2616，也就是 HTTP/1.1 版的规范，是实体\n  主体管理和编码方面的主要参考。\n- http://www.ietf.org/rfc/rfc3229.txt RFC 3229，“Delta Encoding in HTTP”(“HTTP\n  中的差异编码”)，说明了如何通 过扩展 HTTP/1.1 来支持差异编码。\n- Introduction to Data Compression11(《数据压缩导论》) 这本书的作者是 Khalid\n  Sayood，出版商为 Morgan Kaufmann Publishers。该书介 绍了几种 HTTP 内容编码支持\n  的压缩算法。\n- http://www.ietf.org/rfc/rfc1521.txt RFC 1521，“Multipurpose Internet Mail\n  Extensions, Part One: Mechanisms for Specifying and Describing the Format of\n  Internet Message Bodies”(“ 多 用 途 因 特网邮件扩展，第一部分:规定和描述因特网\n  报文主体格式的机制”)，描述了 MIME 主体的格式。这份参考材料很有用，因为 HTTP 从\n  MIME 中借用了大量内容。设计这份文档的目的，就是为了提供在单一报文中包含多个对\n  象的各种设施，比如用 US-ASCII 之外的字符集来表示主体文本，表示多种字体格式的文\n  本消息以及表示非文本类的信息，比如图像和声音片段等。\n- http://www.ietf.org/rfc/rfc2045.txt RFC 2045，“Multipurpose Internet Mail\n  Extensions, Part One: Format of Internet Message Bodies”(“多用途因特网邮件扩展\n  ，第一部分:因特网报文主体的格 式”)，规定了用来描述 MIME 格式报文结构的各种首部\n  ，其中许多都和 HTTP 中的用法类似或相同。\n- http://www.ietf.org/rfc/rfc1864.txt RFC 1864，“The Content-MD5 Header\n  Field”(“Content-MD5 首部字段”)，提 供了用 Content-MD5 首部字段来做报文完整性检\n  查的行为及用途方面的一些历史 细节。\n- http://www.ietf.org/rfc/rfc3230.txt RFC 3230，“Instance Digests in HTTP”(“HTTP\n  中 的 实 例 摘 要 ”)， 描 述 了 对 HTTP 实体摘要处理的改进，解决了 Content-MD5\n  中存在的各种问题。\n",
    "date": "2020-06-09",
    "id": 41,
    "slug": "http-entities-encoding",
    "title": "HTTP 请求实体和编码"
  },
  {
    "author": "Gao",
    "content": "打算使用 xterm 来实现 ssh 的登陆功能\n\n需要实现终端的输入\n\n现在 debug 看到控制字符如下\n\n| 字符          | 十进制               | 行为                 |\n| ------------- | -------------------- | -------------------- |\n| \\r            | 13                   | 到行首               |\n| \\n            | 10                   | 下一行               |\n| \\x1B[1D\\x1B[J | 27,91,49,68,27,91,74 | 向前删除 1 个字符 ｜ |\n\n**其它一些控制字符**\n\n```txt\n# \\033 == 27 == \\x1B == \"ESC key\"\n\\33[0m 关闭所有属性\n\\33[01m 设置高亮度\n\\33[04m 下划线\n\\33[05m 闪烁\n\\33[07m 反显\n\\33[08m 消隐\n\\33[30m -- \\33[37m 设置前景色\n\\33[40m -- \\33[47m 设置背景色\n\\33[nA 光标上移n行\n\\33[nB 光标下移n行\n\\33[nC 光标右移n行\n\\33[nD 光标左移n行\n\\33[y;xH设置光标位置\n\\33[2J 清屏\n\\33[K 清除从光标到行尾的内容\n\\33[s 保存光标位置\n\\33[u 恢复光标位置\n\\33[?25l 隐藏光标\n\\33[?25h 显示光标\n```\n\n发现有些功能不支持，目前看应该是模拟终端类型为 vt100 导致的\n\n需要查询 term simulator 支持的类型做设置\n",
    "date": "2020-06-03",
    "id": 40,
    "slug": "term-control-char",
    "title": "xTerm中的控制模拟"
  },
  {
    "author": "Gao",
    "content": "调研相关软件\n\n- node-pty\n- xterm.js\n- blessed\n- ssh2\n\n### node-pty\n\n[链接](https://github.com/microsoft/node-pty)\n\nnode.js 的 forkpty（3） 绑定。这允许您使用伪终端文件描述符分叉进程。它返回允许读\n取和写入的终端对象。\n\n这对于：\n\n- 编写终端仿真器（例如通过 xterm.js）。\n- 让某些程序认为您是终端，例如当您需要程序向您发送控制序列时。\n\nnode-pty 支持 Linux、macOS 和 Windows。通过使用 Windows 1809+ 上的\n[Windows conpty API](https://blogs.msdn.microsoft.com/commandline/2018/08/02/windows-command-line-introducing-the-windows-pseudo-console-conpty/)\n或者旧版本中的[winpty](https://github.com/rprichard/winpty)，获得 Windows 支持。\n\n### xterm.js\n\n[链接](https://github.com/xtermjs/xterm.js)\n\nXterm.js 是一个在 TypeScript 中编写的前端组件，它允许应用程序在浏览器中为其用户\n带来功能齐全的终端。它被流行的项目，如 VS 代码，超级和 Theia 使用。\n\n#### **Feature**\n\n- Terminal apps just work: Xterm.js 可以通大多数终端 apps，比\n  如`bash`，`vim`和`tmux`，一起工作，这包含了 Curses-based 应用和鼠标事件支持。\n- 性能：Xterm.js 非常快速，它甚至包括了 GPU 加速渲染\n- 丰富的 unicode 支持：支持 CJK，emojis 和 IMEs\n- 自包含：没有任何依赖就可以运行\n- 无障碍：可以打开屏幕阅读器和最小对比度支持\n- 更多的：Links，therming，addons，优秀的 API 文档，等等\n\n#### What xterm.js is not\n\n- Xterm.js is not a terminal application that you can download and use on your\n  computer.\n- Xterm.js is not `bash`. Xterm.js can be connected to processes like `bash` and\n  let you interact with them (provide input, receive output).\n\n### blessed\n\n为 node.js 开发的一个带有高级终端接口的 curses-like library\n\n### ssh2\n\nSSH2 客户端和服务器模块以纯 JavaScript 编写的运行于 node.js.\n\n开发/测试针对 OpenSSH（当前为 7.6） 完成。\n\n## 设计实现\n\n最初设计实现是通过 websocket 服务打通浏览器到 server 之间的连接，使\n用`xterm.js`在浏览器创建 terminal UI，并使用`node-pty`在 server 打开对应的 shell\n来进行服务。\n\n这样只需要使用 web 做好认证就可以处理当前的问题。\n\n经过一番选择后，不希望直接连接服务器，所以更换了一种方式。\n\n在 web 服务器上启动一个`ss2`客户端代理，接入服务后，要求用户来输入用户的 ssh 登\n陆密码来进行登陆，对应服务器上需要启动 openssh-server。在浏览器启动 xterm.js 模\n拟终端，之后在浏览器和服务之间创建连接隧道，让终端和 ssh2 代理通讯。\n\n## SSH2 解析\n\n```txt\nssh2@0.8.9\n└─┬ ssh2-streams@0.4.10\n  ├─┬ asn1@0.2.4\n  │ └── safer-buffer@2.1.2\n  ├─┬ bcrypt-pbkdf@1.0.2\n  │ └── tweetnacl@0.14.5\n  └── streamsearch@0.1.2\n```\n\n- ssh2 提供 ssh Client/Server\n- ssh-streams 提供 ssh 传输流，包含加密解密和传输处理\n\n## SSH2 API\n\n`require('ssh2').Client` returns a **_Client_** constructor.\n\n`require('ssh2').Server` returns a **_Server_** constructor.\n\n`require('ssh2').utils` returns the\n[utility methods from `ssh2-streams`](https://github.com/mscdex/ssh2-streams#utility-methods).\n\n`require('ssh2').HTTPAgent` returns an\n[`http.Agent`](https://nodejs.org/docs/latest/api/http.html#http_class_http_agent)\nconstructor.\n\n`require('ssh2').HTTPSAgent` returns an\n[`https.Agent`](https://nodejs.org/docs/latest/api/https.html#https_class_https_agent)\nconstructor. Its API is the same as `HTTPAgent` except it's for HTTPS\nconnections.\n\n`require('ssh2').SFTP_STATUS_CODE` returns the\n[`SFTPStream.STATUS_CODE` from `ssh2-streams`](https://github.com/mscdex/ssh2-streams/blob/master/SFTPStream.md#sftpstream-static-constants).\n\n`require('ssh2').SFTP_OPEN_MODE` returns the\n[`SFTPStream.OPEN_MODE` from `ssh2-streams`](https://github.com/mscdex/ssh2-streams/blob/master/SFTPStream.md#sftpstream-static-constants).\n\n### Client\n\n#### Client events\n\n- **banner**(< _string_ >message, < _string_ >language) - A notice was sent by\n  the server upon connection.\n\n- **ready**() - Authentication was successful.\n\n- **tcp connection**(< _object_ >details, < _function_ >accept, <\n  _function_ >reject) - An incoming forwarded TCP connection is being requested.\n  Calling `accept` accepts the connection and returns a `Channel` object.\n  Calling `reject` rejects the connection and no further action is needed.\n  `details` contains:\n\n  - **srcIP** - _string_ - The originating IP of the connection.\n\n  - **srcPort** - _integer_ - The originating port of the connection.\n\n  - **destIP** - _string_ - The remote IP the connection was received on (given\n    in earlier call to `forwardIn()`).\n\n  - **destPort** - _integer_ - The remote port the connection was received on\n    (given in earlier call to `forwardIn()`).\n\n- **x11**(< _object_ >details, < _function_ >accept, < _function_ >reject) - An\n  incoming X11 connection is being requested. Calling `accept` accepts the\n  connection and returns a `Channel` object. Calling `reject` rejects the\n  connection and no further action is needed. `details` contains:\n\n  - **srcIP** - _string_ - The originating IP of the connection.\n\n  - **srcPort** - _integer_ - The originating port of the connection.\n\n- **keyboard-interactive**(< _string_ >name, < _string_ >instructions, <\n  _string_ >instructionsLang, < _array_ >prompts, < _function_ >finish) - The\n  server is asking for replies to the given `prompts` for keyboard-interactive\n  user authentication. `name` is generally what you'd use as a window title (for\n  GUI apps). `prompts` is an array of `{ prompt: 'Password: ', echo: false }`\n  style objects (here `echo` indicates whether user input should be displayed on\n  the screen). The answers for all prompts must be provided as an array of\n  strings and passed to `finish` when you are ready to continue. Note: It's\n  possible for the server to come back and ask more questions.\n\n- **unix connection**(< _object_ >details, < _function_ >accept, <\n  _function_ >reject) - An incoming forwarded UNIX socket connection is being\n  requested. Calling `accept` accepts the connection and returns a `Channel`\n  object. Calling `reject` rejects the connection and no further action is\n  needed. `details` contains:\n\n  - **socketPath** - _string_ - The originating UNIX socket path of the\n    connection.\n\n- **change password**(< _string_ >message, < _string_ >language, <\n  _function_ >done) - If using password-based user authentication, the server\n  has requested that the user's password be changed. Call `done` with the new\n  password.\n\n- **continue**() - Emitted when more requests/data can be sent to the server\n  (after a `Client` method returned `false`).\n\n- **error**(< _Error_ >err) - An error occurred. A 'level' property indicates\n  'client-socket' for socket-level errors and 'client-ssh' for SSH disconnection\n  messages. In the case of 'client-ssh' messages, there may be a 'description'\n  property that provides more detail.\n\n- **end**() - The socket was disconnected.\n\n- **close**() - The socket was closed.\n\n#### Client methods\n\n- **(constructor)**() - Creates and returns a new Client instance.\n\n- **connect**(< _object_ >config) - _(void)_ - Attempts a connection to a server\n  using the information given in `config`:\n\n  - **host** - _string_ - Hostname or IP address of the server. **Default:**\n    `'localhost'`\n\n  - **port** - _integer_ - Port number of the server. **Default:** `22`\n\n  - **localAddress** - _string_ - IP address of the network interface to use to\n    connect to the server. **Default:** (none -- determined by OS)\n\n  - **localPort** - _string_ - The local port number to connect from.\n    **Default:** (none -- determined by OS)\n\n  - **forceIPv4** - _boolean_ - Only connect via resolved IPv4 address for\n    `host`. **Default:** `false`\n\n  - **forceIPv6** - _boolean_ - Only connect via resolved IPv6 address for\n    `host`. **Default:** `false`\n\n  - **hostHash** - _string_ - Any valid hash algorithm supported by node. The\n    host's key is hashed using this algorithm and passed to the **hostVerifier**\n    function. **Default:** (none)\n\n  - **hostVerifier** - _function_ - Function with parameters\n    `(hashedKey[, callback])` where `hashedKey` is a string hex hash of the\n    host's key for verification purposes. Return `true` to continue with the\n    handshake or `false` to reject and disconnect, or call `callback()` with\n    `true` or `false` if you need to perform asynchronous verification.\n    **Default:** (auto-accept if `hostVerifier` is not set)\n\n  - **username** - _string_ - Username for authentication. **Default:** (none)\n\n  - **password** - _string_ - Password for password-based user authentication.\n    **Default:** (none)\n\n  - **agent** - _string_ - Path to ssh-agent's UNIX socket for ssh-agent-based\n    user authentication. **Windows users: set to 'pageant' for authenticating\n    with Pageant or (actual) path to a cygwin \"UNIX socket.\"** **Default:**\n    (none)\n\n  - **agentForward** - _boolean_ - Set to `true` to use OpenSSH agent forwarding\n    (`auth-agent@openssh.com`) for the life of the connection. `agent` must also\n    be set to use this feature. **Default:** `false`\n\n  - **privateKey** - _mixed_ - _Buffer_ or _string_ that contains a private key\n    for either key-based or hostbased user authentication (OpenSSH format).\n    **Default:** (none)\n\n  - **passphrase** - _string_ - For an encrypted private key, this is the\n    passphrase used to decrypt it. **Default:** (none)\n\n  - **localHostname** - _string_ - Along with **localUsername** and\n    **privateKey**, set this to a non-empty string for hostbased user\n    authentication. **Default:** (none)\n\n  - **localUsername** - _string_ - Along with **localHostname** and\n    **privateKey**, set this to a non-empty string for hostbased user\n    authentication. **Default:** (none)\n\n  - **tryKeyboard** - _boolean_ - Try keyboard-interactive user authentication\n    if primary user authentication method fails. If you set this to `true`, you\n    need to handle the `keyboard-interactive` event. **Default:** `false`\n\n  - **authHandler** - _function_ - Function with parameters\n    `(methodsLeft, partialSuccess, callback)` where `methodsLeft` and\n    `partialSuccess` are `null` on the first authentication attempt, otherwise\n    are an array and boolean respectively. Return or call `callback()` with the\n    name of the authentication method to try next (pass `false` to signal no\n    more methods to try). Valid method names are:\n    `'none', 'password', 'publickey', 'agent', 'keyboard-interactive', 'hostbased'`.\n    **Default:** function that follows a set method order: None -> Password ->\n    Private Key -> Agent (-> keyboard-interactive if `tryKeyboard` is `true`) ->\n    Hostbased\n\n  - **keepaliveInterval** - _integer_ - How often (in milliseconds) to send\n    SSH-level keepalive packets to the server (in a similar way as OpenSSH's\n    ServerAliveInterval config option). Set to 0 to disable. **Default:** `0`\n\n  - **keepaliveCountMax** - _integer_ - How many consecutive, unanswered\n    SSH-level keepalive packets that can be sent to the server before\n    disconnection (similar to OpenSSH's ServerAliveCountMax config option).\n    **Default:** `3`\n\n  - **readyTimeout** - _integer_ - How long (in milliseconds) to wait for the\n    SSH handshake to complete. **Default:** `20000`\n\n  - **sock** - _ReadableStream_ - A _ReadableStream_ to use for communicating\n    with the server instead of creating and using a new TCP connection (useful\n    for connection hopping).\n\n  - **strictVendor** - _boolean_ - Performs a strict server vendor check before\n    sending vendor-specific requests, etc. (e.g. check for OpenSSH server when\n    using `openssh_noMoreSessions()`) **Default:** `true`\n\n  - **algorithms** - _object_ - This option allows you to explicitly override\n    the default transport layer algorithms used for the connection. Each value\n    must be an array of valid algorithms for that category. The order of the\n    algorithms in the arrays are important, with the most favorable being first.\n    For a list of valid and default algorithm names, please review the\n    documentation for the version of `ssh2-streams` used by this module. Valid\n    keys:\n\n    - **kex** - _array_ - Key exchange algorithms.\n\n    - **cipher** - _array_ - Ciphers.\n\n    - **serverHostKey** - _array_ - Server host key formats.\n\n    - **hmac** - _array_ - (H)MAC algorithms.\n\n    - **compress** - _array_ - Compression algorithms.\n\n  - **compress** - _mixed_ - Set to `true` to enable compression if server\n    supports it, `'force'` to force compression (disconnecting if server does\n    not support it), or `false` to explicitly opt out of compression all of the\n    time. Note: this setting is overridden when explicitly setting a compression\n    algorithm in the `algorithms` configuration option. **Default:** (only use\n    compression if that is only what the server supports)\n\n  - **debug** - _function_ - Set this to a function that receives a single\n    string argument to get detailed (local) debug information. **Default:**\n    (none)\n\n**Default authentication method order:** None -> Password -> Private Key ->\nAgent (-> keyboard-interactive if `tryKeyboard` is `true`) -> Hostbased\n\n- **exec**(< _string_ >command[, < _object_ >options], < _function_ >callback) -\n  _boolean_ - Executes `command` on the server. Returns `false` if you should\n  wait for the `continue` event before sending any more traffic. `callback` has\n  2 parameters: < _Error_ >err, < _Channel_ >stream. Valid `options` properties\n  are:\n\n  - **env** - _object_ - An environment to use for the execution of the command.\n\n  - **pty** - _mixed_ - Set to `true` to allocate a pseudo-tty with defaults, or\n    an object containing specific pseudo-tty settings (see 'Pseudo-TTY\n    settings'). Setting up a pseudo-tty can be useful when working with remote\n    processes that expect input from an actual terminal (e.g. sudo's password\n    prompt).\n\n  - **x11** - _mixed_ - Set to `true` to use defaults below, set to a number to\n    specify a specific screen number, or an object with the following valid\n    properties:\n\n    - **single** - _boolean_ - Allow just a single connection? **Default:**\n      `false`\n\n    - **screen** - _number_ - Screen number to use **Default:** `0`\n\n    - **protocol** - _string_ - The authentication protocol name. **Default:**\n      `'MIT-MAGIC-COOKIE-1'`\n\n    - **cookie** - _mixed_ - The authentication cookie. Can be a hex _string_ or\n      a _Buffer_ containing the raw cookie value (which will be converted to a\n      hex string). **Default:** (random 16 byte value)\n\n- **shell**([[< _mixed_ >window,] < _object_ >options]< _function_ >callback) -\n  _boolean_ - Starts an interactive shell session on the server, with an\n  optional `window` object containing pseudo-tty settings (see 'Pseudo-TTY\n  settings'). If `window === false`, then no pseudo-tty is allocated. `options`\n  supports the `x11` and `env` options as described in `exec()`. `callback` has\n  2 parameters: < _Error_ >err, < _Channel_ >stream. Returns `false` if you\n  should wait for the `continue` event before sending any more traffic.\n\n- **forwardIn**(< _string_ >remoteAddr, < _integer_ >remotePort, <\n  _function_ >callback) - _boolean_ - Bind to `remoteAddr` on `remotePort` on\n  the server and forward incoming TCP connections. `callback` has 2 parameters:\n  < _Error_ >err, < _integer_ >port (`port` is the assigned port number if\n  `remotePort` was 0). Returns `false` if you should wait for the `continue`\n  event before sending any more traffic. Here are some special values for\n  `remoteAddr` and their associated binding behaviors:\n\n  - '' - Connections are to be accepted on all protocol families supported by\n    the server.\n\n  - '0.0.0.0' - Listen on all IPv4 addresses.\n\n  - '::' - Listen on all IPv6 addresses.\n\n  - 'localhost' - Listen on all protocol families supported by the server on\n    loopback addresses only.\n\n  - '127.0.0.1' and '::1' - Listen on the loopback interfaces for IPv4 and IPv6,\n    respectively.\n\n- **unforwardIn**(< _string_ >remoteAddr, < _integer_ >remotePort, <\n  _function_ >callback) - _boolean_ - Unbind from `remoteAddr` on `remotePort`\n  on the server and stop forwarding incoming TCP connections. Until `callback`\n  is called, more connections may still come in. `callback` has 1 parameter: <\n  _Error_ >err. Returns `false` if you should wait for the `continue` event\n  before sending any more traffic.\n\n- **forwardOut**(< _string_ >srcIP, < _integer_ >srcPort, < _string_ >dstIP, <\n  _integer_ >dstPort, < _function_ >callback) - _boolean_ - Open a connection\n  with `srcIP` and `srcPort` as the originating address and port and `dstIP` and\n  `dstPort` as the remote destination address and port. `callback` has 2\n  parameters: < _Error_ >err, < _Channel_ >stream. Returns `false` if you should\n  wait for the `continue` event before sending any more traffic.\n\n- **sftp**(< _function_ >callback) - _boolean_ - Starts an SFTP session.\n  `callback` has 2 parameters: < _Error_ >err, < _SFTPStream_ >sftp. For methods\n  available on `sftp`, see the\n  [`SFTPStream` client documentation](https://github.com/mscdex/ssh2-streams/blob/master/SFTPStream.md)\n  (except `read()` and `write()` are used instead of `readData()` and\n  `writeData()` respectively, for convenience). Returns `false` if you should\n  wait for the `continue` event before sending any more traffic.\n\n- **subsys**(< _string_ >subsystem, < _function_ >callback) - _boolean_ -\n  Invokes `subsystem` on the server. `callback` has 2 parameters: <\n  _Error_ >err, < _Channel_ >stream. Returns `false` if you should wait for the\n  `continue` event before sending any more traffic.\n\n- **end**() - _(void)_ - Disconnects the socket.\n\n- **openssh_noMoreSessions**(< _function_ >callback) - _boolean_ - OpenSSH\n  extension that sends a request to reject any new sessions (e.g. exec, shell,\n  sftp, subsys) for this connection. `callback` has 1 parameter: < _Error_ >err.\n  Returns `false` if you should wait for the `continue` event before sending any\n  more traffic.\n\n- **openssh_forwardInStreamLocal**(< _string_ >socketPath, <\n  _function_ >callback) - _boolean_ - OpenSSH extension that binds to a UNIX\n  domain socket at `socketPath` on the server and forwards incoming connections.\n  `callback` has 1 parameter: < _Error_ >err. Returns `false` if you should wait\n  for the `continue` event before sending any more traffic.\n\n- **openssh_unforwardInStreamLocal**(< _string_ >socketPath, <\n  _function_ >callback) - _boolean_ - OpenSSH extension that unbinds from a UNIX\n  domain socket at `socketPath` on the server and stops forwarding incoming\n  connections. `callback` has 1 parameter: < _Error_ >err. Returns `false` if\n  you should wait for the `continue` event before sending any more traffic.\n\n- **openssh_forwardOutStreamLocal**(< _string_ >socketPath, <\n  _function_ >callback) - _boolean_ - OpenSSH extension that opens a connection\n  to a UNIX domain socket at `socketPath` on the server. `callback` has 2\n  parameters: < _Error_ >err, < _Channel_ >stream. Returns `false` if you should\n  wait for the `continue` event before sending any more traffic.\n\n### Server\n\n#### Server events\n\n- **connection**(< _Connection_ >client, < _object_ >info) - A new client has\n  connected. `info` contains the following properties:\n\n  - **ip** - _string_ - The `remoteAddress` of the connection.\n\n  - **family** - _string_ - The `remoteFamily` of the connection.\n\n  - **port** - _integer_ - The `remotePort` of the connection.\n\n  - **header** - _object_ - Information about the client's header:\n\n    - **identRaw** - _string_ - The raw client identification string.\n\n    - **versions** - _object_ - Various version information:\n\n      - **protocol** - _string_ - The SSH protocol version (always `1.99` or\n        `2.0`).\n\n      - **software** - _string_ - The software name and version of the client.\n\n    - **comments** - _string_ - Any text that comes after the software\n      name/version.\n\n  Example: the identification string `SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2`\n  would be parsed as:\n\n```js\n        { identRaw: 'SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2',\n          version: {\n            protocol: '2.0',\n            software: 'OpenSSH_6.6.1p1'\n          },\n          comments: 'Ubuntu-2ubuntu2' }\n```\n\n#### Server methods\n\n- **(constructor)**(< _object_ >config[, < _function_ >connectionListener]) -\n  Creates and returns a new Server instance. Server instances also have the same\n  methods/properties/events as\n  [`net.Server`](http://nodejs.org/docs/latest/api/net.html#net_class_net_server).\n  `connectionListener` if supplied, is added as a `connection` listener. Valid\n  `config` properties:\n\n  - **hostKeys** - _array_ - An array of either Buffers/strings that contain\n    host private keys or objects in the format of\n    `{ key: <Buffer/string>, passphrase: <string> }` for encrypted private keys.\n    (**Required**) **Default:** (none)\n\n  - **algorithms** - _object_ - This option allows you to explicitly override\n    the default transport layer algorithms used for incoming client connections.\n    Each value must be an array of valid algorithms for that category. The order\n    of the algorithms in the arrays are important, with the most favorable being\n    first. For a list of valid and default algorithm names, please review the\n    documentation for the version of `ssh2-streams` used by this module. Valid\n    keys:\n\n    - **kex** - _array_ - Key exchange algorithms.\n\n    - **cipher** - _array_ - Ciphers.\n\n    - **serverHostKey** - _array_ - Server host key formats.\n\n    - **hmac** - _array_ - (H)MAC algorithms.\n\n    - **compress** - _array_ - Compression algorithms.\n\n  - **greeting** - _string_ - A message that is sent to clients immediately upon\n    connection, before handshaking begins. **Note:** Most clients usually ignore\n    this. **Default:** (none)\n\n  - **banner** - _string_ - A message that is sent to clients once, right before\n    authentication begins. **Default:** (none)\n\n  - **ident** - _string_ - A custom server software name/version identifier.\n    **Default:** `'ssh2js' + moduleVersion + 'srv'`\n\n  - **highWaterMark** - _integer_ - This is the `highWaterMark` to use for the\n    parser stream. **Default:** `32 * 1024`\n\n  - **debug** - _function_ - Set this to a function that receives a single\n    string argument to get detailed (local) debug information. **Default:**\n    (none)\n\n#### Connection events\n\n- **authentication**(< _AuthContext_ >ctx) - The client has requested\n  authentication. `ctx.username` contains the client username, `ctx.method`\n  contains the requested authentication method, and `ctx.accept()` and\n  `ctx.reject([< Array >authMethodsLeft[, < Boolean >isPartialSuccess]])` are\n  used to accept or reject the authentication request respectively. `abort` is\n  emitted if the client aborts the authentication request. Other\n  properties/methods available on `ctx` depends on the `ctx.method` of\n  authentication the client has requested:\n\n  - `password`:\n\n    - **password** - _string_ - This is the password sent by the client.\n\n  - `publickey`:\n\n    - **key** - _object_ - Contains information about the public key sent by the\n      client:\n\n      - **algo** - _string_ - The name of the key algorithm (e.g. `ssh-rsa`).\n\n      - **data** - _Buffer_ - The actual key data.\n\n    - **sigAlgo** - _mixed_ - If the value is `undefined`, the client is only\n      checking the validity of the `key`. If the value is a _string_, then this\n      contains the signature algorithm that is passed to\n      [`crypto.createVerify()`](http://nodejs.org/docs/latest/api/crypto.html#crypto_crypto_createverify_algorithm).\n\n    - **blob** - _mixed_ - If the value is `undefined`, the client is only\n      checking the validity of the `key`. If the value is a _Buffer_, then this\n      contains the data that is passed to\n      [`verifier.update()`](http://nodejs.org/docs/latest/api/crypto.html#crypto_verifier_update_data).\n\n    - **signature** - _mixed_ - If the value is `undefined`, the client is only\n      checking the validity of the `key`. If the value is a _Buffer_, then this\n      contains a signature that is passed to\n      [`verifier.verify()`](http://nodejs.org/docs/latest/api/crypto.html#crypto_verifier_verify_object_signature_signature_format).\n\n  - `keyboard-interactive`:\n\n    - **submethods** - _array_ - A list of preferred authentication\n      \"sub-methods\" sent by the client. This may be used to determine what (if\n      any) prompts to send to the client.\n\n    - **prompt**(< _array_ >prompts[, < _string_ >title[, < _string_\n      >instructions]], < _function_ >callback) - _boolean_ - Send prompts to the\n      client. `prompts` is an array of `{ prompt: 'Prompt text', echo: true }`\n      objects (`prompt` being the prompt text and `echo` indicating whether the\n      client's response to the prompt should be echoed to their display).\n      `callback` is called with `(err, responses)`, where `responses` is an\n      array of string responses matching up to the `prompts`.\n\n- **ready**() - Emitted when the client has been successfully authenticated.\n\n- **session**(< _function_ >accept, < _function_ >reject) - Emitted when the\n  client has requested a new session. Sessions are used to start interactive\n  shells, execute commands, request X11 forwarding, etc. `accept()` returns a\n  new _Session_ instance. `reject()` Returns `false` if you should wait for the\n  `continue` event before sending any more traffic.\n\n- **tcpip**(< _function_ >accept, < _function_ >reject, < _object_ >info) -\n  Emitted when the client has requested an outbound (TCP) connection. `accept()`\n  returns a new _Channel_ instance representing the connection. `reject()`\n  Returns `false` if you should wait for the `continue` event before sending any\n  more traffic. `info` contains:\n\n  - **srcIP** - _string_ - Source IP address of outgoing connection.\n\n  - **srcPort** - _string_ - Source port of outgoing connection.\n\n  - **destIP** - _string_ - Destination IP address of outgoing connection.\n\n  - **destPort** - _string_ - Destination port of outgoing connection.\n\n- **openssh.streamlocal**(< _function_ >accept, < _function_ >reject, <\n  _object_ >info) - Emitted when the client has requested a connection to a UNIX\n  domain socket. `accept()` returns a new _Channel_ instance representing the\n  connection. `reject()` Returns `false` if you should wait for the `continue`\n  event before sending any more traffic. `info` contains:\n\n  - **socketPath** - _string_ - Destination socket path of outgoing connection.\n\n- **request**(< _mixed_ >accept, < _mixed_ >reject, < _string_ >name, <\n  _object_ >info) - Emitted when the client has sent a global request for `name`\n  (e.g. `tcpip-forward` or `cancel-tcpip-forward`). `accept` and `reject` are\n  functions if the client requested a response. If `bindPort === 0`, you should\n  pass the chosen port to `accept()` so that the client will know what port was\n  bound. `info` contains additional details about the request:\n\n  - `tcpip-forward` and `cancel-tcpip-forward`:\n\n    - **bindAddr** - _string_ - The IP address to start/stop binding to.\n\n    - **bindPort** - _integer_ - The port to start/stop binding to.\n\n  - `streamlocal-forward@openssh.com` and\n    `cancel-streamlocal-forward@openssh.com`:\n\n    - **socketPath** - _string_ - The socket path to start/stop binding to.\n\n- **rekey**() - Emitted when the client has finished rekeying (either client or\n  server initiated).\n\n- **continue**() - Emitted when more requests/data can be sent to the client\n  (after a `Connection` method returned `false`).\n\n- **error**(< _Error_ >err) - An error occurred.\n\n- **end**() - The client socket disconnected.\n\n- **close**() - The client socket was closed.\n\n#### Connection methods\n\n- **end**() - _boolean_ - Closes the client connection. Returns `false` if you\n  should wait for the `continue` event before sending any more traffic.\n\n- **x11**(< _string_ >originAddr, < _integer_ >originPort, <\n  _function_ >callback) - _boolean_ - Alert the client of an incoming X11 client\n  connection from `originAddr` on port `originPort`. `callback` has 2\n  parameters: < _Error_ >err, < _Channel_ >stream. Returns `false` if you should\n  wait for the `continue` event before sending any more traffic.\n\n- **forwardOut**(< _string_ >boundAddr, < _integer_ >boundPort, <\n  _string_ >remoteAddr, < _integer_ >remotePort, < _function_ >callback) -\n  _boolean_ - Alert the client of an incoming TCP connection on `boundAddr` on\n  port `boundPort` from `remoteAddr` on port `remotePort`. `callback` has 2\n  parameters: < _Error_ >err, < _Channel_ >stream. Returns `false` if you should\n  wait for the `continue` event before sending any more traffic.\n\n- **openssh_forwardOutStreamLocal**(< _string_ >socketPath, <\n  _function_ >callback) - _boolean_ - Alert the client of an incoming UNIX\n  domain socket connection on `socketPath`. `callback` has 2 parameters: <\n  _Error_ >err, < _Channel_ >stream. Returns `false` if you should wait for the\n  `continue` event before sending any more traffic.\n\n- **rekey**([< _function_ >callback]) - _boolean_ - Initiates a rekeying with\n  the client. If `callback` is supplied, it is added as a one-time handler for\n  the `rekey` event. Returns `false` if you should wait for the `continue` event\n  before sending any more traffic.\n\n#### Session events\n\n- **pty**(< _mixed_ >accept, < _mixed_ >reject, < _object_ >info) - The client\n  requested allocation of a pseudo-TTY for this session. `accept` and `reject`\n  are functions if the client requested a response and return `false` if you\n  should wait for the `continue` event before sending any more traffic. `info`\n  has these properties:\n\n  - **cols** - _integer_ - The number of columns for the pseudo-TTY.\n\n  - **rows** - _integer_ - The number of rows for the pseudo-TTY.\n\n  - **width** - _integer_ - The width of the pseudo-TTY in pixels.\n\n  - **height** - _integer_ - The height of the pseudo-TTY in pixels.\n\n  - **modes** - _object_ - Contains the requested terminal modes of the\n    pseudo-TTY keyed on the mode name with the value being the mode argument.\n    (See the table at the end for valid names).\n\n- **window-change**(< _mixed_ >accept, < _mixed_ >reject, < _object_ >info) -\n  The client reported a change in window dimensions during this session.\n  `accept` and `reject` are functions if the client requested a response and\n  return `false` if you should wait for the `continue` event before sending any\n  more traffic. `info` has these properties:\n\n  - **cols** - _integer_ - The new number of columns for the client window.\n\n  - **rows** - _integer_ - The new number of rows for the client window.\n\n  - **width** - _integer_ - The new width of the client window in pixels.\n\n  - **height** - _integer_ - The new height of the client window in pixels.\n\n- **x11**(< _mixed_ >accept, < _mixed_ >reject, < _object_ >info) - The client\n  requested X11 forwarding. `accept` and `reject` are functions if the client\n  requested a response and return `false` if you should wait for the `continue`\n  event before sending any more traffic. `info` has these properties:\n\n  - **single** - _boolean_ - `true` if only a single connection should be\n    forwarded.\n\n  - **protocol** - _string_ - The name of the X11 authentication method used\n    (e.g. `MIT-MAGIC-COOKIE-1`).\n\n  - **cookie** - _string_ - The X11 authentication cookie encoded in\n    hexadecimal.\n\n  - **screen** - _integer_ - The screen number to forward X11 connections for.\n\n- **env**(< _mixed_ >accept, < _mixed_ >reject, < _object_ >info) - The client\n  requested an environment variable to be set for this session. `accept` and\n  `reject` are functions if the client requested a response and return `false`\n  if you should wait for the `continue` event before sending any more traffic.\n  `info` has these properties:\n\n  - **key** - _string_ - The environment variable's name.\n\n  - **value** - _string_ - The environment variable's value.\n\n- **signal**(< _mixed_ >accept, < _mixed_ >reject, < _object_ >info) - The\n  client has sent a signal. `accept` and `reject` are functions if the client\n  requested a response and return `false` if you should wait for the `continue`\n  event before sending any more traffic. `info` has these properties:\n\n  - **name** - _string_ - The signal name (e.g. `SIGUSR1`).\n\n- **auth-agent**(< _mixed_ >accept, < _mixed_ >reject) - The client has\n  requested incoming ssh-agent requests be forwarded to them. `accept` and\n  `reject` are functions if the client requested a response and return `false`\n  if you should wait for the `continue` event before sending any more traffic.\n\n- **shell**(< _mixed_ >accept, < _mixed_ >reject) - The client has requested an\n  interactive shell. `accept` and `reject` are functions if the client requested\n  a response. `accept()` returns a _Channel_ for the interactive shell.\n  `reject()` Returns `false` if you should wait for the `continue` event before\n  sending any more traffic.\n\n- **exec**(< _mixed_ >accept, < _mixed_ >reject, < _object_ >info) - The client\n  has requested execution of a command string. `accept` and `reject` are\n  functions if the client requested a response. `accept()` returns a _Channel_\n  for the command execution. `reject()` Returns `false` if you should wait for\n  the `continue` event before sending any more traffic. `info` has these\n  properties:\n\n  - **command** - _string_ - The command line to be executed.\n\n- **sftp**(< _mixed_ >accept, < _mixed_ >reject) - The client has requested the\n  SFTP subsystem. `accept` and `reject` are functions if the client requested a\n  response. `accept()` returns an _SFTPStream_ in server mode (see the\n  [`SFTPStream` documentation](https://github.com/mscdex/ssh2-streams/blob/master/SFTPStream.md)\n  for details). `reject()` Returns `false` if you should wait for the `continue`\n  event before sending any more traffic. `info` has these properties:\n\n- **subsystem**(< _mixed_ >accept, < _mixed_ >reject, < _object_ >info) - The\n  client has requested an arbitrary subsystem. `accept` and `reject` are\n  functions if the client requested a response. `accept()` returns a _Channel_\n  for the subsystem. `reject()` Returns `false` if you should wait for the\n  `continue` event before sending any more traffic. `info` has these properties:\n\n  - **name** - _string_ - The name of the subsystem.\n\n- **close**() - The session was closed.\n\n### Channel\n\nThis is a normal **streams2** Duplex Stream (used both by clients and servers),\nwith the following changes:\n\n- A boolean property `allowHalfOpen` exists and behaves similarly to the\n  property of the same name for `net.Socket`. When the stream's end() is called,\n  if `allowHalfOpen` is `true`, only EOF will be sent (the server can still send\n  data if they have not already sent EOF). The default value for this property\n  is `true`.\n\n- A `close` event is emitted once the channel is completely closed on both the\n  client and server.\n\n- Client-specific:\n\n  - For exec():\n\n    - An `exit` event _may_ (the SSH2 spec says it is optional) be emitted when\n      the process finishes. If the process finished normally, the process's\n      return value is passed to the `exit` callback. If the process was\n      interrupted by a signal, the following are passed to the `exit` callback:\n      null, < _string_ >signalName, < _boolean_ >didCoreDump, <\n      _string_ >description.\n\n    - If there was an `exit` event, the `close` event will be passed the same\n      arguments for convenience.\n\n    - A `stderr` property contains a Readable stream that represents output from\n      stderr.\n\n  - For shell() and exec():\n\n    - The readable side represents stdout and the writable side represents\n      stdin.\n\n    - **signal**(< _string_ >signalName) - _boolean_ - Sends a POSIX signal to\n      the current process on the server. Valid signal names are: 'ABRT', 'ALRM',\n      'FPE', 'HUP', 'ILL', 'INT', 'KILL', 'PIPE', 'QUIT', 'SEGV', 'TERM',\n      'USR1', and 'USR2'. Some server implementations may ignore this request if\n      they do not support signals. Note: If you are trying to send SIGINT and\n      you find `signal()` doesn't work, try writing `'\\x03'` to the Channel\n      stream instead. Returns `false` if you should wait for the `continue`\n      event before sending any more traffic.\n\n    - **setWindow**(< _integer_ >rows, < _integer_ >cols, < _integer_ >height, <\n      _integer_ >width) - _boolean_ - Lets the server know that the local\n      terminal window has been resized. The meaning of these arguments are\n      described in the 'Pseudo-TTY settings' section. Returns `false` if you\n      should wait for the `continue` event before sending any more traffic.\n\n- Server-specific:\n\n  - For exec-enabled channel instances there is an additional method available\n    that may be called right before you close the channel. It has two different\n    signatures:\n\n    - **exit**(< _integer_ >exitCode) - _boolean_ - Sends an exit status code to\n      the client. Returns `false` if you should wait for the `continue` event\n      before sending any more traffic.\n\n    - **exit**(< _string_ >signalName[, < _boolean_ >coreDumped[, < _string_\n      >errorMsg]]) - _boolean_ - Sends an exit status code to the client.\n      Returns `false` if you should wait for the `continue` event before sending\n      any more traffic.\n\n  - For exec and shell-enabled channel instances, `channel.stderr` is a writable\n    stream.\n\n### Pseudo-TTY settings\n\n- **rows** - < _integer_ > - Number of rows. **Default:** `24`\n\n- **cols** - < _integer_ > - Number of columns. **Default:** `80`\n\n- **height** - < _integer_ > - Height in pixels. **Default:** `480`\n\n- **width** - < _integer_ > - Width in pixels. **Default:** `640`\n\n- **term** - < _string_ > - The value to use for \\$TERM. **Default:** `'vt100'`\n\n- **modes** - < _object_ > - An object containing\n  [Terminal Modes](#terminal-modes) as keys, with each value set to each mode\n  argument. **Default:** `null`\n\n`rows` and `cols` override `width` and `height` when `rows` and `cols` are\nnon-zero.\n\nPixel dimensions refer to the drawable area of the window.\n\nZero dimension parameters are ignored.\n\n### Terminal modes\n\n| Name          | Description                                                                                                                     |\n| ------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n| VINTR         | Interrupt character; 255 if none. Similarly for the other characters. Not all of these characters are supported on all systems. |\n| VQUIT         | The quit character (sends SIGQUIT signal on POSIX systems).                                                                     |\n| VERASE        | Erase the character to left of the cursor.                                                                                      |\n| VKILL         | Kill the current input line.                                                                                                    |\n| VEOF          | End-of-file character (sends EOF from the terminal).                                                                            |\n| VEOL          | End-of-line character in addition to carriage return and/or linefeed.                                                           |\n| VEOL2         | Additional end-of-line character.                                                                                               |\n| VSTART        | Continues paused output (normally control-Q).                                                                                   |\n| VSTOP         | Pauses output (normally control-S).                                                                                             |\n| VSUSP         | Suspends the current program.                                                                                                   |\n| VDSUSP        | Another suspend character.                                                                                                      |\n| VREPRINT      | Reprints the current input line.                                                                                                |\n| VWERASE       | Erases a word left of cursor.                                                                                                   |\n| VLNEXT        | Enter the next character typed literally, even if it is a special character                                                     |\n| VFLUSH        | Character to flush output.                                                                                                      |\n| VSWTCH        | Switch to a different shell layer.                                                                                              |\n| VSTATUS       | Prints system status line (load, command, pid, etc).                                                                            |\n| VDISCARD      | Toggles the flushing of terminal output.                                                                                        |\n| IGNPAR        | The ignore parity flag. The parameter SHOULD be 0 if this flag is FALSE, and 1 if it is TRUE.                                   |\n| PARMRK        | Mark parity and framing errors.                                                                                                 |\n| INPCK         | Enable checking of parity errors.                                                                                               |\n| ISTRIP        | Strip 8th bit off characters.                                                                                                   |\n| INLCR         | Map NL into CR on input.                                                                                                        |\n| IGNCR         | Ignore CR on input.                                                                                                             |\n| ICRNL         | Map CR to NL on input.                                                                                                          |\n| IUCLC         | Translate uppercase characters to lowercase.                                                                                    |\n| IXON          | Enable output flow control.                                                                                                     |\n| IXANY         | Any char will restart after stop.                                                                                               |\n| IXOFF         | Enable input flow control.                                                                                                      |\n| IMAXBEL       | Ring bell on input queue full.                                                                                                  |\n| ISIG          | Enable signals INTR, QUIT, [D]SUSP.                                                                                             |\n| ICANON        | Canonicalize input lines.                                                                                                       |\n| XCASE         | Enable input and output of uppercase characters by preceding their lowercase equivalents with \"\\\".                              |\n| ECHO          | Enable echoing.                                                                                                                 |\n| ECHOE         | Visually erase chars.                                                                                                           |\n| ECHOK         | Kill character discards current line.                                                                                           |\n| ECHONL        | Echo NL even if ECHO is off.                                                                                                    |\n| NOFLSH        | Don't flush after interrupt.                                                                                                    |\n| TOSTOP        | Stop background jobs from output.                                                                                               |\n| IEXTEN        | Enable extensions.                                                                                                              |\n| ECHOCTL       | Echo control characters as ^(Char).                                                                                             |\n| ECHOKE        | Visual erase for line kill.                                                                                                     |\n| PENDIN        | Retype pending input.                                                                                                           |\n| OPOST         | Enable output processing.                                                                                                       |\n| OLCUC         | Convert lowercase to uppercase.                                                                                                 |\n| ONLCR         | Map NL to CR-NL.                                                                                                                |\n| OCRNL         | Translate carriage return to newline (output).                                                                                  |\n| ONOCR         | Translate newline to carriage return-newline (output).                                                                          |\n| ONLRET        | Newline performs a carriage return (output).                                                                                    |\n| CS7           | 7 bit mode.                                                                                                                     |\n| CS8           | 8 bit mode.                                                                                                                     |\n| PARENB        | Parity enable.                                                                                                                  |\n| PARODD        | Odd parity, else even.                                                                                                          |\n| TTY_OP_ISPEED | Specifies the input baud rate in bits per second.                                                                               |\n| TTY_OP_OSPEED | Specifies the output baud rate in bits per second.                                                                              |\n\n### HTTPAgent\n\n#### HTTPAgent methods\n\n- **(constructor)**(< _object_ >sshConfig[, < _object_ >agentConfig]) - Creates\n  and returns a new `http.Agent` instance used to tunnel an HTTP connection over\n  SSH. `sshConfig` is what is passed to `client.connect()` and `agentOptions` is\n  passed to the `http.Agent` constructor.\n",
    "date": "2020-05-27",
    "id": 39,
    "slug": "web-ssh",
    "title": "浏览器中使用Shell和SSH"
  },
  {
    "author": "Gao",
    "content": "### 简介\n\n`Socket.io`曾经是 websocket 持久连接的唯一选择，具有最好的浏览器兼容性。随着时间\n的推移，浏览器都已经支持 websocket 技术，这种持久连接库渐渐的淡出了。\n\n### 依赖模块\n\n```json\n\"debug\": \"~4.1.0\",\n\"engine.io\": \"~3.4.0\",\n\"has-binary2\": \"~1.0.2\",\n\"socket.io-adapter\": \"~1.1.0\",\n\"socket.io-client\": \"2.3.0\",\n\"socket.io-parser\": \"~3.4.0\"\n```\n\n#### 模块功能说明\n\n- engine.io Engine.IO 是 Socket.IO 实现基于传输的跨浏览器/跨设备双向通信层。\n\n- socket.io-adapter 用户管理用户和连接的默认适配器，如果启动 socket.io cluster，\n  可是使用 socket.io-redis\n\n- socket.io-client socket.io 客户端\n\n- socket.io-parser 用 JavaScript 编写的符合 socket.io-protocol 版本 4 的\n  socket.io 编码器和解码器。 由 socket.io 和 socket.io-client 使用。\n\n### 功能开发\n\n#### 使用接入认证\n\n实现方式是在建立连接的时候检查请求，可以同作配置功能来处理\n\n```js\nconst authorization = (request, cb) => {\n  console.log('==== athorization ====');\n  const {headers} = request;\n  const clientRequest = http\n    .get(\n      {\n        ...addr,\n        rejectUnauthorized: false,\n        headers: {\n          cookie: headers.cookie,\n        },\n      },\n      (res) => {\n        let buf = Buffer.from('');\n        res.on('data', (b) => {\n          buf = Buffer.concat([buf, b]);\n        });\n        res.on('end', (b) => {\n          const s = buf.toString('utf-8');\n          const d = JSON.parse(s);\n          if (d.role) {\n            cb(null, d.role);\n          } else {\n            cb(null);\n          }\n        });\n      },\n    )\n    .on('error', (e) => cb(e));\n};\n\nio.set('authorization', authorization);\n```\n\n同样也可以使用 io.use 来对请求做准入验证\n\n```js\nio.use((socket, next) => {\n  const {headers} = socket.request;\n  // do some check\n  checkHeaderInfo(headers)\n    .then(() => next())\n    .catch((e = new Error(e)));\n});\n```\n\n#### 连接复用与隔离\n\n当多个应用需要复用一条连接时，我们需要配置相关的隔离来处里对应的业务\n\nsocket.io 提供了两种方式做隔离\n\n1. namespace\n2. room\n\n##### namespace\n\n当前默认会有一个 namespace，默认的 namespace 调用位置为\n\n```js\nconst defaultNS = io.sockets || io.of('/');\n```\n\n每个 namespace 下都可以做单独的认证配置和创建自己的 room\n\nnamespace 可以在 client 控制\n\nclient 控制方式：\n\n```js\nconst socket = io('http://server.address', {path: 'socket'});\nconst nsSocket = socket.socket('/someNamespace');\n```\n\n##### room\n\n每个用户默认会加入一个名称为自己连接的 ID 的 room\n\n只能够在 server 加入 room，加入方式为:\n\n```js\nio.on('connection', (socket) => {\n  socket.join('soom room', (room) => {\n    console.log('join room success');\n  });\n});\n```\n\n### 官方文档\n\nSocket.io [地址](https://github.com/socketio/socket.io/blob/master/docs/API.md)\n\nSocket.io-client\n[地址](https://github.com/socketio/socket.io-client/blob/master/docs/API.md)\n",
    "date": "2020-05-26",
    "id": 38,
    "slug": "socket-io",
    "title": "SocketIO使用解析"
  },
  {
    "author": "Gao",
    "content": "最近配置了一个 DevOps 集群给前端使用，现在整理一下这个流程，和在做成碰到的问题\n\n### 安装\n\n#### 集群\n\n由于要配置多台服务器，安装使用离线安装，来减轻现在的负担\n\n下载好 k3s 和镜像包\n\n- master:\n\n```bash\ncp ./k3s /usr/local/bin/\ncp ./k3s-airgap-images-amd64.tar /var/lib/rancher/k3s/agent/images/\n\ncat ./install.sh | \\\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\n    sh -s - server \\\n    --cluster-domain=devops.local \\\n    --cluster-cidr=10.31.0.0/16 \\\n    --service-cidr=10.32.0.0/16 \\\n    --default-local-storage-path=/storage/volumes \\\n    --node-name=master \\\n    --docker\n```\n\n- backup:\n\n```bash\nmkdir -p /var/lib/rancher/k3s/agent/images/\ncp ./k3s-airgap-images-amd64.tar /var/lib/rancher/k3s/agent/images/\n\nexport K3S_TOKEN=\"{server-token}\"\nexport K3S_URL=\"https://{server-ip}:6443\"\n\ncat ./install.sh | \\\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\n    sh -s - agent \\\n    --docker \\\n    --node-name=slave \\\n```\n\n- ⚠️ 注意问题\n\n* 安装好后集群运行有问题，发现是 iptables 设置问题处理方式\n\n```bash\n# master\niptables -F && systemctl restart k3s\n# slave\niptables -F && systemctl restart k3s-agent\n```\n\n如果服务重启或者网络重启，可能会导致问题，也需要这么处理\n\n- 这里使用 docker 而没有使用 containerd 是因为网络环境有问题，rancher-agent 无法\n  运行导致的\n- 安装完成后禁止了在 master 运行任务，防止 master 负荷过大导致集群瘫痪\n  `kubectl taint node mymasternode node-role.kubernetes.io/master:NoSchedule`\n\n#### 安装 Rancher\n\n首先安装 helm，下载到 `/usr/local/bin/helm`\n\n安装 rancher\n\n```shell\nhelm repo add rancher  https://releases.rancher.com/server-charts/latest\nhelm repo update\nhelm install rancher rancher-stable/rancher --namespace cattle-system\n```\n\n配置好域名证书后，正常访问\n\n#### NFS\n\n希望集群能够共享数据，所以增加了 nfs 存储，可以在节点之间共享数据\n\n- 配置 NFS 服务器\n\n方便管理，将所有 export 都放入一个目录，真正的目录都通过`--bind`来绑定\n\n```shell\nmkdir -p /export/volumes\n# 配置权限\nchmod 777 -R /export\n\nmount --bind /home/nfs-data /export/volumes\n```\n\n在/etc/fstab 中添加\n\n```fstab\n/home/nfs-data    /export/volumes   none    bind  0  0\n```\n\n在`/etc/exports`中配置\n\n```exports\n/export/volumes 10.1.108.0/24(rw,nohide,subtree_check,insecure,all_squash,anonuid=0,async)\n\n/export 10.1.0.0/16(ro,fsid=0,root_squash,no_subtree_check,hide)\n```\n\n#### 安装 nfs-client-provisioner\n\n使用 helm 安装 nfs-client-provisioner，为集群提供动态存储\n\n```shell\nhelm install -n kube-system nfs-client-provisioner --set nfs.server={nfs-server-ip} --set nfs.path=/volumes stable/nfs-client-provisioner --set storageClass.name=nfs\n```\n\n#### 安装 Tekton\n\n配置安装 Tekton\n\n前置工作已经完成，使用 github 上的项目来安装\n\n下载目录下文件 `https://github.com/gsmlg/pipeline/tree/master/tektoncd`\n\n直接安装即可\n\n需要配置项目\n\n- ssh-key 配置 known_hosts 和 ssh-privatekey\n\n获取权限\n\n这个项目中定义了一个 pipeline，用于跑项目任务\n\n在 rancher 和 gitlab 配置好 eventlistener 的触发 URL，就可以自动运行当前的\npipeline 了\n\n### 总结问题\n\n过程中碰到 too many open files 的问题，修改 ulimit 解决\n\n测试网络和服务器不太稳定，经常连接不上，或者运行两个任务后，系统很卡，主要是虚拟\n平台给的性能严重不足\n\nnfs 服务器和集群机器之间网络有问题，导致无法共享存储，最后被迫使用了\nlocal-path，失去了共享存储的并行任务能力\n\n碰到 tekton 升级 0.12 版本，更新了 git 资源到 task 来实现共享工作空间\n\n给 nfs，tekton，rancher 增加了 toleration 和 affinity，将他们调度到 master，防止\nworker 过于繁忙，导致的无法服务问题\n",
    "date": "2020-05-12",
    "id": 37,
    "slug": "devops-cluster",
    "title": "DevOps集群"
  },
  {
    "author": "Gao",
    "content": "集群在运行几个任务后，突然无法启动\n\n排查过程 `k3s` 发现无法启动手动启动`k3s`，发现`docker`没有启动启动 docker，启\n动`k3s`，发现无法启动，打印超长的错误栈排查发现报错，`too many open files`\n\n检查系统配置\n\n```shell\n# ulimit -n\n1204\n\n# # 设置\n# ulimit -n 65535\n65535\n```\n\n编辑系统文件 /etc/security/limits.conf ，以保证重启后生效增加\n\n```text\n*               soft    nofile            65535\n*               hard    nofile            65535\n```\n\n如果需要不重启修改进程 ulimit， 需要在\n\n```\n/proc/<PID>/limits\n```\n\n中查看修改\n",
    "date": "2020-05-12",
    "id": 36,
    "slug": "k3s-errors-too-many-open-files",
    "title": "K3s集群无法启动错误排查 - too many open files"
  },
  {
    "author": "Gao",
    "content": "昨天给项目添加单元测试，发现`import`有大量的 missing\n\n检查返现问题：\n\n1. webpack 中有大量的`alias`导致\n2. webpack 中有`define plugin`，导致全局变量丢失\n3. webpack 中有`provide plugin`，导致一些没有被引入的变量出错\n\n进过一番调研，决定使用如下解决方式：\n\n使用 Babel 的 module resolver plugin 来处理这个问题\n\n所以，对整个项目做了一些调整\n\n将原先的`.babelrc`文件更换为`babel.config.js`\n\n添加 babel 插件`babel-plugin-module-resolver`,并将原先的 webpack 别名修改过来\n\n删除了 webpack 的 alias，添加了如下内容到 babel.config.js，由于路径会和 webpack\n相互交互，为了方便处理，所以使用了绝对路径\n\n```js\nplugins: [\n  [\n    'module-resolver',\n    {\n      root: [rootPath, path.join(rootPath, '/assets/javascripts')],\n      alias: {\n        plugins: path.join(zddiRoot, 'zddi/common/plugins'),\n        eve: path.join(zddiRoot, 'zddi/common/plugins/eve-raphael'),\n        raphael: path.join(zddiRoot, 'zddi/common/plugins/raphael/raphael.amd'),\n        i18n: `${zddiRoot}/i18n/i18n-data`,\n        common: path.join(zddiRoot, 'zddi/common'),\n        models: path.join(zddiRoot, 'zddi/common/models'),\n        views: path.join(zddiRoot, 'zddi/common/views'),\n        controller: path.join(zddiRoot, 'zddi/common/controller'),\n        utils: path.join(zddiRoot, 'zddi/common/utils'),\n        dashboard: path.join(zddiRoot, 'zddi/dashboard'),\n        address: path.join(zddiRoot, 'zddi/address'),\n        cloud: path.join(zddiRoot, 'zddi/cloud'),\n        am: path.join(zddiRoot, 'zddi/am'),\n        dns: path.join(zddiRoot, 'zddi/dns'),\n        secure: path.join(zddiRoot, 'zddi/secure'),\n        system: path.join(zddiRoot, 'zddi/system'),\n        jquery: path.join(zddiRoot, 'zddi/common/plugins/jquery'),\n        cell: path.join(zddiRoot, 'zddi/common/components/table/index'),\n      },\n    },\n  ],\n];\n```\n\n修改完成后发现问题，原先的 define plugin 的导入出了错误。原因是由于 template\nloader 没有用 babel 处理导致的，为了方便，我改了 provide plugin 的引入点，做了路\n径指向\n\n提交时发现问题，eslint 无法通过\n\n于是做了修改，增加了两个插件\n\n- `eslint-plugin-jest`\n- `eslint-import-resolver-babel-module`\n\n修改配置后支持 jest 全局变量和使用 babel module resolver 来检查当前的包含关系\n",
    "date": "2020-04-09",
    "id": 35,
    "slug": "move-alias-from-webpack-to-babel",
    "title": "使用Babel的来代替webpack别名"
  },
  {
    "author": "Gao",
    "content": "## 如何停止 erlang VM\n\n当你需要停止一个 Erlang VM 的时候，如果你不知道怎么做？这里有 10 种方式介绍如何\n停止\n\n### 比较好的方式\n\n1. q/0, c:q/0, init:stop/0\n\n最简单和直接的方式是使用`q/0`或者`c:q/0`（实际相同），就像文档种的一样\n\n```\nThis function is shorthand for init:stop(), that is, it causes the node to stop in a controlled fashion.\n```\n\n`init:stop/0` :\n\n```\nThe same as stop(0).\n```\n\n所以，最直接的方式就是运行`init:stop(0)`。要明白这个指令如何运行，我们可以检查文\n档：\n\n```\nAll applications are taken down smoothly, all code is unloaded,\nand all ports are closed before the system terminates by calling halt(Status).\nIf command-line flag -heart was specified, the heartprogram is terminated before the Erlang node terminates.\nFor more information, see heart(3).\n\nTo limit the shutdown time, the time init is allowed to spend taking down applications,\ncommand-line flag -shutdown_time is to be used.\n```\n\n所以这种方式是最直接的终止方式。\n\n2. erlang:halt/0\n\n向上边的文档中提到的一样，`erlang:halt()`和`erlang:halt(0,[])`。更多的内容可以看\n下边的`erlang:halt/1,2`，但是现在，`erlang:halt()` 只停止关闭 VM，不处理应用的终\n止和任何的端口关闭\n\n3. JCL mode\n\n先前的方式需要你能够链接到 erlang shell 才可以执行。如果你做不到，或者是 shell\n被阻止了该如何操作？如果你进入了 shell，但是无法输入，你可以指键\n入`Ctrl-g`([JCL mode](http://erlang.org/doc/man/shell.html#jcl-mode))\n\n这样操作的效果和`erlang:halt(0)`相同\n\n4. BREAK mode\n\n除了`Ctrl-g`，还可以使用`Ctrl-c`。这样会进入`*BREAK mode*`,样式如下：\n\n```\nBREAK: (a)bort (c)ontinue (p)roc info (i)nfo (l)oaded\n       (v)ersion (k)ill (D)b-tables (d)istribution\n```\n\n可以用两种方式关闭 erlang 节点：\n\n- Press **Ctrl-c** again\n- Press **a** and then return\n\n效果都和`erlang:halt(0)`一样\n\n### 不好的方式\n\n如果想要用一些不太好的方式来退出，并生成某些错误报告。那么，这些是可以做的选择……\n\n5. erlang:halt/1,2\n\n正如你看到\n的[这些文档](https://erldocs.com/current/erts/erlang.html?i=0&search=erlang:ha#halt/1)，\n`erlang:halt/1,2`可以提交一些选项并输出处理错误。可以看一下文档中的这些选项：\n\n- 如果你想要一个干净的关闭并且有一个合适的退出状态，使用整数比较好\n- 如果需要生成`erl_crash.dump`，使用一个`string`\n- 如果需要生成`core dump`，可以使用`atom` `abort`\n\n当然，无论选择什么，都不会终止任何 application 和官彬任何 ports，etc.\n\n6. Just kill it\n\nErlang VM 只是一个操作系统进程，在类 Unix 系统可以使用关闭进程的信号来关闭进程。\n不同的信号会给 Erlang VM 不同的处理。通常的信号：`kill -SIGTERM`的行为会\n和`init:stop()`一样。而`kill -SIGKILL`会和`erlang:halt(137)`一样\n\n还有一些其他的信号，生成`erl_crash.dump`: `kill -SIGUSR1`。\n\n### 最恶的方式\n\n关闭虚拟机的乐趣何在？让他们燃烧吧……\n\n7. Don't event let it start\n\n```\n$ erl -s something_that_doesnt_exist\nErlang/OTP 20 [erts-9.0] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:10] [kernel-poll:false]\n…\ninit terminating in do_boot ({undef,[{something_that_doesnt_exist,start,[],[]},{init,start_em,1,[]},{init,do_boot,3,[]}]})\nCrash dump is being written to: erl_crash.dump...done\n```\n\n8. Kill the Kernel\n\n```\n$ erl\nErlang/OTP 20 [erts-9.0] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:10] [kernel-poll:false]\n…\n1> exit(whereis(application_controller), kill).\ntrue\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n*** ERROR: Shell process terminated! ***\n{\"Kernel pid terminated\",application_controller,killed}\nKernel pid terminated (application_controller) (killed)\nCrash dump is being written to: erl_crash.dump...done\n```\n\n9. Exhaust the Atom Table\n\n```\n$ erl\nErlang/OTP 20 [erts-9.0] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:10] [kernel-poll:false]\n…\n1> [list_to_atom(integer_to_list(I)) || I <- lists:seq(erlang:system_info(atom_count), erlang:system_info(atom_limit))].\nno more index entries in atom_tab (max=1048576)\nCrash dump is being written to: erl_crash.dump...done\n```\n\n10. Turn off your Computer\n\n![laugh](stop-an-erlang-vm/evil-laugh.jpg)\n",
    "date": "2020-04-07",
    "id": 34,
    "slug": "stop-an-erlang-vm",
    "title": "终止erlang VM的10种方式"
  },
  {
    "author": "Gao",
    "content": "# 使用 `s2i` Build 镜像\n\n## 安装`s2i`\n\n- 使用 `go get`\n\n```shell\n$ go get github.com/openshift/source-to-image/cmd/s2i\n```\n\n- macOS 使用\n\n```shell\n$ brew install source-to-image\n```\n\n- Linux 使用\n\n在[版本发布页面](https://github.com/openshift/source-to-image/releases)找到对应\n链接下载\n\n```shell\ncurl -sSL https://github.com/openshift/source-to-image/releases/download/v1.1.14/source-to-image-v1.1.14-874754de-linux-amd64.tar.gz | tar zxf - -C /usr/local/bin/ './s2i'\n```\n\n- Windows 使用\n\n在[版本发布页面](https://github.com/openshift/source-to-image/releases)找到对应\n链接下载\n\n下载\n\n```\nhttps://github.com/openshift/source-to-image/releases/download/v1.1.14/source-to-image-v1.1.14-874754de-windows-amd64.zip\n```\n\n- 源码编译\n\n```shell\n$ go get github.com/openshift/source-to-image\n$ cd ${GOPATH}/src/github.com/openshift/source-to-image\n$ export PATH=$PATH:${GOPATH}/src/github.com/openshift/source-to-image/_output/local/bin/linux/amd64/\n$ hack/build-go.sh\n```\n\n## 使用`s2i`\n\n使用方式为：\n\n```shell\ns2i [source dir] [builder image] [built image name]\n```\n\n可用的 builder 镜像源码可以在 [Software Collection](https://github.com/sclorg)\n找到\n\n### 创建镜像 PHP 项目镜像\n\nPHP builder 镜像\n\n- centos/php-72-centos7\n- centos/php-71-centos7\n- centos/php-70-centos7\n- centos/php-56-centos7\n- centos/php-55-centos7\n\n创建 test-app 镜像\n\n```\ns2i build /root/s2i-php-test-app centos/php-72-centos7 my-test-app\n\ndocker run --rm -p 8080:8080 my-test-app\n\n```\n\n#### 配置运行时参数\n\n##### 给镜像配置以下环境变量可以作用于`php.ini`:\n\n- **ERROR_REPORTING**\n  - Informs PHP of which errors, warnings and notices you would like it to take\n    action for\n  - Default: E_ALL & ~E_NOTICE\n- **DISPLAY_ERRORS**\n  - Controls whether or not and where PHP will output errors, notices and\n    warnings\n  - Default: ON\n- **DISPLAY_STARTUP_ERRORS**\n  - Cause display errors which occur during PHP's startup sequence to be handled\n    separately from display errors\n  - Default: OFF\n- **TRACK_ERRORS**\n  - Store the last error/warning message in \\$php_errormsg (boolean)\n  - Default: OFF\n- **HTML_ERRORS**\n  - Link errors to documentation related to the error\n  - Default: ON\n- **INCLUDE_PATH**\n  - Path for PHP source files\n  - Default: .:/opt/app-root/src:/opt/rh/rh-php72/root/usr/share/pear (EL7)\n  - Default: .:/opt/app-root/src:/usr/share/pear (EL8, Fedora)\n- **PHP_MEMORY_LIMIT**\n  - Memory Limit\n  - Default: 128M\n- **SESSION_NAME**\n  - Name of the session\n  - Default: PHPSESSID\n- **SESSION_HANDLER**\n  - Method for saving sessions\n  - Default: files\n- **SESSION_PATH**\n  - Location for session data files\n  - Default: /tmp/sessions\n- **SESSION_COOKIE_DOMAIN**\n  - The domain for which the cookie is valid.\n  - Default:\n- **SESSION_COOKIE_HTTPONLY**\n  - Whether or not to add the httpOnly flag to the cookie\n  - Default: 0\n- **SESSION_COOKIE_SECURE**\n  - Specifies whether cookies should only be sent over secure connections.\n  - Default: Off\n- **SHORT_OPEN_TAG**\n  - Determines whether or not PHP will recognize code between <? and ?> tags\n  - Default: OFF\n- **DOCUMENTROOT**\n  - Path that defines the DocumentRoot for your application (ie. /public)\n  - Default: /\n\n##### 给镜像配置以下环境变量可以作用于`opcache.ini`:\n\n- **OPCACHE_MEMORY_CONSUMPTION**\n  - The OPcache shared memory storage size in megabytes\n  - Default: 128\n- **OPCACHE_REVALIDATE_FREQ**\n  - How often to check script timestamps for updates, in seconds. 0 will result\n    in OPcache checking for updates on every request.\n  - Default: 2\n\n##### 以下配置环境变量作用于 Apache 服务，运行于 Apache [MPM prefork](https://httpd.apache.org/docs/2.4/mod/mpm_common.html) 模式:\n\n- **HTTPD_START_SERVERS**\n  - The\n    [StartServers](https://httpd.apache.org/docs/2.4/mod/mpm_common.html#startservers)\n    directive sets the number of child server processes created on startup.\n  - Default: 8\n- **HTTPD_MAX_REQUEST_WORKERS**\n  - The\n    [MaxRequestWorkers](https://httpd.apache.org/docs/2.4/mod/mpm_common.html#maxrequestworkers)\n    directive sets the limit on the number of simultaneous requests that will be\n    served.\n  - `MaxRequestWorkers` was called `MaxClients` before version httpd 2.3.13.\n  - Default: 256 (this is automatically tuned by setting Cgroup limits for the\n    container using this formula: `TOTAL_MEMORY / 15MB`. The 15MB is average\n    size of a single httpd process.\n\n##### 以下配置环境变量作用于 composer:\n\n- **COMPOSER_MIRROR**\n  - Adds a custom composer repository mirror URL to composer configuration.\n    Note: This only affects packages listed in composer.json.\n- **COMPOSER_INSTALLER**\n  - Overrides the default URL for downloading Composer of\n    https://getcomposer.org/installer. Useful in disconnected environments.\n- **COMPOSER_ARGS**\n  - Adds extra arguments to the `composer install` command line (for example\n    `--no-dev`).\n\n#### 代码目录配置\n\n当以下文件在代码目录中时，会被使用：\n\n- **composer.json**\n\n  List of dependencies to be installed with `composer`. The format is documented\n  [here](https://getcomposer.org/doc/04-schema.md).\n\n* **.htaccess**\n\n  In case the **DocumentRoot** of the application is nested within the source\n  directory `/opt/app-root/src`, users can provide their own Apache\n  **.htaccess** file. This allows the overriding of Apache's behavior and\n  specifies how application requests should be handled. The **.htaccess** file\n  needs to be located at the root of the application source.\n\n* **.s2i/environment**\n\n  也可以用于配置环境变量\n\n### 创建 nodejs 项目镜像\n\n可用 builder 镜像\n\n- centos/nodejs-10-centos7\n- centos/nodejs-8-centos7\n- centos/nodejs-6-centos7\n\n#### 服务启动\n\n默认会调用 `npm start` 来启动服务\n\n当`DEV_MODE=true`时，默认会调用`nodemon <main attribute in package.json>`,来启动\n服务，如果失败再调用，`npm start` 来启动服务\n\n#### 可配置环境变量\n\n**`NODE_ENV`** NodeJS runtime mode (default: \"production\")\n\n**`DEV_MODE`** When set to \"true\", `nodemon` will be used to automatically\nreload the server while you work (default: \"false\"). Setting `DEV_MODE` to\n\"true\" will change the `NODE_ENV` default to \"development\" (if not explicitly\nset).\n\n**`NPM_RUN`** Select an alternate / custom runtime mode, defined in your\n`package.json` file's [`scripts`](https://docs.npmjs.com/misc/scripts) section\n(default: npm run \"start\"). These user-defined run-scripts are unavailable while\n`DEV_MODE` is in use.\n\n**`HTTP_PROXY`** Use an npm proxy during assembly\n\n**`HTTPS_PROXY`** Use an npm proxy during assembly\n\n**`NPM_MIRROR`** Use a custom NPM registry mirror to download packages during\nthe build process\n\n### 创建 go 项目镜像\n\n可用 builder 镜像\n\n- centos/go-toolset-7-centos7\n\n#### 配置运行时参数\n\n- **IMPORT_URL**\n\n指定应用的导入 URL，如 `github.com/someorg/somerepo`\n\n- **INSTALL_URL**\n\n如果`main.go`不在代码目录下时，指定 build 目录,如\n`github.com/someorg/somerepo/somefolder`\n\n### 创建 java 项目镜像\n\n由于 java 项目的多样性，建议进行定制\n",
    "date": "2019-08-15",
    "id": 33,
    "slug": "build-with-s2i",
    "title": "使用 s2i Build镜像"
  },
  {
    "author": "Gao",
    "content": "## `Source to Image`\n\n`Source-to-Image` (`s2i`) 是由`openshift`提供的一套从自动从代码构建到镜像的工具\n和流程。\n\nS2I 提供了一套镜像模版来对多种语言和矿建进行构建\n\n### 应用\n\n`s2i` 适用于将已有程序迁移到 docker 镜像。 `s2i`提供了各类的 builder 镜像，可以\n针对不同的应用快速的完成构建。用户不再需要在为应用编写 Dockerfile，也不再需要在\n构建过程中运行安装依赖程序 `s2i`可以对构建镜像进行版本管理，向控制代码仓库一样控\n制 build 环境 `s2i`提供了可以持续流程，可以进行递增的项目编译，从而大大减少构建\n时间\n\n### 原理\n\n`s2i`提供了 builder 镜像，提供了完整的编译运行环境。 `s2i`会把代码注入到 builder\n镜像中。在 builder 镜像中对源码进行处理，使其可以被运行。\n\n处理脚本：\n\n- assemble 执行 build\n- run 运行\n- save-artifacts 保存构建供后续使用 optional\n- usage 显示使用信息 optional\n\n### 创建 Builder 镜像\n\n为`singlecloud`创建一个镜像\n\n#### 安装`s2i`命令\n\n```shell\ncurl -sSL https://github.com/zdnscloud/s2i/releases/download/v1.0/s2i.tar.gz | tar zxf - -C /usr/local/bin/ s2i\n```\n\n#### 创建`s2i builder`模版\n\n```shell\ns2i create s2i-singlecloud sc\n# 进入模版目录\ncd sc\n```\n\n模版中提供了两个命令来处理\n\n- make build 构建 builder 镜像\n- make test 测试 builder 镜像\n\n##### 修改 Dockerfile 文件\n\n```Dockerfile\n# s2i-singlecloud\nFROM golang:1.12.5-alpine3.9\n\n# TODO: Put the maintainer name in the image metadata\n# LABEL maintainer=\"Your Name <your@email.com>\"\nLABEL maintainer=\"GSMLG <me@gsmlg.org>\"\n\n# TODO: Rename the builder environment variable to inform users about application you provide them\nENV BUILDER_VERSION 1.0\n\n# TODO: Set labels used in OpenShift to describe the builder image\nLABEL io.k8s.description=\"Platform for building singlecloud\" \\\n      io.k8s.display-name=\"singlecloud builder\" \\\n      io.openshift.expose-services=\"80:http\" \\\n      io.openshift.s2i.scripts-url=image:///usr/libexec/s2i \\\n      io.openshift.tags=\"builder,go,node\"\n\nUSER root\n# TODO: Install required packages here:\nRUN mkdir -p /go/src/github.com/zdnscloud/singlecloud && apk upate && apk add bash && rm -rf /var/cache/apk/\n\nWORKDIR /go/src/github.com/zdnscloud/singlecloud\n\n# TODO: Copy the S2I scripts to /usr/libexec/s2i, since openshift/base-centos7 image\n# sets io.openshift.s2i.scripts-url label that way, or update that label\nCOPY ./s2i/bin /usr/libexec/s2i\n\n# This default user is created in the openshift/base-centos7 image\n#USER 1001\n\n# TODO: Set the default port for applications built using this image\nEXPOSE 80\n\n# TODO: Set the default CMD for the image\nCMD [\"/usr/libexec/s2i/usage\"]\n```\n\n##### 修改`s2i/bin/assemble`\n\n```bash\n#!/bin/bash -e\n#\n# S2I assemble script for the 's2i-singlecloud-builder' image.\n# The 'assemble' script builds your application source so that it is ready to run.\n#\n# For more information refer to the documentation:\n#   https://github.com/openshift/source-to-image/blob/master/docs/builder_image.md\n#\n\n# If the 's2i-singlecloud' assemble script is executed with the '-h' flag, print the usage.\nif [[ \"$1\" == \"-h\" ]]; then\n    exec /usr/libexec/s2i/usage\nfi\n\n# Restore artifacts from the previous build (if they exist).\n#\nif [ \"$(ls /tmp/artifacts/ 2>/dev/null)\" ]; then\n  echo \"---> Restoring build artifacts...\"\n  mv /tmp/artifacts/. ./\nfi\n\necho \"---> Installing application source...\"\ncp -Rf /tmp/src/. ./\n\necho \"---> Building application from source...\"\n# TODO: Add build steps for your application, eg npm install, bundle install, pip install, etc.\ngo build cmd/singlecloud/singlecloud.go\nmv singlecloud /go/bin/\n```\n\n##### 修改`s2i/bin/run`\n\n```bash\n#!/bin/bash -e\n#\n# S2I run script for the 's2i-singlecloud-builder' image.\n# The run script executes the server that runs your application.\n#\n# For more information see the documentation:\n#   https://github.com/openshift/source-to-image/blob/master/docs/builder_image.md\n#\n\nexec /go/bin/singlecloud\n```\n\n#### 创建 builder 镜像\n\n```bash\nmake build\n```\n\n#### Build `singlecloud`\n\n```bash\ns2i build https://github.com/zdnscloud/singlecloud s2i-singlecloud singlecloud\n```\n\n#### 运行`singlecloud`\n\n```bash\ndocker run -p 8080:80 --rm singlecloud singlecloud -listen :80\n```\n",
    "date": "2019-08-15",
    "id": 32,
    "slug": "s2i",
    "title": "Source to Image"
  },
  {
    "author": "Gao",
    "content": "### 什么是 k3s？\n\nk3s 是微型的 kubernetes 发行版本\n\n1. CNCF 认证的 Kubernetes 发行版\n2. 50MB 左右二进制包，500MB 左右内存消耗\n3. 单一进程包含 Kubernetes master, Kubelet, 和 containerd\n4. 支持 SQLite/Mysql/PostgreSQL/DQlite 和 etcd\n5. 同时为 x86_64, Arm64, 和 Armv7 平台发布\n\n### k3s 基本架构\n\n#### 整体架构\n\n##### 部署架构\n\n![cc737ff7270d834dd8ca3e6efcc4509b.png](./k3s/cc737ff7270d834dd8ca3e6efcc4509b.png)\n\n轻量化\n\n相比 k8s 移除\n\n- 删除旧的和非必要的组件\n- alpha feature\n- In-tree cloud providers\n- In-tree storage strivers\n- Docker (optional)\n\n增加\n\n- 简单的安装\n- etcd 默认使用 SQLite 做数据源\n- TLS 管理\n- 自动 helm chart 管理\n- containerd、cordons、Flannel 集成\n\n##### k3s 代码结构\n\n![d7fece440f1c3f7c3a4333c3c924ebfd.png](./k3s/d7fece440f1c3f7c3a4333c3c924ebfd.png)\n\n注意事项：\n\n- contaienrd 是独立进程，也可以使用 docker\n- Tunnel Proxy 负责维护 k3s server 和 k3s agent 之间的链接，采用 Basic Auth 的方\n  式来进行认证\n\n##### Demo\n\nk3s 进程\n\n- server\n\n\\# 6443 k3s server, 6444 api-server\n\n- agent\n\n```\npstree -p -aT $pid\nps -T $pid\n```\n\n##### 参考链接\n\n- [k3s 代码组织结构分析参考](https://mp.weixin.qq.com/s/1o9X0Dlv2WhUS6iC9P-KQA)\n- [k3s 部署参考](https://mp.weixin.qq.com/s/V-VyWrCZux5WXxD__QpEWQ)\n- [k3s 为何轻量](https://mp.weixin.qq.com/s/5aprEfYSWJyVoW4trDp4Hw)\n\n#### k3s 的高可用架构\n\n![efddb62fd824b694d539d686cbdf5cbd.png](./k3s/efddb62fd824b694d539d686cbdf5cbd.png)\n\n![01a39ea3b8684c5889e69a1c625e8a95.png](./k3s/01a39ea3b8684c5889e69a1c625e8a95.png)\n\n![983420ce2dbc3d812c68639fae050dee.png](./k3s/983420ce2dbc3d812c68639fae050dee.png)\n\n##### 高可用 - 外置数据库\n\n- PostgreSQL (v10.7、v11.5) ü\n- MySQL (v5.7)\n- etcd (v3.3.15)\n\n实现方式： rancher/kine\n\n![fb719eff62e7da623289c06cf66e9f2e.png](./k3s/fb719eff62e7da623289c06cf66e9f2e.png)\n\n##### 高可用 - 分布数据库\n\n**SQLite**\n\n- 软件库，无独立进程:C 语言编写\n- 零管理配置:不需要服务管理进程\n- 事务安全:兼容 ACID，可并发访问\n- 标准 SQL 支持\n- 单一磁盘文件\n\nk3s 默认使用 `/var/lib/rancher/k3s/server/db/state.db`\n\n**Dqlite**\n\n- 软件库，无独立进程:C 语言编写\n- 分布式一致:C-Raft 实现\n- 兼容 SQLite\n\nDqlite 原理\n\n- 一个 k3sserver 进程内含 SQL 的 client 组 件和 server 组件\n- client 仅连接一个 server\n- server 链接 SQLite 软件库\n- 奇数个 k3sserver 进程\n- client 需连接所有 server\n- server 链接 Dqlite 软件库\n- server 通过 C-Raft 来选主\n- client 发现 主 server\n- client 把请求都发送到主 server\n- 主 server 通过 C-Raft 给从 server 发送差分日志作为数据同步\n\n![e8387ec04f8c4c9843d12e1c2c5659fb.png](./k3s/e8387ec04f8c4c9843d12e1c2c5659fb.png)\n\n##### 参考链接\n\n- [SQLite 基础命令](https://www.runoob.com/sqlite/sqlite-commands.html)\n- [SQLite Go 语言驱动实现](https://github.com/mattn/go-sqlite3)\n- [CGO 的动静态链接介绍](https://books.studygolang.com/advanced-go-programming-book/ch2-cgo/ch2-06-static-shared-lib.html)\n- [Dqlite 讲解](https://fosdem.org/2020/schedule/event/dqlite/)\n- [Raft 协议介绍](https://raft.github.io/)\n- [k3s 社区高可用介绍](https://mp.weixin.qq.com/s/3by95UIJ7v41KXElt7uvGA)\n\n#### Containerd\n\n`Containerd`的设计目的是嵌入更大的系统\n\nDocker 的历史\n\n- 1.8 之前:docker -d - 2015 年，OCI 成立\n- 1.8 - 1.11:docker daemon - runtime-spec 制定\n- 1.11 以后:docker、dockerd - libcontainer -> runC\n- dockerd = docker engine + containerd + containerd-shim + runC\n\n![a558aca87f7a8679d9fe1a2da820ec21.png](./k3s/a558aca87f7a8679d9fe1a2da820ec21.png)\n\n![5471d6d59bbe3ba83a514e23af38dcef.png](./k3s/5471d6d59bbe3ba83a514e23af38dcef.png)\n\n![1c7a968cb544086aaaa167819a26a1b0.png](./k3s/1c7a968cb544086aaaa167819a26a1b0.png)\n\n![33bede9601ebd8546cd7de980cc55135.png](./k3s/33bede9601ebd8546cd7de980cc55135.png)\n\n![1cc7615d71efe2799e6bbcd38bb3d718.png](./k3s/1cc7615d71efe2799e6bbcd38bb3d718.png)\n\n**操作**\n\n| 镜像操作       | Docker         | ContainerD         |\n| :------------- | :------------- | :----------------- | --------------------- |\n| 本地镜像列表   | docker images  | crictl images      | ctr images list       |\n| 下载镜像       | docker pull    | crictl pull        | ctr (images) pull     |\n| 上传镜像       | docker push    |                    | ctr (images) push     |\n| 删除本地镜像   | docker rmi     | crictl rmi         | ctr images remove     |\n| 标记本地镜像   | docker tag     |                    | ctr (images) tag      |\n| 镜像详情       | docker inspect | crictl inspecti    |\n| 容器列表       | docker ps      | crictl ps          | ctr containers list   |\n| 创建容器       | docker create  | crictl create      | ctr containers create |\n| 运行容器       | docker start   | crictl start       | ctr (tasks) start     |\n| 停止容器       | docker stop    | crictl stop        | ctr (tasks) pause     |\n| 删除容器       | docker rm      | crictl rm          | ctr (tasks) rm        |\n| 容器详情       | docker inspect | crictl inspect     |\n| 连接容器       | docker attach  | crictl attach      | ctr (tasks) attach    |\n| 容器内操作     | docker exec    | crictl exec        | ctr (tasks) exec      |\n| 容器日志       | docker logs    | crictl logs        |\n| 容器状态       | docker stats   | crictl stats       |\n| 显示 POD 列表  |                | crictl pods        |\n| 查看 POD 详情  |                | crictl inspectp    |\n| 运行 POD       |                | crictl runp        |\n| 停止 POD       |                | crictl stopp       |\n| 删除 POD       |                | crictl rmp         |\n| 转发端口到 POD |                | crictl port-foward |\n\nk3s 内置 containerd\n\n- ctr : 单纯的容器管理\n- crictl : 从 Kubernetes 视角出发，对 POD、容器进行管理\n\nk3s 修改 containerd 配置修\n改`/var/lib/rancher/k3s/agent/etc/containerd/config.toml`同目录\n下`config.toml.tmpl`文件，重启 k3s\n\ncontaienrd 日志 `/var/lib/rancher/k3s/agent/containerd/containerd.log`\n\n##### 参考链接\n\n- [cri 的演进史](https://zhuanlan.zhihu.com/p/87602649)\n- [runC 的介绍](https://www.infoq.cn/article/docker-standard-container-execution-engine-runc)\n- [k3s 社区 Containerd 使用介绍](https://mp.weixin.qq.com/s/EJqS7G36f7_srgxSZaCuPw)\n- [crictl 基本操作](https://github.com/kubernetes-sigs/cri-tools/blob/master/docs/crictl.md)\n- [Containerd CNI 插件配置介绍](https://github.com/containerd/cri/blob/master/docs/config.md)\n\n### k3s 拓展功能概览\n\n#### Helm Controller\n\n- k3s Helm Controller 同时支持 v2 与 v3 版本\n  - 从 v1.17.0+k3s1 or above 默认使用 helm_v3\n- Helm v2 vs Helm v3\n  - 移除了 Tiller(from SA to kubeconfig)\n  - 三方会谈 (Three-way Strategic merge patch)\n  - 使用 Secret 作为默认存储\n  - crd-install hook 迁移到了 crds/路径等...\n- Helm Controller 的优势\n\n  - 更方便的用户体验\n  - HelmChart CRD 可以支持更丰富的拓展\n\n**设计原理**\n\n1. Helm-controller 运行在 master 节点并 list/watch HelmChart CRD 对象\n2. CRD onChange 时执行 Job 更新\n3. Job Container 使用 rancher/kilipper-helm 为 entrypoint\n4. Killper-helm 内置 helm cli，可以安装/升级/删除对应的 chart\n\n```yaml\napiVersion: helm.cattle.io/v1\nkind: HelmChart\nmetadata:\n  name: traefik\n  namespace: kube-system\nspec:\n  chart: stable/traefik\n  set:\n    rbac.enabled: 'true'\n    ssl.enabled: 'true'\n```\n\n- K3s 会自动部署在/var/lib/rancher/k3s/server/manifests 路径下的 HelmChart\n- 通过 HelmChart CRD 部署的 chart 是兼容 helm v3 CLI 的\n- 在 k3s 中管理和部署 Helm 应用\n\n相关工具包 - rancher/helm-controller - rancher/kilipper-helm\n\n#### Traefik LB\n\nK3s 支持模块化的开启或关闭相关组件，例如 Traefik LB, Scheduler, servicelb 等\n\n- curl -sfL https://get.k3s.io | sh -s - server --no-deploy=traefik\n- k3s server --no-deploy=traefik --no-deploy=servicelb\n- 也可通过修改 k3s.service 配置然后重启生效\n\n##### Service LB Controller 设计原理\n\nService LB 是 Rancher 针对 k3s 集群而设计的一种 service loadbalancer\ncontroller，用户可通过将 Service 的 type 类似配置为 LoadBalancer 来使用。\n\n1. svc-controller watch 到 service 类型为 LoadBalancer 时，自动创建一个\n   Daemonset;\n2. 默认 Daemonset 会部署到每个节点，如果任意 Node 设定了 label\n   svccontroller.k3s.cattle.io/enablelb=true, 则只在拥有这个 label 的 node 上 创\n   建 DS 的 pod;\n3. 对于某个部署的节点，一个 LB port 只会对应一个 POD， 端口不能重复使 用;\n4. 若创建失败或无可用端口时，service 的状态为 Pending\n\n##### 本地存储\n\n- K3s 默认添加了 local path provisioner\n\n- Local path provisioner 是基于 Kubernetes Local Persistent Volume 功能实现的一\n  个本地动态存储管理器\n\n  - 默认 host path 路径为/var/lib/rancher/k3s/storage\n  - 配置文件存放在 kube-system 下的 local-path-config configmap\n  - 支持动态创建 host path volumes\n  - 不支持 capacity limit\n\n### k3s 与 GPU 结合使用\n\n#### 从 AI 视角看计算的三个层次\n\n云计算:\n\n- 最通用的计算\n- 算力要求高，实时性要求低\n- 执行复杂的认知计算和模型训练通用操作系统/海量 GPU 卡\n\n边缘计算\n\n- 连接云和端，针对端做特定 优化\n- 执行推理和数据融合处理通用操作系统/数量有限的 GPU 卡/专业 AI 芯片\n\n端计算\n\n- 场景相关性强\n- 极致效率，实时性要求高\n- 主要面向推理实时操作系统/专业 AI 芯片\n\n#### Kuberntes 正成为机器学习的主流基础设施平台\n\n![6d49f668d0984291ed581b816a9bf39a.png](./k3s/6d49f668d0984291ed581b816a9bf39a.png)\n\nk3s 的优势\n\n- K3s 足够轻量，减小边缘基础设施服务的资源占用\n- K3s 部署运维足够简单，用户可以专注 GPU 和计算框架的管理\n\n#### Docker 容器中的 GPU\n\n![63f55898dd5d0aef168da6dababbec7a.png](./k3s/63f55898dd5d0aef168da6dababbec7a.png)\n\n#### k3s 使用 GPU 设备的原理\n\n1. 操作系统安装支持 Nvidia Driver\n2. 安装容器运行时，并切换 runtime 到 nvidia\n3. K8s 通过 gpu-device-plugin 来获取 GPU 资源并记录在 k8s 中\n4. Pod 通过在 k8s 内申请 gpu 资源，kubelet 驱 动 runtime 把一定额度的 GPU 卡分配\n   给它\n\n```yaml\nresources:\n  limits:\n    nvidia.com/gpu: '1'\n```\n\n##### Demo 演示 GPU\n\n- 准备 GPU 主机，安装 cuda-drivers\n- 安装 nvidia-docker2\n- 安装 k3s\n- 安装 gpu-device-plugin\n- 测试 GPU workload\n\n#### 当前的问题和展望\n\n##### 容器中对 GPU 的资源分配还不太灵活\n\n- GPU 资源分配只能整数增减(可通过 Tensorflow 间接细化显存资源分配)\n- NVIDIA docker 不支持 vGPU(kubevirt 虚拟化方式可支持)\n\n##### AI 场景:云边文件传输的痛点\n\n- 边缘 AI 训练特点:海量小文件 IO 性能要求\n- 与云端同步数据的网络带宽消耗(断点续传)\n\n### K3s 的 IoT 场景管理\n\n#### 什么是边缘计算?\n\n边缘计算是指在靠近智能设备或数据源头的一端，提供`网络`、\n`存储`、`计算`、`应用`等能力，达到*更快的网络服务响应，更安 全的本地数据传输*。\n\n#### 边缘场景的 k8s 用例正在不断涌现\n\n- 1106 个有效问卷\n- 15%的受访者表示，正在把 Kubernetes 应用在边缘计算场景中\n- Chick-fil-A\n  [Link](https://medium.com/@cfatechblog/bare-metal-k8s-clustering-at-chick-fil-a-scale-7b0607bd3541)\n\n#### 边缘计算的问题与挑战\n\n- 边缘设备种类繁多\n- 繁琐的版本管理\n- 复杂的跨域环境\n- 成百上千部署在边缘侧的应用\n\n- 统一和可持续化迭代的管理 平台\n- 继承了强大的 k8s 社区和生 态\n- 边缘节点独立自制，云端系统统一管理\n\n#### k3s 云边协作模式\n\n![a4bdfa2ed0fbef25adc5c819ddf132d8.png](./k3s/a4bdfa2ed0fbef25adc5c819ddf132d8.png)\n\n![25851741f97501c67fef0e0a3c9551b0.png](./k3s/25851741f97501c67fef0e0a3c9551b0.png)\n\n#### k3s 案例\n\n![c219a97aa1e92f765e8c8c1662362845.png](./k3s/c219a97aa1e92f765e8c8c1662362845.png)\n\n![db52d9567d5d3b9cbf97f98c24c4a0cf.png](./k3s/db52d9567d5d3b9cbf97f98c24c4a0cf.png)\n\n#### K3s 与 IoT 设备管理\n\n![638a2d821645ae0ccd4071ad63da136c.png](./k3s/638a2d821645ae0ccd4071ad63da136c.png)\n\n![924c981a90322fe42990d2e538e46aa9.png](./k3s/924c981a90322fe42990d2e538e46aa9.png)\n\n1. 创建并纳管边缘 k3s 集群\n2. 部署 MQTT Broker 到 k3s 集群\n3. 创建、部署 IoT 设备相关的应用\n4. 基于 MQTT 实现设备联动\n\n### K3S 周边介绍\n\n#### 实例化 k3s 集群的工具\n\n- K3sup(https://github.com/alexellis/k3sup) - VM 实例中运行 k3s\n  - 具备隔离型，但依赖公有云服务\n- K3s-ansible(https://github.com/itwars/k3s-ansible)\n  - 依赖用户对机器环境访问权限\n  - 依赖 ansible\n- Multipass-k3s\n  - 依托 multipass 本身对虚拟机的管理\n\n#### K3d - 依托 Docker 的 k3s 管理工具\n\n[k3d 项目](https://github.com/rancher/k3d)\n\n- K3s 本身被置于容器中\n- 容器中类似是 Docker-in-Docker 原理(https://hub.docker.com/_/docker)\n- 实际是 k3s(containerd)-in-Docker\n- K3d 整合各种 use cases，方便通过 CLI 创建 k3s 集群\n\nK3d 带来的好处\n\n- 管理容器一样管理 k3s 集群\n- 给每个开发者本地 k3s 环境，方便调试应用\n- https://github.com/rancher/k3d/tree/master/docs\n\n#### 不可变基础设施\n\nImmutable Infrastructure\n\n![2229583e9c091f989762212a1eab143a.png](./k3s/2229583e9c091f989762212a1eab143a.png)\n\n##### VM 实现了早期的构想\n\n- VM 镜像过于笨重，且无法做版本控制\n- 对异构环境不友好\n- 用户习惯无法被约束，依然会在线进行部分更新操作\n\n##### 不可变基础设施 1.0 --- 容器技术(Docker)\n\n- 解决环境间差异问题\n- 快速回滚到老版本\n- 更好的进行 CI\n- 更好的自动化\n- 更容易进行大规模运维\n\n![6bdd28c497110a72bd3c98e694c0df9d.png](./k3s/6bdd28c497110a72bd3c98e694c0df9d.png)\n\n##### 不可变基础设施 2.0 -- Immutable OS\n\n硬件之上全部为 **“不可变”**\n\n更复杂更高级的云原生应用的更新，不仅仅依赖 RootFS 变更，更需要内核的同步更新。\n\n操作系统也应成为不可变基础设施的一部分，保证基础架构更高的一致性和可靠性，以及更\n加方便运维管理。\n\n![6fa8948e140aa39a937f4a508db479c4.png](./k3s/6fa8948e140aa39a937f4a508db479c4.png)\n\n##### Docker native 正在向 Kubernetes native 演变\n\nImmutable OS 也紧跟趋势\n\nImmutable OS for Docker:\n\n- RancherOS\n- Atomic\n- CoreOS\n- Photon OS\n\nImmutable OS for Kubernetes:\n\n- K3os\n- Bottlerocket-os\n- Talos\n\n##### K3os – An Immutable OS For App\n\n![0c5994ce907a7689185ec96b8b6d2f10.png](./k3s/0c5994ce907a7689185ec96b8b6d2f10.png)\n\n###### system-upgrade-controller\n\n- 使用 Kubernets 方式管理 OS 升降级\n- 未来会集成在 Rancher2.x 中\n\n#### k3c - Classic Docker for a Kubernetes world\n\n与 Docker 比\n\n1. 相似的交互\n2. singlebinary\n3. 同样内置 containerd 4. 更加轻量化\n\n与 Crictl 比\n\n1. 满足 CRI 规范\n2. 支持 image tag/push\n3. 支持 image build\n",
    "date": "2020-03-05",
    "id": 31,
    "slug": "k3s",
    "title": "全面了解k3s"
  },
  {
    "author": "Gao",
    "content": "# prow\n\n![prow](./prow/logo_horizontal_solid.png)\n\nProw 是基于 Kubernetes 开发的 CI/CD 系统\n\nJobs 可以由多种类型的事件出发，并且报告状态给不同的服务。除了 Job 执行外，Prow\n还提供了 Github 自动化执行策略，`/foo`格式的命令的 chat-ops 和自动 PR 合并\n\n### Functions and Features\n\n- 用于测试，批处理和产品发布的 Job 运行\n- 基于`/foo`格式的可扩展 Github bot 命令，强化配置策略和进程\n- 带有批量测试的 Github 自动合并\n- 用于查看 Job，合并队列状态，动态生成的帮助信息的前端界面\n- 基于 SCM 的自动部署\n- 在 SCM 中自动管理 Github 的 org/repo\n- 专为拥有大量仓库的多组织设计（Prow 只需要一个 Github bot token）\n- 在 Kubernetes 上运行带来的高可用性\n- JSON 结构日志\n- Prometheus metrics\n\n### Who use Prow\n\nProw is used by the following organizations and projects:\n\n- [Kubernetes](https://prow.k8s.io)\n  - This includes [kubernetes](https://github.com/kubernetes),\n    [kubernetes-client](https://github.com/kubernetes-client),\n    [kubernetes-csi](https://github.com/kubernetes-csi),\n    [kubernetes-incubator](https://github.com/kubernetes-incubator), and\n    [kubernetes-sigs](https://github.com/kubernetes-sigs).\n- [OpenShift](https://prow.svc.ci.openshift.org/)\n  - This includes [openshift](https://github.com/openshift),\n    [openshift-s2i](https://github.com/openshift-s2i),\n    [operator-framework](https://github.com/operator-framework), and some repos\n    in [kubernetes-incubator](https://github.com/kubernetes-incubator),\n    [containers](https://github.com/containers) and\n    [heketi](https://github.com/heketi).\n- [Istio](https://prow.istio.io/)\n- [Knative](https://prow.knative.dev/)\n- [Jetstack](https://prow.build-infra.jetstack.net/)\n- [Kyma](https://status.build.kyma-project.io/)\n- [Metal³](https://prow.apps.ci.metal3.io/)\n- [Prometheus](http://prombench.prometheus.io/)\n- [Caicloud](https://github.com/caicloud)\n- [Kubeflow](https://github.com/kubeflow)\n- [Azure AKS Engine](https://github.com/Azure/aks-engine/tree/master/.prowci)\n- [tensorflow/minigo](https://github.com/tensorflow/minigo#automated-tests)\n- [helm/charts](https://github.com/helm/charts)\n- [Daisy(google compute image tools)](https://github.com/GoogleCloudPlatform/compute-image-tools/tree/master/test-infra#prow-and-gubenator)\n- [KubeEdge (Kubernetes Native Edge Computing Framework)](https://github.com/kubeedge/kubeedge)\n- [Volcano (Kubernetes Native Batch System)](https://github.com/volcano-sh/volcano)\n- [Loodse](https://public-prow.loodse.com/)\n\n[Jenkins X](https://jenkins-x.io/) uses\n[Prow as part of Serverless Jenkins](https://medium.com/@jdrawlings/serverless-jenkins-with-jenkins-x-9134cbfe6870).\n\n### 部署 Prow\n\n#### 创建 Github bot 账号\n\n配置账户的 `personal access token`\n\n- Must have the `public_repo` and `repo:status` scopes\n- Add the `repo` scope if you plan on handing private repos\n- Add the `admin_org:hook` scope if you plan on handling a github org\n\n##### 创建 Github secrets\n\n1. 创建 `hmac-token` 用于 Github webhooks 的认证\n\n```bash\n# openssl rand -hex 20 > /path/to/hook/secret\nkubectl create secret generic hmac-token --from-file=hmac=/path/to/hook/secret\n```\n\n2. 创建 Github OAuth2 token\n\n```bash\n# https://github.com/settings/tokens\nkubectl create secret generic oauth-token --from-file=oauth=/path/to/oauth/secret\n```\n\n#### 安装`prow`到集群\n\n```\nkubectl apply -f https://github.com/gsmlg/pipeline/raw/master/updated_prow.yaml\n```\n\n默认会安装到 default namesapce 下，Job 运行在 test-pods namsapces 下\n\n通过命令查看是否安装完成\n\n```\n# kubectl get deployments\nNAME               READY   UP-TO-DATE   AVAILABLE   AGE\ndeck               2/2     2            2           21h\nhook               2/2     2            2           21h\nhorologium         1/1     1            1           21h\nplank              1/1     1            1           21h\nsinker             1/1     1            1           21h\nstatusreconciler   1/1     1            1           21h\ntide               1/1     1            1           21h\n```\n\n配置 ingress\n\n```\n# 查看ingress\nkubectl get ingress ing\n\n# 编辑ingress\nkubectl edit ingress ing\n\n```\n\n#### 创建 webhook\n\n配置 ingress，default/ing\n\n设置好 ingress 域名\n\n打开 github repo 的 setting 页面设置 webook，URL 设置为 ingress-domain/hook,\nsecret 为 webook 创建的 secret\n\n这样一个 prow 集群配置完成\n\n### 添加 plugins\n\n增加 configmap plugins\n\n内容为：\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: plugins\n  namespace: default\ndata:\n  plugins.yaml: |\n    plugins:\n      ORG/PROJECT:\n      - size\n```\n\n会自动在 pull-request 上添加一个 size 标签\n",
    "date": "2020-01-05",
    "id": 30,
    "slug": "prow",
    "title": "Prow"
  },
  {
    "author": "Gao",
    "content": "# Tekton Pipelines\n\n## Intro\n\nTekton Pipelines 是一个为`Kubernetes`应用程序配置和运行`CI / CD`风格\n的`Pipelined`的开源实现\n\n`Pipeline` 创建 `Custom Resources` 作为构建模块来声明`pipelines`\n\nTekton Pipelines 是云原生的\n\n- 运行于`Kubernetes`\n- 将`Kubernetes`集群作为一级资源类型\n- 使用容器作为构建块\n\nTekton Pipelines 是解耦的\n\n- Pipeline 可以被部署于任意 k8s 集群\n- 组成`pipeline`的`task`可以分开独立运行\n- 向 Git repos 之类的资源可以轻松的在运行之间交换\n\nTekton Pipelines are Typed\n\n- 类型化的资源意味着对于诸如 Image 之类的资源，可以轻松地将资源输出\n\n### 此设计的高级细节：\n\n- Pipeline 运行管道，可以实现一个流程，可以由事件出发，也可以通过`PipelineRun`来\n  运行\n- Task 基本运行单元，可以通过`TaskRun`来运行\n- PipelineResource `Task`的输入和输出资源\n\n## 各类资源介绍\n\n### PipelineResources\n\n`PipelineResource` 是 `Pipline` 中 `Task` 的输入和输出对象\n\nSyntax:\n\nTo define a configuration file for a PipelineResource, you can specify the\nfollowing fields:\n\n- Required:\n  - apiVersion - Specifies the API version, for example tekton.dev/v1alpha1.\n  - kind - Specify the PipelineResource resource object.\n  - metadata - Specifies data to uniquely identify the PipelineResource object,\n    for example a name.\n  - spec - Specifies the configuration information for your PipelineResource\n    resource object.\n  - type - Specifies the type of the PipelineResource\n- Optional:\n  - params - Parameters which are specific to each type of PipelineResource\n\nTypes:\n\n- Git\n- PullRequest\n- Image\n- Cluster\n- Storage\n- CloutEvent\n\n### Tasks\n\nTask(or ClusterTask) 是 CI 中一个组顺序执行的 step 的集合，是基本任务单位。Task\n会在 pod 中运行。\n\nTask 需要声明三部分：\n\n- inputs\n- outputs\n- steps\n\nTask 在 namespace 中可用，ClusterTask 在整个集群可用\n\nSyntax:\n\nTo define a configuration file for a Task resource, you can specify the\nfollowing fields:\n\n- Required:\n  - apiVersion - Specifies the API version, for example tekton.dev/v1alpha1.\n  - kind - Specify the Task resource object.\n  - metadata - Specifies data to uniquely identify the Task resource object, for\n    example a name.\n  - spec - Specifies the configuration information for your Task resource\n    object. Task steps must be defined through either of the following fields:\n    -steps - Specifies one or more container images that you want to run in your\n    Task.\n- Optional:\n  - inputs - Specifies parameters and PipelineResources needed by your Task\n  - outputs - Specifies PipelineResources created by your Task\n  - volumes - Specifies one or more volumes that you want to make available to\n    your Task's steps.\n  - stepTemplate - Specifies a Container step definition to use as the basis for\n    all steps within your Task.\n  - sidecars - Specifies sidecar containers to run alongside steps.\n\n### Piplines\n\nPipline 定义并执行一组 Task\n\nSyntax:\n\nTo define a configuration file for a Pipeline resource, you can specify the\nfollowing fields:\n\n- Required:\n  - apiVersion - Specifies the API version, for example tekton.dev/v1alpha1.\n  - kind - Specify the Pipeline resource object.\n  - metadata - Specifies data to uniquely identify the Pipeline resource object,\n    for example a name.\n  - spec - Specifies the configuration information for your Pipeline resource\n    object. In order for a Pipeline to do anything, the spec must include:\n    - tasks - Specifies which Tasks to run and how to run them\n- Optional:\n  - resources - Specifies which PipelineResources of which types the Pipeline\n    will be using in its Tasks\n  - tasks\n    - resources.inputs / resource.outputs\n      - from - Used when the content of the PipelineResource should come from\n        the output of a previous Pipeline Task\n      - runAfter - Used when the Pipeline Task should be executed after another\n        Pipeline Task, but there is no output linking required\n      - retries - Used when the task is wanted to be executed if it fails. Could\n        be a network error or a missing dependency. It does not apply to\n        cancellations.\n      - conditions - Used when a task is to be executed only if the specified\n        conditions are evaluated to be true.\n\nTask 执行顺序，所有 Task 默认都会并行执行，除非指定了\n\n- from\n- runAfter 两项会指定 task 执行的依赖关系\n\nFor example see this Pipeline spec:\n\n```yaml\n- name: lint-repo\n  taskRef:\n    name: pylint\n  resources:\n    inputs:\n      - name: workspace\n        resource: my-repo\n- name: test-app\n  taskRef:\n    name: make-test\n  resources:\n    inputs:\n      - name: workspace\n        resource: my-repo\n- name: build-app\n  taskRef:\n    name: kaniko-build-app\n  runAfter:\n    - test-app\n  resources:\n    inputs:\n      - name: workspace\n        resource: my-repo\n    outputs:\n      - name: image\n        resource: my-app-image\n- name: build-frontend\n  taskRef:\n    name: kaniko-build-frontend\n  runAfter:\n    - test-app\n  resources:\n    inputs:\n      - name: workspace\n        resource: my-repo\n    outputs:\n      - name: image\n        resource: my-frontend-image\n- name: deploy-all\n  taskRef:\n    name: deploy-kubectl\n  resources:\n    inputs:\n      - name: my-app-image\n        resource: my-app-image\n        from:\n          - build-app\n      - name: my-frontend-image\n        resource: my-frontend-image\n        from:\n          - build-frontend\n```\n\nThis will result in the following execution graph:\n\n```none\n        |            |\n        v            v\n     test-app    lint-repo\n    /        \\\n   v          v\nbuild-app  build-frontend\n   \\          /\n    v        v\n    deploy-all\n```\n\n## 安装\n\n运行 kubectl 安装指定的 yaml 文件\n\n```shell\nkubectl apply -f https://raw.githubusercontent.com/gsmlg/pipeline/master/updated.yaml\n```\n\n检查所有 pod 都处于`running`状态时，安装完成\n\n```shell\nkubectl -n tekton-pipelines get pods\n```\n\n安装 dashboard，更方便的查看 pipeline\n\n```shell\nkubectl apply -f https://raw.githubusercontent.com/gsmlg/pipeline/master/updated_dashboard.yaml\n```\n\n## 演示运行一个`singlecloud`的构建过程\n\n创建账户\n\n```yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: pipeline-run-role\nrules:\n  - apiGroups:\n      - extensions\n    resources:\n      - deployments\n    verbs:\n      - get\n      - list\n      - watch\n      - create\n      - update\n      - patch\n      - delete\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: pipeline-run-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: pipeline-run-role\nsubjects:\n  - kind: ServiceAccount\n    name: pipeline-run-service\n    namespace: default\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: pipeline-run-service\n  namespace: default\nsecrets:\n  - name: regcred\n\n---\napiVersion: v1\ndata:\n  .dockerconfigjson: <encoded docker registry auth data>\nkind: Secret\nmetadata:\n  name: regcred\n  namespace: default\ntype: kubernetes.io/dockerconfigjson\n```\n\n定义资源\n\n```yaml\napiVersion: tekton.dev/v1alpha1\nkind: PipelineResource\nmetadata:\n  name: zcloud-image\nspec:\n  type: image\n  params:\n    - name: url\n      value: docker.io/gsmlg/zcloud\n```\n\n创建 task\n\n```yaml\napiVersion: tekton.dev/v1alpha1\nkind: Task\nmetadata:\n  name: build-image-from-git\nspec:\n  inputs:\n    resources:\n      - name: docker-source\n        type: git\n    params:\n      - name: pathToDockerFile\n        type: string\n        description: The path to the dockerfile to build\n        default: /workspace/docker-source/Dockerfile\n      - name: pathToContext\n        type: string\n        description:\n          The build context used by Kaniko\n          (https://github.com/GoogleContainerTools/kaniko#kaniko-build-contexts)\n        default: /workspace/docker-source\n  outputs:\n    resources:\n      - name: builtImage\n        type: image\n  steps:\n    - name: build-and-push\n      image: registry.zdns.cn/gsmlg/kaniko-project-executor:v0.13.0\n      # specifying DOCKER_CONFIG is required to allow kaniko to detect docker credential\n      env:\n        - name: 'DOCKER_CONFIG'\n          value: '/builder/home/.docker/'\n      command:\n        - /kaniko/executor\n      args:\n        - --dockerfile=$(inputs.params.pathToDockerFile)\n        - --destination=$(outputs.resources.builtImage.url)\n        - --context=$(inputs.params.pathToContext)\n        - --oci-layout-path=/builder/home/image-outputs/builtImage\n        - --skip-tls-verify\n\n---\napiVersion: tekton.dev/v1alpha1\nkind: Task\nmetadata:\n  name: build-zcloud\nspec:\n  inputs:\n    resources:\n      - name: docker-source\n        type: git\n      - name: image\n        type: image\n      - name: uiImage\n        type: image\n    params:\n      - name: pathToDockerFile\n        type: string\n        description: The path to the dockerfile to build\n        default: /workspace/docker-source/Dockerfile\n      - name: pathToContext\n        type: string\n        description:\n          The build context used by Kaniko\n          (https://github.com/GoogleContainerTools/kaniko#kaniko-build-contexts)\n        default: /workspace/docker-source\n  outputs:\n    resources:\n      - name: builtImage\n        type: image\n  steps:\n    - name: setup-dockerfile\n      image: docker.io/ubuntu:18.04\n      command:\n        - /workspace/docker-source/setup.sh\n      args:\n        - $(inputs.resources.image.url)\n        - $(inputs.resources.uiImage.url)\n        - /workspace/docker-source/Dockerfile\n    - name: build-and-push\n      image: registry.zdns.cn/gsmlg/kaniko-project-executor:v0.13.0\n      # specifying DOCKER_CONFIG is required to allow kaniko to detect docker credential\n      env:\n        - name: 'DOCKER_CONFIG'\n          value: '/builder/home/.docker/'\n      command:\n        - /kaniko/executor\n      args:\n        - --dockerfile=$(inputs.params.pathToDockerFile)\n        - --destination=$(outputs.resources.builtImage.url)\n        - --context=$(inputs.params.pathToContext)\n        - --oci-layout-path=/builder/home/image-outputs/builtImage\n        - --skip-tls-verify\n\n---\napiVersion: tekton.dev/v1alpha1\nkind: Pipeline\nmetadata:\n  name: zcloud-build-pipeline\nspec:\n  resources:\n    - name: singlecloud-repo\n      type: git\n    - name: singlecloud-ui-repo\n      type: git\n    - name: zcloud-repo\n      type: git\n    - name: singlecloud-image\n      type: image\n    - name: singlecloud-ui-image\n      type: image\n    - name: zcloud-image\n      type: image\n  tasks:\n    - name: build-singlecloud-ui\n      retries: 1\n      taskRef:\n        name: build-image-from-git\n      resources:\n        inputs:\n          - name: docker-source\n            resource: singlecloud-ui-repo\n        outputs:\n          - name: builtImage\n            resource: singlecloud-ui-image\n    - name: build-singlecloud\n      taskRef:\n        name: build-image-from-git\n      resources:\n        inputs:\n          - name: docker-source\n            resource: singlecloud-repo\n        outputs:\n          - name: builtImage\n            resource: singlecloud-image\n    - name: build-zcloud\n      taskRef:\n        name: build-zcloud\n      resources:\n        inputs:\n          - name: docker-source\n            resource: zcloud-repo\n          - name: uiImage\n            resource: singlecloud-ui-image\n            from:\n              - build-singlecloud-ui\n          - name: image\n            resource: singlecloud-image\n            from:\n              - build-singlecloud\n        outputs:\n          - name: builtImage\n            resource: zcloud-image\n```\n\n运行 pipelinue:\n\n```yaml\napiVersion: tekton.dev/v1alpha1\nkind: PipelineRun\nmetadata:\n  generateName: zcloud-build-run-\nspec:\n  pipelineRef:\n    name: zcloud-build-pipeline\n  serviceAccount: pipeline-run-service\n  resources:\n    - name: singlecloud-repo\n      resourceSpec:\n        type: git\n        params:\n          - name: revision\n            value: master\n          - name: url\n            value: https://github.com/zdnscloud/singlecloud\n    - name: singlecloud-ui-repo\n      resourceSpec:\n        type: git\n        params:\n          - name: revision\n            value: master\n          - name: url\n            value: https://github.com/zdnscloud/singlecloud-ui\n    - name: zcloud-repo\n      resourceSpec:\n        type: git\n        params:\n          - name: revision\n            value: master\n          - name: url\n            value: https://github.com/gsmlg/zcloud-image\n    - name: singlecloud-image\n      resourceSpec:\n        type: image\n        params:\n          - name: url\n            value: registry.zdns.cn/zcloud/singlecloud:master\n    - name: singlecloud-ui-image\n      resourceSpec:\n        type: image\n        params:\n          - name: url\n            value: registry.zdns.cn/zcloud/singlecloud-ui:master\n    - name: zcloud-image\n      resourceRef:\n        name: zcloud-image\n```\n",
    "date": "2020-01-04",
    "id": 29,
    "slug": "tektoncd",
    "title": "Tekton Pipelines"
  },
  {
    "author": "Gao",
    "content": "## 在 Kubernetes 中安装 jenkins\n\n### 简介\n\n在 kubernetes 中安装 Jenkins Jenkins 会以 master 方式运行，当有 build 任务时，会\n在 kubernetes 中启动一个 pod 来运行对应的构建任务需要配置对应的 pod 来解决常规的\n构建问题\n\n### 安装 Jeknis 到 Kubernetes：\n\n    使用仓库 https://github.com/gsmlg/jenkins 中的配置\n\n1. 配置 Deployment 使用 deployment.yaml\n\n```\nkubectl create -f deployment.yaml\n```\n\n2. 配置 service.yaml 使用 service.yaml\n\n```\nkubectl create -f service.yaml\n```\n\n3. 手动添加 ingress 配置使用`rancher`配置 ingress 服务\n\n### 对 jenkins 进行配置\n\n1. 在 configure global security 中可以配置用户，用于登陆管理\n\n2. 配置连接 kubernetes 的权限\n\n   - 在 configure system 中，配置\n\n添加 cloud 配置\n\n- 配置 `kubernetes URL` 为 `API server` 的地址\n\n- 在 `Credentials` 配置上配置 `kubeconfig`\n\n- 添加`Jenkins tunnel` 地址，地址为`service`配置中的 `jenkins-jnlp` 的地址\n\n- 配置`Kubenetes Pod Template`， `labels` 配置用于`slave`启动时添加的配置\n\n- 配置`contaienr`参照需求配置\n\n  记录下配置的 Labels\n\n  删除 command to run， Arguments to pass to the command 配置\n\n  dind 配置需要添加 volume 映射 docker.sock\n\n        contaienr镜像当前需要自己配置，目前已经做了两个镜像\n        - gsmlg/jenkins-slave-jnlp-dind\n        - gsmlg/jenkins-slave-jnlp-nodejs\n\n### 配置项目\n\n添加`project`的时候\n\n- 通过 `Label Expression` 来确定使用哪一个`Pod template` 来启动 `slave`\n\n- `Source Code Management` 配置 git 项目地址\n\n- `branches to build` 指定那些分支会进行构建\n\n- `Build Triggers` 中指定自动出发 build 的触发器\n\n- `Build Environment` 指定 Build 终端输出颜色\n\n- `Build` 指定 build 命令，可以分阶段执行\n\n- `Post build` build 完成后的动作\n\n## Comment\n\n- jnlp - Java Network Launch Protocol\n  [Link](https://docs.oracle.com/javase/tutorial/deployment/deploymentInDepth/jnlp.html)\n",
    "date": "2019-11-24",
    "id": 28,
    "slug": "jenkins-in-k8s",
    "title": "Jenkins in Kubernetes"
  },
  {
    "author": "Gao",
    "content": "# Lint Code\n\nLinting 是自动检查源代码中是否存在编程错误和样式错误。 这可以通过使用 Lint 工具\n（也称为 Linter）来完成。 Lint 工具是基本的静态代码分析器。\n\n术语 linting 最初来自于 C 的 Unix 实用程序。如今，有许多可用于各种编程语言的\nCode linter。\n\n### Lint 很重要！\n\nLinting 对于减少错误和提高代码的整体质量很重要。 使用 Lint 工具可以通过早期发现\n错误来帮助您加速开发并降低成本。\n\n### Lint 工作流程\n\n- 开发便携代码\n- 使用 lint 工具检查\n- 解决检查到的错误\n- 运行测试\n- 提交 review 代码\n\nLint Code 是一种自动检查程序，它应该在代码审查和测试之前的开发早期进行。自动代码\n检查使代码审查和测试过程更加有效，并且可以使开发人员有更多的时间专注于正确的事情\n。\n",
    "date": "2019-10-14",
    "id": 27,
    "slug": "lint-code",
    "title": "Lint Code"
  },
  {
    "author": "Gao",
    "content": "# `Serverless` and `Lambda`\n\n## What is `Serverless`\n\n通常，我们可以控制向我们已经部署的的 Web 应用发起的 Http 请求。我们负责为应用配\n置和管理资源，保证应用在服务上运行。这有一些问题：\n\n1. 即使我们的服务没有被用户请求，也会被收取服务费用。\n\n2. 我们需要负责服务器及其所有资源的正常运行和维护。\n\n3. 我们还负责将适当的安全更新应用于服务器。\n\n4. 当应用使用量激增的时候我们需要扩展服务。当应用使用量下降时我们需要减少服务投\n   入。\n\n对于较小的公司和个人开发者来说，这可能需要处理很多。这最终会分散我们的精力，分散\n我们投入在构建和维护实际应用的力量。\n\n在大型组织中，这由基础架构团队处理，通常不是单个开发人员的责任。但是，支持此操作\n所需的过程最终会减慢开发时间。\n\n应用因为必需与基础架构团队合作才能启动和运行，所以很难持续构建应用。作为开发人员\n，我们一直在寻找这些问题的解决方案，而`serverless`正是应运而生。\n\n## Severless Coumputing\n\n**Serverless Coumputing**（简称为 `serverless`）是一种执行模型，其中云提供商\n（AWS，Azure 或 Google Cloud）负责通过动态分配资源来执行一段代码。并且根据运行代\n码的资源量进行收费。\n\n代码通常在无状态容器内运行，可以由各种事件触发，包括 `http requests`,\n`database events`, `queuing services`, `monitoring alerts`, `file uploads`,\n`scheduled events` (`cron jobs`), 等。发送到云的代码执行提供程序通常采用函数的形\n式。\n\n因此，`serverless`有时被称为`Fucntions as Services`或`FaaS`。以下是主要云提供商\n的 FaaS 产品：\n\n- AWS：[AWS Lambda](https://aws.amazon.com/lambda/)\n- Microsoft\n  Azure：[Azure Functions](https://azure.microsoft.com/en-us/services/functions/)\n- Google Cloud：[Cloud Functions](https://cloud.google.com/functions/)\n\n虽然`serverless`将底层基础架构从开发人员手中抽象出来，但`server`仍然参与执行我们\n的`function`。\n\n由于代码将作为单独的函数执行，因此我们需要注意一些事项。\n\n## Microservices\n\n在转换到`serverless`世界时，我们面临的最大变化是我们的应用程序需要\n以`functions`的形式进行组织。我们可能习惯将应用程序部署为单个 Rails 或 Express\n整体应用程序。\n\n在`serverless`的世界中，我们通常需要采用更基础的微服务的架构。我们可以通过在单个\n函数中运行整个应用程序，并自行处理应用整体路由来解决这个问题。但不建议这样做，因\n为我们需要尽量减小`functions`的大小。\n\n## Stateless Functions\n\n我们的`functions`通常运行在安全的无状态容器内。这意味着我们不能在应用服务中运行\n一些代码：\n\n- 在 event 完成后还需要运行，执行时间超长\n- 需要使用先前的上下文来执行请求我们必须认为我们的函数每次都在新的容器中运行使用\n  。\n\n这有一些细微之处，我们将在什么是 AWS Lambda 章节中讨论。\n\n## Cold Starts\n\n由于我们的函数是在按需响应事件的容器内运行的，因此存在一些与之相关的延迟，这被称\n之为`Cold Start`。在`function`完成执行后，我们的容器可能会保留一段时间。如果在此\n期间触发了另一个事件，则响应速度更快，这通常称为`Warm Start`。\n\n`Code Start`的延迟时间取决于所使用的云提供商的实现。在 AWS Lambda 上，它的范围可\n以从几百毫秒到几秒不等。它可以取决于所使用的运行时（或语言），函数的大小（作为包\n），当然还有所涉及的云提供者。多年来，`Code Start`已经大大改善，因为云提供商在优\n化低延迟时间方面已经做得更好。\n\n除了优化我们的`functions`外，我们还可以使用一些简单的技巧，例如指定时间内执行脚\n本，每隔几分钟调用一次`function`以保持`Warm`。\n\n使用 [`Serverless Framework`](https://serverless.com) 可以帮助我们很好的使\n`serverless` 应用\n[`Warm Start`](https://github.com/FidelLimited/serverless-plugin-warmup)\n\n# What is Lambda\n\nAWS Lambda (简称为 Lambda) 是由亚马逊云计算（AWS）提供的`serverless` 服务。当我\n们使用 Lambda 来构建 serverless 应用时，虽然我们不需要知道 Lambda 内部是如何工作\n的，但是我们了解`functions`是如何被执行的还是非常重要的。\n\n## Lambda Specs\n\n我们从 Lambda 的技术规范开始。Lambda 支持如下运行时。\n\n- Node.js: v10.15 and v8.10\n- Java 8\n- Python: 3.7, 3.6, and 2.7\n- .NET Core: 1.0.1 and 2.1\n- Go 1.x\n- Ruby 2.5\n- Rust\n\n每个函数都在一个 64 位 Amazon Linux AMI 中的容器内运行。并且执行环境具有：\n\n- Memory: 128MB - 3008MB, in 64 MB increments\n- Ephemeral disk space: 512MB\n- Max execution duration: 900 seconds\n- Compressed package size: 50MB\n- Uncompressed package size: 250MB\n\n我们看到 CPU 未被提及作为容器规范的一部分。这是因为我们无法直接控制 CPU。随着内\n存的增加，CPU 也会增加。\n\n临时磁盘空间以`/tmp`目录的形式提供。我们只能将此空间用于临时存储，因为后续调用将\n无法访问此空间。我们将在下面讨论 Lambda 函数的无状态特性。\n\n执行持续时间意味着您的 Lambda 函数最多可以运行 900 秒或 15 分钟。这意味着 Lambda\n不适用于长时间运行的进程。\n\n包大小是指运行函数所需的所有代码。这包括我们的函数可能导入的任何依赖项（Node.js\n中的 `node_modules` 目录）。未压缩的上限制为 250MB，压缩后限制为 50MB。我们将看\n看下面的包装过程。\n\n## Lambda Function\n\n最后，这是 Lambda Function (Node.js 版本) 的样子。\n\n```javascript\n\nexports.myHandler = function(event, context, callback) {\n\n  // Do Stuff\n\n  callback(Error error, Object result)\n\n}\n\n```\n\n这里，`myHandler` 是我们的 Lambda function 的名字。 `event` 对象包含了触发这个\nLambda 的时间的所有信息。如果 event 为一个 HTTP 请求触发，信息为 HTTP 请求的所有\n特征。 `context`对象包含了 Lambda function 执行的运行时的信息当函数执行结束后，\n我们使用`callback`来回结束执行，并返回结果，AWS 会把结果返回给 HTTP 请求\n\n## Packaging Functions\n\nLambda function 需要打包并发送到 AWS。这通常是压缩函数及其所有依赖项并将其上载到\nS3 存储桶的过程。并且让 AWS 知道您希望在特定 event 发生时使用此包。为了简化完成\n此过程，我们可以使用`Serverless Framework`。\n\n## Execution Model\n\n运行我们的`function`的容器（以及它使用的资源）完全由 AWS 管理。它在`event`发生时\n启动，如果没有使用则关闭。如果在执行`event`时发出了其他相同`event`，则会启动一个\n新容器来响应请求。这意味着如果我们遇到使用量激增，云提供商只需使用我们的函数创建\n容器的多个实例来为这些请求提供服务。\n\n这有一些有趣的含义。首先，我们的`function`实际上是`stateless`的。其次，每个请求\n（或 event）由独立的实例提供`Lambda function`服务。这意味着我们不需要在代码中处\n理并发请求。只要有新请求，AWS 就会调出一个容器。它在这里进行了一些优化。它会让容\n器留存几分钟（5 到 15 分钟，具体取决于负载），因此它可以在没有`Cold Start`的情况\n下响应后续请求。\n\n## Stateless Functions\n\n上述执行模型使 `Lambda function` 实际的无状态。这意味着每\n次`Lambda function`由`event`触发时，都会在全新的环境中调用它。您无权访问上一个事\n件的执行上下文。\n\n但是，由于上面提到的优化，每个容器实例化仅调用一次实际的`Lambda function`。回想\n一下，我们的函数是在容器内运行的。因此，当首次调用函数时，我们的处理函数中的所有\n代码都会被执行，并且调用处理函数。如果容器仍可用于后续请求，则将调用您的函数，而\n不是其周围的代码。\n\n例如，下面的`createNewDbConnection`方法在每个容器实例化时调用一次，而不是每次调\n用`Lambda function`时调用。另一方面，`myHandler`函数在每次调用时都会被调用。\n\n```javascript\nvar dbConnection = createNewDbConnection();\n\nexports.myHandler = function (event, context, callback) {\n  var result = dbConnection.makeQuery();\n  callback(null, result);\n};\n```\n\n容器的缓存效果也适用于我们上面讨论过的`/tmp`目录。只要容器被缓存，它就可用。\n\n现在我们可以猜测这不是一种使我们的`Lambda function`有状态的非常可靠的方法。这是\n因为我们只是不控制调用`Lambda`或缓存其容器的基础进程。\n\n## Pricing\n\n最后，Lambda 函数仅对执行函数所花费的时间进行计费。它从它开始执行到返回或终止的\n时间计算。它向上舍入到最接近的 100 毫秒。\n\n请注意，虽然 AWS 可能会在容器完成后保留容器和 Lambda 函数; 但我们不用为这个付费\n。\n\nLambda 提供了非常慷慨的免费套餐。\n\nLambda 免费套餐包括每月 1,000,000 次免费请求和每月 400,000 GB-seconds 的计算时间\n。过去，每 100 万个请求需要 0.20 美元，每 GB-seconds 需要 0.00001667 美元。\nGB-seconds 基于 Lambda 函数的内存消耗。有关详细信息，请查看 Lambda 定价页面。\n\nLambda 通常是我们基础设施成本中最便宜的部分。\n\n# Why Create Serverless Apps?\n\n```\n _____ _   _       _____ _\n|_   _| | ( )     /  __ \\ |\n  | | | |_|/ ___  | /  \\/ |__   ___  ___ _ __\n  | | | __| / __| | |   | '_ \\ / _ \\/ _ \\ '_ \\\n _| |_| |_  \\__ \\ | \\__/\\ | | |  __/  __/ |_) |\n \\___/ \\__| |___/  \\____/_| |_|\\___|\\___| .__/\n                                        | |\n                                        |_|\n```\n\n重要的是要明白为什么值得学习如何创建`serverless`应用程序。 `serverless`应用程序\n优于传统服务器托管应用程序的原因有几个：\n\n- 低维护\n- 低成本\n- 易于扩展\n\n到目前为止，最大的好处是我们只需要关心代码而不需要担心其他问题。低维护是因为没有\n任何服务器需要管理。我们无需确保服务器正常运行并保证我们的服务器应用正确的安全更\n新。我们只需要处理自己的应用程序代码，没有别的。\n\n运行`serverless`应用程序更便宜的主要原因是您实际上只按每个请求付费。因此，当我们\n的服务未被使用时，我们不会被收取任何费用。让我们快速分析一下我们运行笔记应用的成\n本。我们假设每天有 1000 个活跃用户每天向我们的 API 发出 20 个请求，并在 S3 上存\n储大约 10MB 的文件。这是对我们成本的非常粗略的计算。\n\n| Service             | Rate                                                                  |   Cost |\n| :------------------ | :-------------------------------------------------------------------- | -----: |\n| Cognito             | Free[1]                                                               | \\$0.00 |\n| API Gateway         | $3.5/M reqs + $0.09/GB transfer                                       | \\$2.20 |\n| Lambda              | Free[2]                                                               | \\$0.00 |\n| DynamoDB            | $0.0065/hr 10 write units, $0.0065/hr 50 read units[3]                | \\$2.80 |\n| S3                  | $0.023/GB storage, $0.005/K PUT, $0.004/10K GET, $0.0025/M objects[4] | \\$0.24 |\n| CloudFront          | $0.085/GB transfer + $0.01/10K reqs                                   | \\$0.86 |\n| Route53             | $0.50 per hosted zone + $0.40/M queries                               | \\$0.50 |\n| Certificate Manager | Free                                                                  | \\$0.00 |\n| Total               |                                                                       | \\$6.10 |\n\n- [1] Cognito is free for < 50K MAUs and \\$0.00550/MAU onwards.\n- [2] Lambda is free for < 1M requests and 400000GB-secs of compute.\n- [3] DynamoDB gives 25GB of free storage.\n- [4] S3 gives 1GB of free transfer.\n\n因此成本大约是每月**\\$6.1**。这些都是非常粗略的估计。现实世界的使用模式可能会有\n一些不同。但是，这让我们了解如何计算运行`serverless`应用程序的成本。\n",
    "date": "2019-09-04",
    "id": 26,
    "slug": "serverless",
    "title": "Serverless"
  },
  {
    "author": "Gao",
    "content": "### 什么是 Knative？\n\n基于`Kubernetes`的平台，用于构建，部署和管理现代无服务器工作负载。\n\nknative 于 2018 年 7 月 24 日对外发布，是谷歌开源的 `serverless`架构方案，旨在提\n供一套简单易用的 `serverless`方案，把 `serverless` 标准化。目前参与的公司主要是\nGoogle、Pivotal、IBM、Red Hat，。\n\n`Knative`让开发人员更高效 `Knative`组件构建于`Kubernetes`之上，抽象出复杂的细节\n，使开发人员能够专注于重要的事情。通过编写成功的实际实现共享的最佳实践\n，`Knative`解决了构建，部署和管理云本机服务的“无聊但困难”的部分。\n\n##### 亮点：\n\n- 针对常见应用程序用例提供更高级别抽象 API\n- 在几秒钟内即可提供可扩展，安全，无状态的服务\n- 松散耦合的特性，可以只使用需要的部分\n- 可插拔组件，可以使用自定的日志、监控、网络和 service mesh\n- Knative 可以在任何 k8s 运行的平台运行\n- 一致的开发体验，支持通用模式：GitOps, DockerOps, ManualOps.\n- Knative 可以与常见的工具和框架一起使用，例如 Django，Ruby on Rails，Spring 等\n  等。\n\n### knative 核心概念和原理\n\n为了实现 serverless 应用的管理，knative 把整个系统分成了三个部分：\n\n- Build：构建系统，把用户定义的函数和应用 build 成容器镜像\n- Serving：服务系统，用来配置应用的路由、升级策略、自动扩缩容等功能\n- Eventing：事件系统，用来自动完成事件的绑定和触发\n\n##### Build 构建系统\n\nbuild 的功能是把用户的代码自动化构建成容器镜像\n\nKnative 的特别之处在于两点：一是它的构建完成是在 kubernetes 中进行的，和整个\nkubernetes 生态结合更紧密；另外，它旨在提供一个通用的标准化的构建组件，可以作为\n其他更大系统中的一部分。\n\n根据官方文档中的说的，是为了定义标准化、可移植、可重用、性能高效的构建方法.\n\n##### Serving：服务系统\n\nserving 的核心功能是让应用运行起来提供服务。虽然听起来很简单，但这里包括了很多的\n事情：\n\n自动化启动和销毁容器根据名字生成网络访问相关的 service、ingress 等对象监控应用的\n请求，并自动扩缩容支持蓝绿发布、回滚功能，方便应用方法流程\n\nknative serving 功能是基于 kubernetes 和 istio 开发的，它使用 kubernetes 来管理\n容器（deployment、pod），istio 来管理网络路由（VirtualService、DestinationRule）\n。\n\n因为 kubernetes 和 istio 本身的概念非常多，理解和管理起来比较困难，knative 在此\n之上提供了更高一层的抽象（这些对应是基于 kubernetes 的 CRD 实现的）。这些抽象出\n来的概念对应的关系如下图：\n\n![62aa0d8d20401b05c4f6a51aada04eed](knative/3AFC8398-99AD-4331-B9D6-44EF8F58F2C2.png)\n\n- Configuration：应用的最新配置，也就是应用目前期望的状态，对应了 kubernetes 的\n  容器管理（deployment）。每次应用升级都会更新 configuration，而 knative 也会保\n  留历史版本的记录（图中的 revision），结合流量管理，knative 可以让多个不同的版\n  本共同提供服务，方便蓝绿发布和滚动升级\n- Route：应用的路由规则，也就是进来的流量如何访问应用，对应了 istio 的流量管理\n  （VirtualService）\n- Service：注意这里不是 kubernetes 中提供服务发现的那个 service，而是 knative 自\n  定义的 CRD，它的全称目前是 services.serving.knative.dev 。单独控制 route 和\n  configuration 就能实现 serving 的所有功能，但 knative 更推荐使用 Service 来管\n  理，因为它会自动帮你管理 route 和 configuration\n\n**knative serving 各组件之间的关系：**\n\n![0c2feb4ec772cd689fc9945fb8770985](knative/02553623-4A8C-4195-86CA-8E158C61C2EE.png)\n\n可以看到，每个 revision 对应了一组 deployment 管理的 pod pod 会自动汇报 metrics\n数据到 autoscaler，autoscaler 会根据请求量和资源使用情况修改 deployment 的\nreplicas 数量，从而实现自动扩缩容。serverless 一个重要的特定是它会 scale to 0 的\n，也就是当应用没有流量访问时，它会自动销毁所有的 pod activator 比较有趣，它是为\n了处理 scale to 0 而出现的。当某个 revision 后面的 pod 缩容到 0 时，route 的流量\n会指向 activator，activator 接收到请求之后会自动拉起 pod，然后把流量转发过去\nroute 对象对应了 istio 的 DestinationRoute 和 VirtualService，决定了访问应用的流\n量如何路由\n\n##### Eventing：事件系统\n\nserving 系统实现的功能是让应用/函数能够运行起来，并且自动伸缩，那什么时候才会调\n用应用呢？除了我们熟悉的正常应用调用之外，serverless 最重要的是基于事件的触发机\n制，也就是说当某件事发生时，就触发某个特定的函数。\n\n事件概念的出现，让函数和具体的调用方能够解耦。函数部署出来不用关心谁会调用它，而\n事件源触发也不用关心谁会处理它。\n\nKnative Eventing 是一个旨在满足云原生开发的常见需求的系统，并提供可组合的原语以\n支持后期绑定事件源和事件使用者。\n\nKnative Eventing 围绕以下目标设计：\n\n1. Knative Eventing 服务松散耦合。这些服务可以在各种平台上独立开发和部署（例如\n   Kubernetes，VM，SaaS 或 FaaS）。\n2. Event 的生产者和消费者是独立的。任何生产者（或源）都可以在有正在侦听的 Event\n   事件使用者之前生成 Event。在有创建这些 Event 的生产者之前，任何 Event 消费者\n   都可以选择侦听的事件或事件类别。\n3. 其他服务可以连接到 Eventing 系统。这些服务可以执行以下功能：\n   - 创建新的应用不需要修改事件的生产者何消费者\n   - 从生产者选择和标记指定的时间集合\n4. 确保跨服务互操作性。 Knative Eventing 与 CNCF 无服务器工作组开发的\n   CloudEvents 规范一致。\n\n### 安装 Knative\n\nKnative 依赖于 Ingress/Gateway，它能够将请求路由到 Knative Services。 目前，存在\n两种提供此功能的选项：\n\n- Istio，基于 Envoy 的 Service Mesh\n- Gloo，基于 Envoy 的 API Gateway。\n\n安装过程：\n\n1. 安装 istio\n2. 安装 Knative\n\n#### 首先安装 CRD\n\nlabel knative.dev/crd-install=true，可以防止安装过程中的竞争条件，而导致间歇性错\n误\n\n```shell\n   kubectl apply --selector knative.dev/crd-install=true \\\n   --filename https://github.com/knative/serving/releases/download/v0.7.0/serving.yaml \\\n   --filename https://github.com/knative/build/releases/download/v0.7.0/build.yaml \\\n   --filename https://github.com/knative/eventing/releases/download/v0.7.0/release.yaml \\\n   --filename https://github.com/knative/serving/releases/download/v0.7.0/monitoring.yaml\n```\n\n要完成 Knative 及其依赖项的安装，请再次运行 kubectl apply 命令，这次没有\n--selector 标志，以完成 Knative 及其依赖项的安装\n\n```shell\n   kubectl apply --filename https://github.com/knative/serving/releases/download/v0.7.0/serving.yaml --selector networking.knative.dev/certificate-provider!=cert-manager \\\n   --filename https://github.com/knative/build/releases/download/v0.7.0/build.yaml \\\n   --filename https://github.com/knative/eventing/releases/download/v0.7.0/release.yaml \\\n   --filename https://github.com/knative/serving/releases/download/v0.7.0/monitoring.yaml\n```\n\n如果所有组件状态为你 running，确认安装成功\n\n```shell\n   kubectl get pods --namespace knative-serving\n   kubectl get pods --namespace knative-build\n   kubectl get pods --namespace knative-eventing\n   kubectl get pods --namespace knative-monitoring\n```\n",
    "date": "2019-07-10",
    "id": 25,
    "slug": "knative",
    "title": "Introduce Knative"
  },
  {
    "author": "Gao",
    "content": "# 在 Linux 系统中配置 VPN Client\n\n在没有 X 的 linux 系统中安装启用 VPN\n\n## 安装\n\n```shell\n# Ubuntu & Debian\napt-get update\napt-get -y install strongswan xl2tpd\n\n# CentOS & RHEL\nyum -y install epel-release\nyum --enablerepo=epel -y install strongswan xl2tpd\n\n# Fedora\nyum -y install strongswan xl2tpd\n```\n\n### 配置 VPN 账户\n\n```shell\nVPN_SERVER_IP='你的VPN服务器IP'\nVPN_IPSEC_PSK='你的IPsec预共享密钥'\nVPN_USER='你的VPN用户名'\nVPN_PASSWORD='你的VPN密码'\n```\n\n### 配置 Strongswan\n\n```shell\ncat > /etc/ipsec.conf <<EOF\n# ipsec.conf - strongSwan IPsec configuration file\n\n# basic configuration\n\nconfig setup\n  # strictcrlpolicy=yes\n  # uniqueids = no\n\n# Add connections here.\n\n# Sample VPN connections\n\nconn %default\n  ikelifetime=60m\n  keylife=20m\n  rekeymargin=3m\n  keyingtries=1\n  keyexchange=ikev1\n  authby=secret\n  ike=aes128-sha1-modp1024,3des-sha1-modp1024!\n  esp=aes128-sha1-modp1024,3des-sha1-modp1024!\n\nconn myvpn\n  keyexchange=ikev1\n  left=%defaultroute\n  auto=add\n  authby=secret\n  type=transport\n  leftprotoport=17/1701\n  rightprotoport=17/1701\n  right=$VPN_SERVER_IP\nEOF\n\ncat > /etc/ipsec.secrets <<EOF\n: PSK \"$VPN_IPSEC_PSK\"\nEOF\n\nchmod 600 /etc/ipsec.secrets\n\n# For CentOS/RHEL & Fedora ONLY\nmv /etc/strongswan/ipsec.conf /etc/strongswan/ipsec.conf.old 2>/dev/null\nmv /etc/strongswan/ipsec.secrets /etc/strongswan/ipsec.secrets.old 2>/dev/null\nln -s /etc/ipsec.conf /etc/strongswan/ipsec.conf\nln -s /etc/ipsec.secrets /etc/strongswan/ipsec.secrets\n```\n\n### 配置 xl2tpd\n\n```shell\ncat > /etc/xl2tpd/xl2tpd.conf <<EOF\n[lac myvpn]\nlns = $VPN_SERVER_IP\nppp debug = yes\npppoptfile = /etc/ppp/options.l2tpd.client\nlength bit = yes\nEOF\n\ncat > /etc/ppp/options.l2tpd.client <<EOF\nipcp-accept-local\nipcp-accept-remote\nrefuse-eap\nrequire-chap\nnoccp\nnoauth\nmtu 1280\nmru 1280\nnoipdefault\ndefaultroute\nusepeerdns\nconnect-delay 5000\nname $VPN_USER\npassword $VPN_PASSWORD\nEOF\n\nchmod 600 /etc/ppp/options.l2tpd.client\n```\n\n- 至此 VPN 客户端配置已完成\n\n## 配置连接\n\n### 创建 xl2tpd 控制文件：\n\n```shell\nmkdir -p /var/run/xl2tpd\ntouch /var/run/xl2tpd/l2tp-control\n```\n\n### 重启服务：\n\n````\nservice strongswan restart\nservice xl2tpd restart\n```\n\n### 开始 IPsec 连接：\n\n```shell\n# Ubuntu & Debian\nipsec up myvpn\n\n# CentOS/RHEL & Fedora\nstrongswan up myvpn\n```\n\n### 开始 L2TP 连接：\n\n```shell\necho \"c myvpn\" > /var/run/xl2tpd/l2tp-control\n```\n\n## 配置路由\n\n查看路由\n\n```shell\nip route\n```\n\n创建路由表\n\n```\ngit clone https://github.com/gsmlg/static-routes.git\ncd static-routes\nmake linux\n# mode 1 不需要修改 default route\n\\cp mode1/ip-up /etc/ppp/ip-up.local\n# mode 2 需要配置 default route 到VPN的IP\n\\cp mode1/ip-up /etc/ppp/ip-up.local\n\\cp mode1/ip-down /etc/ppp/ip-down\n\n```\n\n## 断开连接\n\n```\n# Ubuntu & Debian\necho \"d myvpn\" > /var/run/xl2tpd/l2tp-control\nipsec down myvpn\n\n# CentOS/RHEL & Fedora\necho \"d myvpn\" > /var/run/xl2tpd/l2tp-control\nstrongswan down myvpn\n```\n````\n",
    "date": "2018-08-17",
    "id": 24,
    "slug": "vpn-client",
    "title": "Setup VPN Client in Linux Server"
  },
  {
    "author": "Gao",
    "content": "# HTTP 缓存控制\n\nHTTP 协议是 WWW 的通讯协议，用于处理互联网上成百上千的应用请求\n\nHTTP 中的缓存是非常重要的，线上服务可以处理成千上万的请求，很大程度上，都依赖缓\n存\n\nHTTP 协议中定义了在 HTTP 请求中如何缓存数据\n\n## Expires 响应头\n\n指定内容缓存失效时间\n\n```\n# Expires: <http-date>\n# Exampale\nExpires: Wed, 21 Oct 2015 07:28:00 GMT\n```\n\n表明缓存可以保存的时间，如果当前时间早于这个时间，那么可以使用缓存的副本，可以不\n向服务器再次请求\n\n## Cache-Control 响应头\n\n### `max-age`\n\n指定缓存生存时间\n\n示例：\n\n```\nCache-Control: max-age=3600\n```\n\n表示当收到响应后，在 3600 秒内，如果再次请求数据，可以使用缓存的副本，不需要再次\n向服务器请求数据\n\n### `public`\n\n表示这是一个开放资源，可以进行缓存\n\n### `private`\n\n表示这是一个私有资源，代理服务器不得缓存\n\n### `must-revalidate`\n\n当发生请求时，必须向服务器再次验证数据\n\n## 验证数据相关响应头\n\n### `Etag`\n\n用于验证当前数据的内容版本的标示符\n\n这可以让缓存更高效，并节省带宽，因为如果内容没有改变，Web 服务器不需要发送完整的\n响应。而如果内容发生了变化，使用 ETag 有助于防止资源的同时更新相互覆盖（“空中碰\n撞”）。\n\n如果给定 URL 中的资源更改，则一定要生成新的 Etag 值。 因此 Etags 类似于指纹，也\n可能被某些服务器用于跟踪。 比较 etags 能快速确定此资源是否变化，但也可能被跟踪服\n务器永久存留。\n\n```\nETag: W/\"<etag_value>\"\nETag: \"<etag_value>\"\n```\n\n- /W 'W/'(大小写敏感) 表示使用弱验证器。 弱验证器很容易生成，但不利于比较。 强验\n  证器是比较的理想选择，但很难有效地生成。 相同资源的两个弱 Etag 值可能语义等同\n  ，但不是每个字节都相同。\n\n- \"<etag_value>\" 实体标签唯一地表示所请求的资源。 它们是位于双引号之间的 ASCII\n  字符串（如“675af34563dc-tr34”）。\n\n#### 避免“空中碰撞”\n\n在 `ETag` 和 `If-Match` 头部的帮助下，可以检测到\"空中碰撞\"的编辑冲突。\n\n在 `POST` 请求头中包含 `If-Match` 头来检查是否最新版本。\n\n```\nIf-Match: \"33a64df551\"\n```\n\n如果哈希值不匹配，则发送 412 前提条件失败错误\n\n#### 缓存未更改的资源\n\n当用户再次请求对应资源时，会携带`if-none-match`头来\n\n```\nIf-None-Match: \"33a64df551\"\n```\n\n服务器收到后，检查是否和当前`etag`匹配，如果相同，则发送 304 响应，不包含任何内\n容，标示客户端可以使用缓存数据\n\n### `last-modified`\n\n包含源头服务器认定的资源做出修改的日期及时间。\n\n它通常被用作一个验证器来判断接收到的或者存储的资源是否彼此一致。由于精确度比\n`ETag` 要低，所以这是一个备用机制。\n\n```\nLast-Modified: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT\n```\n\n- `<day-name>` \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\" 或 \"Sun\" 之一 （区分大小\n  写）。\n- `<day>` 两位数字表示的天数, 例如\"04\" or \"23\"。\n- `<month>` \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\",\n  \"Oct\", \"Nov\", \"Dec\" 之一（区分大小写）。\n- `<year>` 4 位数字表示的年份, 例如 \"1990\" 或者\"2016\"。\n- `<hour>` 两位数字表示的小时数, 例如 \"09\" 或者 \"23\"。\n- `<minute>` 两位数字表示的分钟数，例如\"04\" 或者 \"59\"。\n- `<second>` 两位数字表示的秒数，例如 \"04\" 或者 \"59\"。\n- `GMT` 国际标准时间。HTTP 中的时间均用国际标准时间表示，从来不使用当地时间。\n\n#### 避免“空中碰撞”\n\n在 `Last-Modified` 和 `If-Unmodified-Since` 头部的帮助下，可以检测到\"空中碰撞\"的\n编辑冲突。\n\n在 `POST` 请求头中包含 `If-Unmodified-Since` 头来检查是否最新版本。\n\n```\nIf-Unmodified-Since: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT\n```\n\n如果请求资源在时间之后做了修改，则返回 412 前提条件失败错误\n\n#### 缓存未更改的资源\n\n当用户再次请求对应资源时，会携带`If-Modified-Since`头来匹配资源，如果在给定日期\n后做了修改，则需要正常响应\n\n```\nIf-Modified-Since: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT\n```\n\n服务器收到后，检查是否和当前`If-Modified-Since`时间，如果在给定日期后没有修改，\n则发送 304 响应，不包含任何内容，标示客户端可以使用缓存数据\n",
    "date": "2018-08-08",
    "id": 23,
    "slug": "http-cache",
    "title": "HTTP缓存控制"
  },
  {
    "author": "Gao",
    "content": "# 在 Ubuntu 上安装 kubeadm\n\n## 安装之前\n\n基本配置要求：\n\n- One or more machines running one of:\n  - Ubuntu 16.04+\n  - Debian 9\n  - CentOS 7\n  - RHEL 7\n  - Fedora 25/26 (best-effort)\n  - HypriotOS v1.0.1+\n  - Container Linux (tested with 1576.4.0)\n- 2 GB or more of RAM per machine (any less will leave little room for your\n  apps)\n- 2 CPUs or more\n- Full network connectivity between all machines in the cluster (public or\n  private network is fine)\n- Unique hostname, MAC address, and product_uuid for every node. See here for\n  more details.\n- Certain ports are open on your machines. See here for more details.\n- Swap disabled. You MUST disable swap in order for the kubelet to work\n  properly.\n\n## 安装 Docker\n\n```\napt-get update\napt-get install -y apt-transport-https ca-certificates curl software-properties-common\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\nadd-apt-repository \"deb https://download.docker.com/linux/$(. /etc/os-release; echo \"$ID\") $(lsb_release -cs) stable\"\napt-get update && apt-get install -y docker-ce=$(apt-cache madison docker-ce | grep 17.03 | head -1 | awk '{print $3}')\n```\n\n## 安装 kubeadm, kubelet and kubectl\n\n```\napt-get update && apt-get install -y apt-transport-https curl\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\ncat <<EOF >/etc/apt/sources.list.d/kubernetes.list\ndeb http://apt.kubernetes.io/ kubernetes-xenial main\nEOF\napt-get update\napt-get install -y kubelet kubeadm kubectl\napt-mark hold kubelet kubeadm kubectl\n```\n\n## 运行\n\n```\nkubeadm init\n```\n",
    "date": "2018-08-02",
    "id": 22,
    "slug": "install-kubernetes",
    "title": "安装Kubernetes"
  },
  {
    "author": "Gao",
    "content": "# 服务启动时启动 OTP 应用\n\n## 出现问题\n\n把 Phoenix 应用发布为 erlang otp 应用，设置开机启动，在 `/etc/rc.local` 中添加了\n启动\n\n重启后发现服务没有启动\n\n## 排查过程\n\n1. 增加打印输出 将服务启动时的输出打印，发现服务启动成功，`$?` 返回为 0\n2. 尝试延迟启动 猜测是否因为有服务没有启动导致，修改 `rc.local` 延迟 15 秒后启动\n   ，无效\n3. 修改启动方式 将启动方式修改为 `foreground` ，发现运行过程中出现错误\n\n```\nerlexec: HOME must be set\n```\n\n原来是启动时需要有`HOME`环境变量被配置\n\n## 解决方式\n\n在 `rc.local` 中启动时设置环境变量 `HOME`\n",
    "date": "2018-07-31",
    "id": 21,
    "slug": "otp-on-startup",
    "title": "系统启动时启动Phoniex应用"
  },
  {
    "author": "Gao",
    "content": "# Using Docker\n\n## 什么是 Docker\n\nDocker 利用现有的 Linux 容器技术，以不同方式将其封装及扩展 --主要是通过提供可以\n值的镜像，以及一个用户友好的接口 --来创建一套完整的容器创建及发布方案\n\nDocker 平台拥有两个不同部分\n\n- 负责创建与运行容器的 Docker Engine\n- 用来发布容器的云服务 Docker Hub\n\nDocker 的哲学经常用航运集装箱的比喻来解释，这或许能解释 Docker 名字的由来。\n\n这个比喻大概是这样：\n\n    运输货物时，要用到不同的运输工具，可能包括货车、叉车、起重机、火车和轮船。\n    这意味着这些工具必须可以处理大小不一，运输需求各异的货物。\n    以往这是一道复杂的工序，需要付出大量的人力、物力。\n    联运集装箱的诞生为运输产业带来了一场革命。\n    集装箱的大小有了统一标准，并且设计的出发点是能以最少的人力在不同的运输方式之间搬运。\n    所有运输机械都为运送集装箱而设计。运输不同类型物品可以使用不同的集装箱。\n    因此运输产业只需要专注于处理集装箱的运输及存储问题，而集装箱内的物品完全由生产商负责。\n\n    Docker 的目的是把集装箱的标准化流程运用到IT行业中去。\n    如今的典型系统可能包括Javascript框架、NoSQL数据库、消息队列、REST API，\n    以及由各个不同编程语言所写的后端。\n    而这个组合的全部或部分可能需要运行到不同的环境中，从开发者的笔记本电脑， 到公司内的测试集群，再到云端的生产环境。\n    每个环境都存在差异，他们存在不同的操作系统和不同的程序库。我们需要付出巨大的人力来在不同环境之间移动这些应用。\n    Docker容器简化了应用程序的移动，好比集装箱一样。\n    开发人员只需专注开发，再也不用担心测试和发布时环境以及依赖关系带来的问题。\n    运维部门只需专注于运行容器的核心问题。\n\n## 安装 Docker\n\nDocker 需要运行于 64 位的 Linux 系统上，内核版本需要大于 3.10\n\nmacOS 可以从`docker.com`下载到 docker-ce 版本安装使用\n\n可以使用`homebrew`来安装\n\n```\nbrew cask install docker\n```\n\nUbuntu 系统安装\n\n```\nsudo apt-get remove docker docker-engine docker.io\napt-get update\n\napt-get install \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    software-properties-common\n\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n\napt-key fingerprint 0EBFCD88\n\npub   4096R/0EBFCD88 2017-02-22\n      Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88\nuid                  Docker Release (CE deb) <docker@docker.com>\nsub   4096R/F273FCD8 2017-02-22\n\nadd-apt-repository \\\n   \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n   $(lsb_release -cs) \\\n   stable\"\n\napt-get update\n\napt-get install docker-ce\n\n```\n\n## 运行 Docker\n\n### images 镜像\n\ndocker 镜像是一个构建好的 docker 环境，可以使用 docker 直接启动一个镜像\n\n```\ndocker run debian\n```\n\n运行镜像会自动从`docker hub`下载对应的镜像，并运行\n\n运行镜像会自动创建一个 container\n\n查看运行中的 container：\n\n```\ndocker ps\n```\n\n运行一个交互式镜像\n\n```\ndocker run --rm -it gsmlg/phoenix\n# -i interactive\n# -t terminal\n# --rm remove after run\n```\n\n当 docker 运行后会生成一个 container 可以通过\n\n```\ndocker ps -a\n```\n\n查看所有 docker containers\n\n删除无用的 container\n\n```\ndocker rm -v $(docker ps -aq -f status=exited)\n```\n\n### Docker 镜像构建与发布\n\n#### Dockerfile\n\ndocker 构建一个镜像需要通过 Dockerfile 文件来配置镜像的内容\n\n一个构建的 Dockerfile 内容：\n\n```\nFROM alpine\n\nMAINTAINER GSMLG < me@gsmlg.org >\n\nRUN apk update \\\n    && apk add curl \\\n    && apk add stunnel \\\n    && apk add squid \\\n    && rm -rf /var/cache/apk/*\n\nCOPY stunnel.conf pkey.pem cert.pem /etc/stunnel/\n\nEXPOSE 443\n\nCOPY entrypoint.sh /\n\nENTRYPOINT [\"/entrypoint.sh\"]\n```\n\nDockerfile 配置说明\n\n#### push and pull\n\n`push`: 将本地镜像推送到远程\n\n`pull`: 拉取远程镜像\n\n### 通过 Docker Compose 运行\n\ndocker compose 通过 yaml 指定 docker 启动配置参数\n\n#### Docker Registry\n\n```\nregistry:\n  restart: always\n  image: registry:2\n  ports:\n    - 127.0.0.1:5000:5000\n  volumes:\n    - ./data:/var/lib/registry\n\n```\n\n### Docker Machine\n\n运行本地或远程的 docker 主机\n\n自动创建管理移除\n",
    "date": "2018-07-27",
    "id": 20,
    "slug": "using-docker",
    "title": "使用Docker"
  },
  {
    "author": "Gao",
    "content": "## 为 macOS 配置 VPN\n\n### 配置 VPN 服务器\n\n搭建 vpn 服务\n\n从系统仓库安装`ipsec` 安装`xl2tpd`\n\n在服务器上启动服务\n\n配置好服务账户\n\n```\nsystemctl restart ipsec\nsystemctl restart xl2tpd\n```\n\n### 配置 VPN Client\n\n从`Mac App Store`安装`Apple Configurator 2`\n\n创建 VPN 描述文件\n\n选择`l2tp`协议配置*服务器地址、用户名、密码和共享密钥*\n\n把描述文件安装到`macOS`的系统配置，`iOS`通过`airDrop`安装\n\n安装完成即可连接 vpn\n\n### 配置 macOS 在 VPN 连接时的路由表\n\n使用`[static-routes][https://github.com/gsmlg/static-routes]`的配置\n\n路由表数据时使用 maxmine 公开的 geoip 数据库来进行配置\n\n在`/etc/ppp/`目录配置`ip-up`,`ip-down`对应在 VPN 启动和停止时执行对应脚本\n\n脚本中可以使用变量说明\n\n```\n$1 interface etc: ppp0\n$2 none?\n$3 ? 0\n$4 client ip\n$5 remote ip\n$6 local gateway\n```\n\n### 命令行中控制 VPN\n\n```\nVPN connections\n\nUsage: scutil --nc [command]\n\n\tlist\n\t\tList available network connection services in the current set\n\n\tstatus <service>\n\t\tIndicate whether a given service is connected, as well as extended status information for the service\n\n\tshow <service>\n\t\tDisplay configuration information for a given service\n\n\tstatistics <service>\n\t\tProvide statistics on bytes, packets, and errors for a given service\n\n\tselect <service>\n\t\tMake the given service active in the current set. This allows it to be started\n\n\tstart <service> [--user user] [--password password] [--secret secret]\n\t\tStart a given service. Can take optional arguments for user, password, and secret\n\n\tstop <service>\n\t\tStop a given service\n\n\tsuspend <service>\n\t\tSuspend a given service (PPP, Modem on Hold)\n\n\tresume <service>\n\t\tResume a given service (PPP, Modem on Hold)\n\n\tondemand [-W] [hostname]\n\tondemand -- --refresh\n\t\tDisplay VPN on-demand information\n\n\ttrigger <hostname> [background] [port]\n\t\tTrigger VPN on-demand with specified hostname, and optional port and background flag\n\n\tenablevpn <service or vpn type> [path]\n\t\tEnables the given VPN application type. Takes either a service or VPN type. Pass a path to set ApplicationURL\n\n\tdisablevpn <service or vpn type>\n\t\tDisables the given VPN application type. Takes either a service or VPN type\n\n\thelp\n\t\tDisplay available commands for --nc\n\n```\n",
    "date": "2018-06-22",
    "id": 19,
    "slug": "vpn-setup-macos",
    "title": "在macOS中配置VPN"
  },
  {
    "author": "Gao",
    "content": "## iOS 10.3.3\n\niOS 10.3.3 是 Apple 发布的最后的 iOS 32bit 版本\n\n当前正好有一个废旧的 iPhone5c 便使用它来进行越狱\n\n## 越狱步骤\n\n### 准备越狱工具\n\n下载 h3lix，地址： https://h3lix.tihmstar.net\n\n下载 ipa，校验签名信息\n\n下载 cydia impactor， http://www.cydiaimpactor.com\n\n### 进行越狱\n\n连接 iPhone 到 USB\n\n打开 cydia impactor\n\n将 h3lix 拖动到 cydia impactor\n\n安装 h3lix.ipa，会请求 apple ID\n\n通过 apple ID 签名并安装 app 到 iPhone\n\n安装成功后打开 iPhone\n\n允许描述文件\n\n打开 h3lix，运行越狱\n\n越狱成功\n\n## Cydia 应用商店\n\n越狱成功后可以使用 cydia 应用商店安装应用\n\n当前 iOS10 已经无法使用 openSSH，需要安装 dropbear 才能使用 ssh 连接\n\n连接到终端方法：\n\n从 bigboss 源安装 iOS Terminal，后打开 app 即可进入终端\n\n打开终端\n\ncydia 使用的是`debian`的包管理系统，可以使用`dpkg`来查看和管理软件包\n\n### dropbear 安装\n\nCydia 默认商店没有 dropbear，所以安装比较麻烦\n\n方法有一下几种：\n\n1. 自己编译， 可以参照\n   https://ivrodriguez.com/installing-dropbear-ssh-on-ios-10-3-3/\n\n2. 下载安装，可以参考\n   https://www.reddit.com/r/jailbreak/comments/7mh516/tutorial_how_to_get_ssh_working_on_the_new_ios/\n\n3. 添加 cydia 源，没有可以参考的\n\n### Cydia 可用的应用\n\nAPP\n\n- iOS Terminal\n- Filza File Manager\n\nCLI\n\n- git\n- BIND\n- lighttpd\n- Vi IMproved\n\n## 越狱注意事项\n\n每次重启 iPhone 都需要重新越狱\n\nh3lix 签名只能使用 7 天，每七天必须重新签名\n",
    "date": "2018-06-13",
    "id": 18,
    "slug": "ios-jailbreak",
    "title": "iOS 10.3.3 h3lix Jailbreak"
  },
  {
    "author": "Gao",
    "content": "## 为什么使用 make\n\n在项目中部署使用了 makefile 配置,来方便快速的执行一些工作流\n\n相比于其它 task runner，make 的优势是不需要安装，所有系统当前都已经预置\n\n方便，是最大的原因\n\n目前使用的 makefile 如下：\n\n```makefile\nGREEN=\\033[0;32m\nNC=\\033[0m\nINSTALL_DIR=/usr/local/public\nPUBLIC=./public\nHOST=10.1.101.60\nTARFILE=assets.tar.bz2\nHASHFILE=assets.hash.txt\n\n.ONESHELL:\n\ndefault:\n\t@cat ReadMe\n\nzddi:\n\t@rm -rf public/assets/*\n\t@./yarn run build\n\nwatch:\n\t@./yarn watch\n\nbuild-system:\n\t@./yarn --offline\n\nrebuild-system:\n\t@./yarn cache clean\n\t@rm -rf node_modules\n\t@rm -f yarn.lock\n\t@./yarn\n\ntar:\n\t@cd ${PUBLIC} ;\\\n\ttar jcf ${TARFILE} assets\n\nrmtar:\n\t@cd ${PUBLIC} ;\\\n\trm ${TARFILE}\n\ncommit: tar\n\t@-cd ${PUBLIC} ;\\\n\tSHASUM=$(shell shasum ${PUBLIC}/${TARFILE} | awk '{print $$1}') ;\\\n\techo $${SHASUM} > ${HASHFILE} ;\\\n\tgit add ${HASHFILE} ;\\\n\tgit commit -nm \"create checksum commit HASH: [$${SHASUM}]\" ;\n\nupload: commit\n\t@cd ${PUBLIC} ;\\\n\tSHASUM=$(shell shasum ${PUBLIC}/${TARFILE} | awk '{print $$1}') ;\\\n\tCOMMIT=$(shell git log -1 --pretty=format:%H) ;\\\n\tBRANCH=$(shell git rev-parse --abbrev-ref HEAD) ;\\\n\tcurl -X POST http://${HOST}/api/web_build/upload \\\n -F hash=$${SHASUM} \\\n -F user=$(shell git config --get user.name) \\\n -F commit=$${COMMIT} \\\n -F branch=$${BRANCH} \\\n -F assets=@./${TARFILE}\n\npush: zddi upload rmtar\n\ndownload:\n\t@cd ${PUBLIC} ;\\\n\tcurl http://${HOST}/api/web_build/$(shell cat ${PUBLIC}/${HASHFILE}) > ${TARFILE}\n\ninstall: download\n\t@rm -rf ${PUBLIC}/assets\n\t@cd ${PUBLIC} ;\\\n\ttar jxf ${TARFILE}\n\t@rm -rf ${INSTALL_DIR}\n\t@cp -r ${PUBLIC} /usr/local/\n\t@rm -rf ${PUBLIC}/assets\n\t@rm ${PUBLIC}/${TARFILE}\n\t@rm /usr/local/${PUBLIC}/${TARFILE}\n\t@echo -e \"Install public folder to ${GREEN}${INSTALL_DIR}${NC}\"\n\npull: download\n\t@rm -rf ${PUBLIC}/assets\n\t@cd ${PUBLIC} ;\\\n\ttar jxf ${TARFILE}\n\t@rm ${PUBLIC}/${TARFILE}\n\t@echo -e \"${GREEN}Code pull from remote done!${NC}\"\n\n\n```\n\n### 定义变量\n\nmakefile 中的变量定义和 shell 中一样，都可以直接使用\n\n```\nabc = 123\nbcd += ddd\ncc := f2\n```\n\n#### shel 中的变量\n\n由于 makefile 中的变量和 shell 格式一样，所以当要使用 shell 变量时，会需要使用转\n义序列来处理，方式是两个`$`符号\n\n### shell\n\nmakefile 中的 shell 使用需要注意，每一行都会启动一个 shell，单独运行当调用 shell\n进行插值的时候，shell 的执行顺序也不是顺序执行的\n\n由于都是使用单独的 shell，所以当想要使用相同的上下文时，可以使用`.ONESHELL`指令\n设置，或者是转义换行符\n\n### 连续的 task\n\n由于 makefile 中 shell 无法连续执行，所以，将 task 拆分成多个，然后通过 task 依\n赖关系顺序执行\n\ntask 依赖，在 task 后输入其它的 task 名称，就会按照顺序，连续执行这些 task\n\n当出现错误，task 队列会中断，这时需要在 shell 开始的行添加一个`-`来继续执行 task\n",
    "date": "2018-05-16",
    "id": 17,
    "slug": "makefile",
    "title": "Makefile使用"
  },
  {
    "author": "Gao",
    "content": "# Ubuntu 18.04 Ruby and Elixir Development Setup\n\nGuide to setting up a new Ubuntu 18.04 dev environment with Ruby and Elixir\ninstalled with the asdf version management tool.\n\n## Update system and install prerequisite packages\n\nSome of these packages may already be installed\n\n```bash\nsudo apt-get install mercurial make binutils bison gcc \\\n build-essential git curl zlib1g-dev openssl libssl-dev libreadline-dev \\\n libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev libcurl4-openssl-dev \\\n software-properties-common wget dnsutils vim zip unzip screen tmux htop \\\n libffi-dev redis-server imagemagick ntp ufw sudo dirmngr libxrender1\n```\n\nInstall postfix SMTP server (Choose internet site configuration and use the\nserver's domain name)\n\n```bash\nsudo apt-get install postfix\n```\n\nEdit postfix config file\n\n```bash\nsudo vim /etc/postfix/main.cf\n```\n\nSet inet_interfaces to be loopback-only\n\n```\ninet_interfaces = loopback-only\n```\n\nGenerate an SSH keypair used for deployments\n\n```bash\nssh-keygen -t rsa -C \"YOUR@EMAIL.com\"\n```\n\nCopy the output of this command and paste into\n[github SSH key settings](https://github.com/settings/keys).\n\n```bash\ncat ~/.ssh/id_rsa.pub\n```\n\nCheck to make sure SSH to github works with your key\n\n```bash\nssh -T git@github.com\n```\n\n## PostgreSQL\n\n```bash\nsudo apt-get install postgresql-10 libpq-dev\n```\n\nSet postgres user password\n\n```\nsudo -u postgres psql\npostgres=# \\password postgres\n```\n\n## zsh and oh-my-zsh\n\n```bash\nsudo apt-get install zsh fonts-powerline\nchsh -s $(which zsh)\n# logout and back in\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n```\n\n## asdf version manager\n\n```bash\nsudo apt-get install automake autoconf libreadline-dev libncurses-dev \\\nlibssl-dev libyaml-dev libxslt-dev libffi-dev libtool unixodbc-dev \\\nlibwxgtk3.0-dev libgl1-mesa-dev  libglu1-mesa-dev libssh-dev xsltproc fop \\\nlibxml2-utils\n\ngit clone https://github.com/asdf-vm/asdf.git ~/.asdf --branch v0.4.3\n\n# add to bottom of .zshrc\necho -e '\\n. $HOME/.asdf/asdf.sh' >> ~/.zshrc\necho -e '\\n. $HOME/.asdf/completions/asdf.bash' >> ~/.zshrc\n\nsource ~/.zshrc\n```\n\n## Ruby and Ruby on Rails\n\n```bash\nasdf plugin-add ruby\nasdf install ruby 2.5.1\nasdf global ruby 2.5.1\nruby -v\n```\n\nTell RubyGems to not install documentation for each gem\n\n```bash\necho \"gem: --no-ri --no-rdoc\" > ~/.gemrc\n```\n\nInstall bundler and rails\n\n```bash\ngem install bundler\ngem install rails\n```\n\n## Node.js\n\n```bash\nasdf plugin-add nodejs https://github.com/asdf-vm/asdf-nodejs.git\nbash ~/.asdf/plugins/nodejs/bin/import-release-team-keyring\nasdf install nodejs 9.11.1\nasdf global nodejs 9.11.1\nnode -v\n```\n\n## Erlang, Elixir and Phoenix\n\n### Erlang\n\n```bash\nasdf plugin-add erlang\nasdf install erlang 20.3.4\nasdf global erlang 20.3.4\n```\n\n### Elixir\n\n```bash\nasdf plugin-add elixir https://github.com/asdf-vm/asdf-elixir.git\nasdf install elixir 1.6.4\nasdf global elixir 1.6.4\nelixir -v\n```\n\n### Phoenix\n\n```bash\nsudo apt-get install inotify-tools\nmix local.hex\nmix archive.install https://github.com/phoenixframework/archives/raw/master/phx_new.ez\n```\n\n## Other Tools\n\n### wkhtmltopdf\n\nThe wkhtmltopdf packge available in debian repo is version with unpatched QT.\nYou most likely want version with patched QT, so download the precompiled\nbinaries for Linux from https://wkhtmltopdf.org/downloads.html, extract them and\ncp the binaries in bin folder to `/usr/bin/`\n\nAt the time of writing, the latest version is 0.12.4 which has an issue fetching\nremote images over https, so you will need to install libssl1.0-dev\n\n```bash\nsudo apt-get install libssl1.0-dev\n```\n\n### PostGIS and Geospatial related tool dependencies\n\n```bash\nsudo apt-get install python-all-dev python-dev python3-pip \\\n libaio-dev libbz2-dev libjpeg-turbo8-dev libpcre3-dev libexpat1-dev \\\n liblzma-dev libevent-dev binutils libproj-dev xsltproc docbook-xsl \\\n docbook-mathml libgeos-dev libgeos-3.6.2 postgresql-10-postgis-2.4 \\\n libgdal-dev python3-gdal python3-numpy gdal-bin postgresql-10-postgis-scripts\n```\n\nAdd to .zshrc\n\n```bash\nexport CPLUS_INCLUDE_PATH=/usr/include/gdal\nexport C_INCLUDE_PATH=/usr/include/gdal\n```\n\nMake sure rgeo will be able to find geos\n\n```bash\nsudo ln -s /usr/lib/x86_64-linux-gnu/libgeos-3.6.2.so /usr/lib/libgeos.so\ngem install rgeo\n```\n",
    "date": "2018-05-09",
    "id": 16,
    "slug": "ubuntu-18.04-ruby-and-elixir",
    "title": "在Ubuntu18.04上安装ruby和elixir开发环境"
  },
  {
    "author": "Gao",
    "content": "## es6 中新增加了 `const` 和 `let`\n\n`const` 和 `let` 都是新增加的变量声名方式\n\n### 有别于`var`声名,他们没有变量提升(Hoisting)机制\n\n```javascript\nif (!('someone' in window)) {\n  var someone = 'Joe';\n} else {\n  someone = 'reload';\n}\n\nconsole.log(someone);\n```\n\n总是会打印出 'reload'\n\n在预编译阶段会变成\n\n```javascript\nvar someone;\n\nif (!('someone' in window)) {\n  someone = 'Joe';\n} else {\n  someone = 'reload';\n}\n\nconsole.log(someone);\n```\n\n### 禁止重声名\n\n`let` 会禁止重新声名变量\n\n### const\n\n`const` 声名时必须赋值\n\n### 临时性死区\n\n使用`cosnt`或者`let`声名变量，如果在之前调用他们，会抛出一个异常`ReferenceError`\n\n这时使用 `typeof` 操作时也是不安全的，这里成为临时性死区 (Temporal Dead Zone)\n",
    "date": "2018-04-28",
    "id": 15,
    "slug": "es6-const-let",
    "title": "ECMAScript 2015 块级作用域绑定"
  },
  {
    "author": "Gao",
    "content": "## Node.js 10 ChangeLog\n\n| Current |\n| :------ |\n| 10.0.0  |\n\n** 2018-04-24, Version 10.0.0 (Current), @jasnell **\n\n### Notable Changes\n\n- Assert\n  - Calling assert.fail() with more than one argument is deprecated.\n    [70dcacd710]\n  - Calling assert.ok() with no arguments will now throw. [3cd7977a42]\n  - Calling assert.ifError() will now throw with any argument other than\n    undefined or null. Previously the method would throw with any truthy value.\n    [e65a6e81ef]\n  - The assert.rejects() and assert.doesNotReject() methods have been added for\n    working with async functions. [599337f43e]\n- Async_hooks\n  - Older experimental async_hooks APIs have been removed. [1cc6b993b9]\n- Buffer\n  - Uses of new Buffer() and Buffer() outside of the node_modules directory will\n    now emit a runtime deprecation warning. [9d4ab90117]\n  - Buffer.isEncoding() now returns undefined for falsy values, including an\n    empty string. [452eed956e]\n  - Buffer.fill() will throw if an attempt is made to fill with an empty Buffer.\n    [1e802539b2]\n- Child Process\n  - Undefined properties of env are ignored. [38ee25e2e2], [85739b6c5b]\n- Console\n  - The console.table() method has been added. [97ace04492]\n- Crypto\n  - The crypto.createCipher() and crypto.createDecipher() methods have been\n    deprecated. Please use crypto.createCipheriv() and crypto.createDecipheriv()\n    instead. [81f88e30dd]\n  - The decipher.finaltol() method has been deprecated. [19f3927d92]\n  - The crypto.DEFAULT_ENCODING property has been deprecated. [6035beea93]\n  - The ECDH.convertKey() method has been added. [f2e02883e7]\n  - The crypto.fips property has been deprecated. [6e7992e8b8]\n- Dependencies\n  - V8 has been updated to 6.6. [9daebb48d6]\n  - OpenSSL has been updated to 1.1.0h. [66cb29e646]\n- EventEmitter\n  - The EventEmitter.prototype.off() method has been added as an alias for\n    EventEmitter.prototype.removeListener(). [3bb6f07d52]\n- File System\n  - The fs/promises API provides experimental promisified versions of the fs\n    functions. [329fc78e49]\n  - Invalid path errors are now thrown synchronously. [d8f73385e2]\n  - The fs.readFile() method now partitions reads to avoid thread pool\n    exhaustion. [67a4ce1c6e]\n- HTTP\n  - Processing of HTTP Status codes 100, 102-199 has been improved. [baf8495078]\n  - Multi-byte characters in URL paths are now forbidden. [b961d9fd83]\n- N-API\n  - The n-api is no longer experimental. [cd7d7b15c1]\n- Net\n  - The 'close' event will be emitted after 'end'. [9b7a6914a7]\n- Perf_hooks\n  - The PerformanceObserver class is now an AsyncResource and can be monitored\n    using async_hooks. [009e41826f]\n  - Trace events are now emitted for performance events. [9e509b622b]\n  - The performance API has been simplified. [2ec6995555]\n  - Performance milestone marks will be emitted as trace events. [96cb4fb795]\n- Process\n  - Using non-string values for process.env is deprecated. [5826fe4e79]\n  - The process.assert() method is deprecated. [703e37cf3f]\n- REPL\n  - REPL now experimentally supports top-level await when using the\n    --experimental-repl-await flag. [eeab7bc068]\n  - The previously deprecated \"magic mode\" has been removed. [4893f70d12]\n  - The previously deprecated NODE_REPL_HISTORY_FILE environment variable has\n    been removed. [60c9ad7979]\n  - Proxy objects are shown as Proxy objects when inspected. [90a43906ab]\n- Streams\n  - The 'readable' event is now always deferred with nextTick. [1e0f3315c7]\n  - A new pipeline() method has been provided for building end-to-data stream\n    pipelines. [a5cf3feaf1]\n  - Experimental support for async for-await has been added to stream.Readable.\n    [61b4d60c5d]\n- Timers\n  - The enroll() and unenroll() methods have been deprecated. [68783ae0b8]\n- TLS\n  - The tls.convertNPNProtocols() method has been deprecated. [9204a0db6e]\n  - Support for NPN (next protocol negotiation) has been dropped. [5bfbe5ceae]\n  - The ecdhCurve default is now 'auto'. [af78840b19]\n- Trace Events\n  - A new trace_events top-level module allows trace event categories to be\n    enabled/disabled at runtime. [da5d818a54]\n- URL\n  - The WHATWG URL API is now a global. [312414662b]\n- Util\n  - util.types.is[…] type checks have been added. [b20af8088a]\n  - Support for bigint formatting has been added to util.inspect(). [39dc947409]\n\n### Deprecations:\n\nThe following APIs have been deprecated in Node.js 10.0.0\n\n- Passing more than one argument to assert.fail() will emit a runtime\n  deprecation warning. [70dcacd710]\n- Previously deprecated legacy async_hooks APIs have reached end-of-life and\n  have been removed. [1cc6b993b9]\n- Using require() to access several of Node.js' own internal dependencies will\n  emit a runtime deprecation. [0e10717e43]\n- The crypto.createCipher() and crypto.createDecipher() methods have been\n  deprecated in documentation.[81f88e30dd]\n- Using the Decipher.finaltol() method will emit a runtime deprecation warning.\n  [19f3927d92]\n- Using the crypto.DEFAULT_ENCODING property will emit a runtime deprecation\n  warning. [6035beea93]\n- Use by native addons of the MakeCallback() variant that passes a Domain will\n  emit a runtime deprecation warning. [14bc3e22f3], [efb32592e1]\n- Previously deprecated internal getters/setters on net.Server has reached\n  end-of-life and have been removed. [3701b02309]\n- Use of non-string values for process.env has been deprecated in documentation.\n  [5826fe4e79]\n- Use of process.assert() will emit a runtime deprecation warning. [703e37cf3f]\n- Previously deprecated NODE_REPL_HISTORY_FILE environment variable has reached\n  end-of-life and has been removed. [60c9ad7979]\n- Use of the timers.enroll() and timers.unenroll() methods will emit a runtime\n  deprecation warning. [68783ae0b8]\n- Use of the tls.convertNPNProtocols() method will emit a runtime deprecation\n  warning. Support for NPN has been removed from Node.js. [9204a0db6e]\n- The crypto.fips property has been deprecated in documentation. [6e7992e8b8]\n",
    "date": "2018-04-28",
    "id": 14,
    "slug": "nodejs-v10",
    "title": "Node.js v10 发布"
  },
  {
    "author": "Gao",
    "content": "## 奇怪的 Bug\n\n开发网络管理的时候，发现了一个非常奇怪的 bug。\n\n当时的情况是：当网络管理打开一个对话框并关闭后，切换到其它的菜单后，再切换回来，\n对话框会自动的打开。\n\n经过多次调试后发现，在 HOC 挂载 reducer 的时候，redux 执行了 action\n`{ type: @@redux/INIT }`，在 action 进入 reducer 的时候，突然变成了打开对话框的\naction `{ type: address/networks/trigger-action, payload: { aciton: 'create'} }`\n\n**对比发现问题**\n\n- Chrome，Firefox 出现这个问题，IE，Safari 没有这个问题\n- 在 Chrome 和 Firefox 中，build production 时也没有这个问题\n- 在调试过程加断点，当逐步调试进入 eval 代码快中后，也没有这个问题了\n\n## 结论\n\nWebpack DLL 插件为了加速编译，模块被转换为字符串在 eval 中执行，在 eval 中执行出\n现了内存泄漏，导致执行错误。\n\nJavascript 中 `eval` 函数作为被严格模式禁止的函数，必然存在 bug，目前不能在项目\n中使用。\n",
    "date": "2018-04-02",
    "id": 13,
    "slug": "webpack-dll-eval-bug",
    "title": "Webpack DLL Plugin 引起的Bug"
  },
  {
    "author": "Gao",
    "content": "# accessibility.browsewithcaret\n\n最近浏览 Firefox 时，发现页面上总是有一个光标，在页面上，导致无法使用方向键控制\n滚屏。\n\n查询发现时 Firefox 的一个配置被打开了名为 `accessibility.browsewithcaret`\n[链接](http://kb.mozillazine.org/Accessibility.browsewithcaret)\n\n> ### Background\n\n> Originally for debugging purposes, this preference now determines whether or\n> not Caret Browsing mode is active. Caret Browsing is provided as a way to\n> navigate through a web page—using only the keyboard—by moving a text caret.\n> This mode is more easily toggled by pressing [F7].\n\n> Caret Browsing mode changes the effects of the arrow keys, as well as the\n> [Home] and [End] keys.\n\n> ### Possible values and their effects\n\n> - True\n\n> A blinking cursor (the caret) is visible on all displayed webpages, allowing\n> the user to navigate through the page as they might a word processor document.\n\n> - False\n\n> The system caret is hidden. (Default)\n\n> ### UI\n\n> **Firefox**\n\n> Tools → Options → Advanced → General / Accessibility → \"Always use the cursor\n> keys to navigate within pages\" (Firefox 2 and above) Tools → Options →\n> Advanced → General / Accessibility → \"Allow text to be selected with the\n> keyboard\" (Firefox 1.5)\n",
    "date": "2018-03-26",
    "id": 12,
    "slug": "browsewithcaret",
    "title": "关于accessibility.browsewithcaret"
  },
  {
    "author": "Gao",
    "content": "# Spacemacs 使用配置\n\n## 安装\n\n```shell\n% git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d/spacemacs\n```\n\n修改配置 `init.el`\n\n```elisp\n(setenv \"SPACEMACSDIR\" \"~/.emacs.d/lisp/\")\n\n;; (package-initialize)\n\n(setq spacemacs-start-directory \"~/.emacs.d/spacemacs/\")\n(load-file (concat spacemacs-start-directory \"init.el\"))\n\n```\n\n## 配置\n\n启动 Emacs 后，会在`~/.emacs.d/lisp/init.el`生成`spacemacs`配置\n\n重度 Emacs 用户选择编辑模式为`emacs`\n\n### 配置概念：`layer`\n\n每一种编辑配置都会进行配置，名称叫做`layer`\n\n每一个`layer`用来处理一种语言配置或配置罗辑\n\n### 配置`layer`\n\n常用 layer 添加：\n\n- org\n- git\n- chinese\n- markdown\n- javascript\n- elixir\n\n[![Built with Spacemacs](https://cdn.rawgit.com/syl20bnr/spacemacs/442d025779da2f62fc86c2082703697714db6514/assets/spacemacs-badge.svg)](http://spacemacs.org)\n",
    "date": "2017-12-23",
    "id": 11,
    "slug": "spacemacs-config",
    "title": "Spacemacs配置"
  },
  {
    "author": "Gao",
    "content": "# 概述\n\n无界面浏览器 <`headdless mode`> 在进行自动化测试和服务器上运行时非常有用。\n\n在服务器上，可能需要运行浏览器去执行一些特殊的任务，但是服务器上是没有 X Window\n系统，这个时候就需要使用无界面浏览器了。\n\n无界面浏览器可以去打开一些真正的页面，并且渲染，然后输出到 html，pdf 或图片。\n\n无界面浏览器还可以打开调试端口，在没有图形界面的情况下，调试真正的浏览器页面。\n\n## Chrome\n\nChrome 从版本 59 开始，提供了无界面浏览功能，使用方式如下:\n\n```shell\nchrome \\\n  --headless \\                   # Runs Chrome in headless mode.\n  --disable-gpu \\                # Temporarily needed for now.\n  --remote-debugging-port=9222 \\\n  https://www.chromestatus.com   # URL to open. Defaults to about:blank.\n```\n\n- chrome 命令设置：\n\n```shell\nalias chrome=\"/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome\"\nalias chrome-canary=\"/Applications/Google\\ Chrome\\ Canary.app/Contents/MacOS/Google\\ Chrome\\ Canary\"\nalias chromium=\"/Applications/Chromium.app/Contents/MacOS/Chromium\"\n```\n\nChrome headless mode 提供了很多强大功能：\n\n- 输出 DOM 结构\n\n`--dump-dom` flag 会输出`document.body.innerHTML`\n\n```shell\nchrome --headless --disable-gpu --dump-dom https://www.chromestatus.com/\n```\n\n- 输出 PDF\n\n```shell\nchrome --headless --disable-gpu --print-to-pdf https://www.chromestatus.com/\n```\n\n- 输出截图\n\n```shell\nchrome --headless --disable-gpu --screenshot https://www.chromestatus.com/\n\n# Size of a standard letterhead.\nchrome --headless --disable-gpu --screenshot --window-size=1280,1696 https://www.chromestatus.com/\n\n# Nexus 5x\nchrome --headless --disable-gpu --screenshot --window-size=412,732 https://www.chromestatus.com/\n```\n\n- REPL\n\n`--repl` 会打开一个 JS Console\n\n```shell\n$ chrome --headless --disable-gpu --repl https://www.chromestatus.com/\n[0608/112805.245285:INFO:headless_shell.cc(278)] Type a Javascript expression to evaluate or \"quit\" to exit.\n>>> location.href\n{\"result\":{\"type\":\"string\",\"value\":\"https://www.chromestatus.com/features\"}}\n>>> quit\n$\n```\n\n- 远程调试\n\n`--remote-debugging-port=9222` 会打开调试端口，调试基于`DevTools protocol`协议可\n以通过编辑器连接，来进行远程调试。\n\n### Node 编程接口\n\n**The Puppeteer API**\n\nPuppeteer is a Node library developed by the Chrome team. It provides a\nhigh-level API to control headless (or full) Chrome. It's similar to other\nautomated testing libraries like Phantom and NightmareJS, but it only works with\nthe latest versions of Chrome.\n\nAmong other things, Puppeteer can be used to easily take screenshots, create\nPDFs, navigate pages, and fetch information about those pages. I recommend the\nlibrary if you want to quickly automate browser testing. It hides away the\ncomplexities of the DevTools protocol and takes care of redundant tasks like\nlaunching a debug instance of Chrome.\n\nInstall it:\n\n```shell\nyarn add puppeteer\n```\n\nExample - print the user agent\n\n```js\nconst puppeteer = require('puppeteer');\n\n(async () => {\n  const browser = await puppeteer.launch();\n  console.log(await browser.version());\n  browser.close();\n})();\n```\n\nExample - taking a screenshot of the page\n\n```js\nconst puppeteer = require('puppeteer');\n\n(async () => {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto('https://www.chromestatus.com', {waitUntil: 'networkidle'});\n  await page.pdf({path: 'page.pdf', format: 'A4'});\n\n  browser.close();\n})();\n```\n\nCheck out\n[Puppeteer's documentation](https://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md)\nto learn more about the full API.\n\n## Firefox\n\nHeadless Firefox works on Fx55+ on Linux, and 56+ on Windows/Mac.\n\n从 Firefox 57 开始，Firefox 开始支持截图\n\n```\n/path/to/firefox -headless -screenshot https://developer.mozilla.com\n```\n\n- `-screenshot` name url — Set a custom name for the screenshot by including it\n  between the -screenshot flag and the URL you want to capture. Note that you\n  can specify other web-compatible image formats such as .jpg, .bmp, etc.\n- `--window-size=x` — Set a custom viewport width when taking the screenshot\n  (full height is maintained). Note that the single argument version of this\n  doesn't work.\n- `--window-size=x,y` — Set a custom viewport width and height to capture.\n\nFirefox headless 模式可以用于自动化测试，基于`Selenium`。\n\nMDN 的[`headless-example`](https://github.com/mdn/headless-examples)\n",
    "date": "2017-11-30",
    "id": 10,
    "slug": "headless-browser",
    "title": "无界面浏览器 - Firefox, Chrome"
  },
  {
    "author": "Gao",
    "content": "## 概念\n\n基于组件的软件工程（Component-based software engineering，简称 CBSE）或基于组件\n的开发（Component-Based Development，简称 CBD）是一种软件开发范型。\n\n它是现今软件复用理论实用化的研究热点，在组件对象模型的支持下，通过复用已有的构件\n，软件开发者可以“即插即用”地快速构造应用软件。\n\n这样不仅可以节省时间和经费，提高工作效率，而且可以产生更加规范、更加可靠的应用软\n件。\n\n## 什么是组件？\n\n摘自 Wikipedia：\n\n    一个单独的软件组件是一个软件包，一个Web服务，一个Web资源，或封装了一组相关功能（或数据）的模块。\n\n    组件通过接口相互通信。当一个组件向系统的其他部分提供服务时，它会采用一个提供的接口来指定其他组件可以使用的服务，以及如何这样做。这个接口可以被看作是组件的签名 - 客户端不需要知道组件的内部工作（实现），以便使用它。这个原理导致组件被称为封装。\n\n## Web 设计的 3 层结构\n\n- 结构层 Structural layer => HTML\n\n- 表现层 Design layer => CSS\n\n- 行为层 Behavioral layer => JavaScript\n\n一个独立的组件需要包含这 3 层结构，并且提供 API 接口，和其他组件之间通信。\n\n设计一个组件需要有可编程接口，可以通过行为层控制，而这些都需要通过 js 来控制\n\n涉及技术：\n\n- html in js\n- css in js\n\n## React 组件\n\nReact 是一个用于创建用户 UI 的 JavaScript 库\n\nReact 组件可以被认为是一个基本的视图元素，用户界面中的一个片段。\n\n在一个应用中，组件具有巢状结构，整个应用由一些容器组件构成，而容器组件由多级组件\n嵌套构成。\n\n## 设计分类：\n\n- Component UI 组件\n\n- Container 组件容器，包含 UI 组件，并且给 UI 组件绑定相应的数据\n\n### UI 组件\n\nUI 组件需要包含了完整页面部分和展示结构，以及对应行为接口.\n\n一个 UI 组件是完整的，独立的，可测试的。\n\n可以参考的 React UI 组件库：\n\n- [Semantic UI](https://react.semantic-ui.com/introduction)\n\n- [Material UI](https://material-ui-next.com/getting-started/installation/)\n\n目前需要提取当前 UI 组件，实现组件独立可重用。当前有待实现的是 Dialog 模块的\nReact 组件化\n\n### Container 容器组件\n\n容器组件是由 UI 组件和业务数据，处理逻辑组成容器把业务数据和 UI 组件绑定，构成一\n个对应的功能模块\n\n### container 的绑定\n\n在 React 中，组件拥有生命周期，数据和 UI 的绑定会和生命周期方法相关通过生命周期\n方法来关联数据\n\n### 高阶组件 Hight-Order Components\n\n高阶组件是 React 的一项高级技术，来实现组件的重用。高阶组件是由 React 设计而衍生\n出的一种构成模式。\n\n高阶组件实质上是一个函数，接受一个组件传入，并返回一个新的组件。高阶组件常见于\nReact 相关的第三方库，比如 Redux 的 connect 函数\n\n目前有待实现的高阶组件：\n\n- loadModule：分离一个模块到单独的文件，实现模块依赖加载，当时用到的时候才会去加\n  载对应的功能模块。\n\n- withReducer：分割 Reducer 处理逻辑，分模块加载 reducer 控制逻辑\n\n- withEffects：分割模块 action 异步控制逻辑，管理 action 调度功能目前可以参考的\n  是 saga 和 reactivex 技术\n\n## React context 技术\n\nReact context 技术可以在应用上发布一个共享数据集合，应用下的任何一个组件都可以通\n过声明订阅的方式来获取这个数据。\n\n目前我们已经使用了这个技术的地方是 redux 的 Provider，发布了 store 给所有组件\n\n### 其他类似功能实现：\n\n- LanguagePrivider 由 react-intl 提供，实现语言动态切换\n- JssProvider 由 CSS in JS 技术提供，结合 withStyles 高阶组件来实现动态样式更新\n- RouterProvider 由 React-Router 提供，实现 router 导航功能\n",
    "date": "2017-11-16",
    "id": 9,
    "slug": "component-based",
    "title": "组件化开发设计"
  },
  {
    "author": "Gao",
    "content": "## npm 的问题\n\nnpm 安装包的版本控制可伸缩性的特性带来的依赖不确定性导致经常出现问题\n\n## 解决方案\n\n### 使用 git 管理的问题\n\n每次变更支持库都要涉及数千个文件的修改需要 git 追踪大量依赖文件\n\nFacebook 面对同样的问题： https://code.facebook.com/posts/1840075619545360\n\n## Yarn\n\nYarn 包管理器是由 Facebook，Exponent，Google 以及 Tilde 合作提供的开源包管理器\n\nYarn 是具有革命性的包管理工具，继承自 npm，包含了 npm 的所有功能\n\n- 极速 Yarn 缓存它下载的每个包，所以无需重复下载。它还并行化操作以最大化资源利用\n  ，所以安装时间比以往快。\n\n- 超级安全。 Yarn 在每个安装包的代码执行前使用校验码验证包的完整性。\n\n- 超级可靠。 Yarn 使用一个格式详尽但简洁的 lockfile 和一个精确的算法来安装，能够\n  保证在一个系统上的运行的安装过程也会以同样的方式运行在其他系统上。\n\n### 实现原理：\n\n使用 yarn.lock 来控制包版本，确定一致 yarn.lock 记录文件签名，以及 URL，确定访问\n\n### npm 指令对应\n\nyarn add [package] == npm install —save [package]\n\nyarn remove [package] == npm uninstall —save [package]\n\nyarn global add [package] == npm install -g [package]\n\nyarn global remove [package] == npm uninstall -g [package]\n",
    "date": "2017-11-16",
    "id": 8,
    "slug": "yarn-pkg",
    "title": "Yarn包管理 - 取代npm"
  },
  {
    "author": "Gao",
    "content": "### 问题出现\n\n开发反馈错误时间过长\n\n发现所有错误请求都被发送了两次，情况是\n\n- 浏览器中发现只有一次请求\n\n- 服务器上发现有两条请求日志\n\n### 排查过程\n\n首先为乐确认问题是在 nginx 转发时发生的，还是由浏览器发送的\n\n只能使用抓包的方式进行排查，重新修改了服务器，关闭了 https\n\n使用 wireshark 进行抓包\n\n```wireshark\nip == 10.1.108.31 && ip.port = 80 && http\n```\n\n检查发现是由浏览器发送了两次请求\n\n分别使用了不同浏览器测试：\n\n- Firefox 两次\n- Chrome 两次\n- Safari 正常\n- IE 正常\n\n检查了请求和响应\n\n查看 chrome 网络 waterfall\n\n![](error-421/time.png)\n\n查看发现，时间显示 stalled 时有一次请求\n\n之后 walting 时间段是重试的请求\n\n测试了是否是 keepalive 的原因，`nginx.conf`设置：\n\n```nginx\nkeepalive_timeoute 0;\n```\n\n排除原因\n\n使用了[`echo`](https://github.com/gsmlg/echo)服务进行测试\n\n通过测试发现，当服务器响应 421 时，浏览器会复制请求并再次请求服务器\n\n### 原因\n\n查看了 `http status code 421` 说明\n\n      421 Misdirected Request （RFC 7540）\n        该请求针对的是无法产生响应的服务器（例如因为连接重用）。\n\nRFC 7540 Hypertext Transfer Protocol Version 2 (HTTP/2)\n[链接](https://tools.ietf.org/html/rfc7540)\n\n指定说明[Section](https://tools.ietf.org/html/rfc7540#section-9.1.2)\n\n      9.1.2.  The 421 (Misdirected Request) Status Code\n\n      The 421 (Misdirected Request) status code indicates that the request\n      was directed at a server that is not able to produce a response.\n      This can be sent by a server that is not configured to produce\n      responses for the combination of scheme and authority that are\n      included in the request URI.\n\n      Clients receiving a 421 (Misdirected Request) response from a server\n      MAY retry the request -- whether the request method is idempotent or\n      not -- over a different connection.  This is possible if a connection\n      is reused (Section 9.1.1) or if an alternative service is selected\n      [ALT-SVC].\n\n      This status code MUST NOT be generated by proxies.\n\n      A 421 response is cacheable by default, i.e., unless otherwise\n      indicated by the method definition or explicit cache controls (see\n      Section 4.2.2 of [RFC7234]).\n\n#### 确定原因\n\nhttp2 中定义了 421 错误\n\n##### 421 错误用于在 http2 中，在 http2 复用连接时，发现连接到的服务器不正确，则会由服务器返回响应码 421，客户端收到后会重新建立连接并且发送相同的请求\n\n### 解决方式\n\n使用通用的错误响应码`403`即可解决问题\n",
    "date": "2017-07-07",
    "id": 7,
    "slug": "error-421",
    "title": "由HTTP STATUS CODE 421导致的错误"
  },
  {
    "author": "Gao",
    "content": "## HTML5 访问视频和音频输入设备\r\n\r\n### API: `Navigator.MediaDevices.getUserMedia()`\r\n\r\n#### 语法：\r\n\r\n```\r\nvar promise = navigator.mediaDevices.getUserMedia(constraints);\r\n```\r\n\r\n#### 参数： _constraints_\r\n\r\n可以配置为如下：\r\n\r\n```\r\nnavigator.mediaDevices.getUsermedia({video: true, audio: true});\r\n\r\nnavigator.mediaDevices.getUsermedia({video: {width: 800, height: 480}, audio: true});\r\n\r\nnavigator.mediaDevices.getUsermedia({audio: true,video:  {\r\n    width: { min: 1024, ideal: 1280, max: 1920 },\r\n    height: { min: 776, ideal: 720, max: 1080 }\r\n  }});\r\n\r\n// 移动设备\r\n// 前置摄像头\r\nnavigator.mediaDevices.getUsermedia({ audio: true, video: { facingMode: \"user\" } })\r\n\r\n// 确认主摄像头\r\nnavigator.mediaDevices.getUsermedia({ audio: true, video: { facingMode: { exact: \"environment\" } } })\r\n\r\n// 限制帧数\r\nnavigator.mediaDevices.getUsermedia({ video: { frameRate: { ideal: 10, max: 15 } } })\r\n\r\n```\r\n\r\n#### 返回值\r\n\r\n`Promise` 对象\r\n\r\n- 成功返回为\r\n  [`MediaStream`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream)\r\n\r\n- 失败异常\r\n  - AbortError\r\n  - NotAllowedError\r\n  - NotFoundError\r\n  - NotReadableError\r\n  - OverConstrainedError\r\n  - SecurityError\r\n  - TypeError\r\n\r\n### 早期接口为 `navigator.getUserMedia()`\r\n\r\n旧浏览器使用示例：\r\n\r\n```javascript\r\n// Older browsers might not implement mediaDevices at all, so we set an empty object first\r\nif (navigator.mediaDevices === undefined) {\r\n  navigator.mediaDevices = {};\r\n}\r\n\r\n// Some browsers partially implement mediaDevices. We can't just assign an object\r\n// with getUserMedia as it would overwrite existing properties.\r\n// Here, we will just add the getUserMedia property if it's missing.\r\nif (navigator.mediaDevices.getUserMedia === undefined) {\r\n  navigator.mediaDevices.getUserMedia = function (constraints) {\r\n    // First get ahold of the legacy getUserMedia, if present\r\n    var getUserMedia =\r\n      navigator.webkitGetUserMedia || navigator.mozGetUserMedia;\r\n\r\n    // Some browsers just don't implement it - return a rejected promise with an error\r\n    // to keep a consistent interface\r\n    if (!getUserMedia) {\r\n      return Promise.reject(\r\n        new Error('getUserMedia is not implemented in this browser'),\r\n      );\r\n    }\r\n\r\n    // Otherwise, wrap the call to the old navigator.getUserMedia with a Promise\r\n    return new Promise(function (resolve, reject) {\r\n      getUserMedia.call(navigator, constraints, resolve, reject);\r\n    });\r\n  };\r\n}\r\n\r\nnavigator.mediaDevices\r\n  .getUserMedia({audio: true, video: true})\r\n  .then(function (stream) {\r\n    var video = document.querySelector('video');\r\n    // Older browsers may not have srcObject\r\n    if ('srcObject' in video) {\r\n      video.srcObject = stream;\r\n    } else {\r\n      // Avoid using this in new browsers, as it is going away.\r\n      video.src = window.URL.createObjectURL(stream);\r\n    }\r\n    video.onloadedmetadata = function (e) {\r\n      video.play();\r\n    };\r\n  })\r\n  .catch(function (err) {\r\n    console.log(err.name + ': ' + err.message);\r\n  });\r\n```\r\n\r\n### 兼容情况\r\n\r\n![](get-user-media/can-i-use.png)\r\n",
    "date": "2017-06-27",
    "id": 6,
    "slug": "get-user-media",
    "title": "HTML5 访问视频和音频输入设备"
  },
  {
    "author": "Gao",
    "content": "## Tern: JavaScript 智能分析工具\n\nTern 是一个独立的 JavaScript 代码分析引擎\n\nTern 被设计成为编辑器插件，用来强化编辑器的智能编辑。\n\n提供了如下特性：\n\n- 自动完成变量名称／属性\n- 函数参数提示\n- 查询表达式属性\n- 查到目标定义的地点\n- 自动重构\n\n### 编辑器插件\n\n- Emacs\n- Vim\n- Sublime Text\n- Brackets (built in to the base editor)\n- Light Table\n- Eclipse (and general Java API)\n- TextMate\n- SourceLair (built in to the base editor)\n- Chocolat (built in to the base editor)\n\n### 支持文档与配置\n\n[在线文档](http://ternjs.net/doc/manual.html)\n\n配置文件，需要在项目下添加`.tern-project`文件格式为 JSON 格式，示例如下：\n\n```json\n{\n  \"libs\": [\"browser\", \"jquery\"],\n  \"loadEagerly\": [\"importantfile.js\"],\n  \"plugins\": {\n    \"doc_comment\": {},\n    \"node\": {},\n    \"webpack\": {\n      \"configPath\": \"./tasks/webpack.conf.js\"\n    }\n  }\n}\n```\n\n#### libs\n\n整个项目中包含的库，\n由[JSON type descriptions](http://ternjs.net/doc/manual.html#typedef)格式指定\n\n使用 JSON 格式定义的库文档，全局有效\n\n已有预定义库：\n\n- browser\n- chai\n- ecmascript\n- jquery\n- react\n- underscore\n\n#### loadEagerly\n\n配置总是会加载的文件\n\n#### Plugins - 支持的插件：\n\n- commonjs\n- angular\n- complete_strings\n- doc_comment\n- es_modules\n- modules\n- node_resolve\n- requirejs\n- node\n- webpack\n\n其它配置项可以参考在线文档\n\n### 安装\n\n```shell\n\nnpm install -g tern\n// or\nyarn global add tern\n\n```\n\n### 使用\n\n编辑器会自动从`PATH`下启动`tern`\n\n#### Emacs 使用\n\n```lisp\n(maybe-require-package 'tern)\n(maybe-require-package 'company-tern)\n```\n\n使用搜索`tern`开头的函数\n\n默认快捷键\n\n- `M-.` 跳到定义点\n- `m-,` 跳回\n- `C-c c` 读取类型\n- `C-c d` 读取文档\n\n#### 其它编辑器\n\n配置类似 Emacs\n\n快捷键检查通过命令搜索，预定义快捷键\n\n#### DEBUG\n\n启动`tern`，项目目录下：\n\n```shell\n\ntern --persistent --debug --verbose\n\n```\n\n可以向`tern`监听的端口发送`POST`请求就可以获取对应数据信息\n\n示例：\n\n```shell\n\nMac-Pro% curl -i localhost:64672 -X POST -d '\n{\"query\": {\n    \"end\": 4,\n    \"file\": \"assets/javascripts/zddi/address/audit_ip/models/audit_ips.js\",\n    \"type\": \"definition\",\n    \"variable\": null\n  }}'\nHTTP/1.1 200 OK\ncontent-type: application/json; charset=utf-8\nDate: Sun, 25 Jun 2017 11:10:56 GMT\nConnection: keep-alive\nTransfer-Encoding: chunked\n\n{\"origin\":\"assets/javascripts/zddi/common/models/collection.js\",\"start\":361,\"end\":1130,\"file\":\"assets/javascripts/zddi/common/models/collection.js\",\"contextOffset\":50,\"context\":\"able: false,\\n\\n    model: Model,\\n\\n    constructor: \"}%\n\n```\n",
    "date": "2017-06-25",
    "id": 5,
    "slug": "tern-js",
    "title": "Tern, JavaScript智能代码分析工具"
  },
  {
    "author": "Gao",
    "content": "### Redux 简述\n\nRedux 提供给应用一个可预测的状态管理机制，可以运行于不同的环境\n\nRedux 设计 API 简单，清晰，测试方便，易于上手\n\n### Redux 核心 API 介绍\n\n- store\n\n  全局唯一的状态存贮库，内部维护一个不可变对象树\n\n  store 需要包含 3 个方法：\n\n  - `dispatch` 用来接受 action\n  - `getState` 返回 store 内的状态\n  - `subscribe` 接受一个回调，在状态更新后会触发回调\n\n- action\n\n  需要修改 store 状态时，发送给 store\n\n  action 必须包含一个`type`属性，用于 reducer 匹配\n\n- reducer\n\n  store 接受到 Action 后，根据 action 来指定更新数据的方法\n\n  接受参数 `state`, `action` 返回更新后的 state\n\n### 简单实现\n\n```javascript\nconst ADD = 'ADD';\n\nconst reducer = (state, action) => {\n  switch (action.type) {\n    case ADD:\n      return {value: state.value + action.value};\n    default:\n      return state;\n  }\n};\n\nconst createStore = (reducer) => {\n  let listeners = [];\n  let state = {value: 0};\n\n  let dispatch = (action) => {\n    state = reducer(state, action);\n    listeners.forEach((cb) => cb());\n  };\n\n  return {\n    getState: (_) => state,\n    subscribe: (cb) => listeners.push(cb),\n    dispatch: dispatch,\n  };\n};\n\nconst store = createStore(reducer);\n\nstore.subscribe(() => console.log(store.getState()));\n\nstore.dispatch({type: ADD, value: 5});\n\nstore.dispatch({type: ADD, value: 10});\n```\n\n### 三大原则\n\n- 单一数据源\n\n- State 是只读的\n\n- 使用纯函数执行修改\n\n### 相关技术\n\n- 函数式编程\n\n- Flux\n\n- Immutable\n",
    "date": "2017-06-21",
    "id": 4,
    "slug": "redux-tutorial",
    "title": "Redux Tutorial"
  },
  {
    "author": "Gao",
    "content": "## React Native 环境安装 iOS\n\n### 基础开发环境环境安装：\n\n```shell\nbrew install node\nbrew install watchman\n\nyarn global add react-native-cli\n# or\nnpm install -g react-native-cli\n\n```\n\n### iOS 开发环境环境安装：\n\n需要安装 XCode 版本大于 8\n\n#### 创建项目\n\n使用 `react-native` 命令行工具创建项目\n\n```shell\n\nreact-native init vultr-ping\n\n```\n\n#### 创建 iOS 和 Android 项目\n\n```shell\n\nreact-native eject\n\n```\n\n#### 启动 iOS 开发\n\n```shell\n\nreact-native run-ios\n\n```\n\n#### 创建项目图标\n\n[详细介绍](https://github.com/bamlab/generator-rn-toolbox/blob/master/generators/assets/README.md)\n\n```shell\nbrew install imagemagick\nyarn global add yo generator-rn-toolbox\n\nyo rn-toolbox:assets --icon icon.png\n\n```\n\n#### iOS 开发注意\n\n- iOS 开发只能使用 https 链接获取数据\n\n- iOS 开发网络链接库可以使用 `XMLHttpRequest` 或者 `fetch` API\n\n- 可以使用 _Redux_ 库来管理状态，支持原生 JavaScript 库\n\n- \\*可以和 iOS 原生代码混合开发\n\n### Android 开发环境安装：\n\n需要安装 _Java SE_ 版本 8.0 以上\n\n需要安装 _Android SDK_\n\n需要安装 _Android Stuido_\n\n```shell\n\nbrew cask install java\nbrea cask install android-sdk\nbrea cask install android-studio\n\n```\n\nReact Native 需要配置环境变量\n\n```shell\n\nexport ANDROID_HOME=$HOME/Library/Android/sdk\nexport PATH=$PATH:$ANDROID_HOME/tools\nexport PATH=$PATH:$ANDROID_HOME/platform-tools\n\n```\n\nAndroid Studio 需要配置 Android SDK\n\n![](react-native/AndroidSDKManagerMacOS.png)\n\n![](react-native/AndroidSDKManagerSDKToolsMacOS.png)\n",
    "date": "2017-06-18",
    "id": 3,
    "slug": "react-native",
    "title": "React Native 开发初探"
  },
  {
    "author": "Gao",
    "content": "- 压缩对比，查看 css 优化功能，并进行对比\n\n## 对比 css 代码\n\n```css\n.btnShrink {\n  background: url(~iframe/icons_rigth.png) 0 0 no-repeat;\n  width: 8px;\n  height: 80px;\n  position: absolute;\n  left: 0;\n  top: 50%;\n  margin: -40px 0 0 0;\n  overflow: hidden;\n  display: block;\n  cursor: pointer;\n}\n\n.btnShrink.shrinkExt {\n  left: -16px;\n  margin-top: -25px;\n  background: url(~iframe/icons_rigth.png) -7px 0 no-repeat;\n  width: 23px;\n}\n```\n\n- css-clean 与 cssnano 优化结果基本一致只在压缩级别上控制会优化 background 的\n  position 属性\n\n```css\n.btnShrink {\n  background: url(~iframe/icons_rigth.png) 0 0 no-repeat;\n  width: 8px;\n  height: 80px;\n  position: absolute;\n  left: 0;\n  top: 50%;\n  margin: -40px 0 0 0;\n  overflow: hidden;\n  display: block;\n  cursor: pointer;\n}\n\n.btnShrink.shrinkExt {\n  left: -16px;\n  margin-top: -25px;\n  background: url(~iframe/icons_rigth.png) -7px 0 no-repeat;\n  width: 23px;\n}\n```\n\n## 对比 css 代码\n\n如下：\n\n```css\n.btnShrink {\n  background-image: url(~iframe/icons_rigth.png);\n  background-position: 0 0;\n  background-repeat: no-repeat;\n  width: 8px;\n  height: 80px;\n  position: absolute;\n  left: 0;\n  top: 50%;\n  margin: -40px 0 0 0;\n  overflow: hidden;\n  display: block;\n  cursor: pointer;\n}\n\n.btnShrink.shrinkExt {\n  left: -16px;\n  margin-top: -25px;\n  background-image: url(~iframe/icons_rigth.png);\n  background-position: -7px 0;\n  background-repeat: no-repeat;\n  width: 23px;\n}\n```\n\n使用 clean-css 压缩优化后结果：\n\n```css\n.btnShrink {\n  background-image: url(~iframe/icons_rigth.png);\n  background-position: 0 0;\n  background-repeat: no-repeat;\n  width: 8px;\n  height: 80px;\n  position: absolute;\n  left: 0;\n  top: 50%;\n  margin: -40px 0 0;\n  overflow: hidden;\n  display: block;\n  cursor: pointer;\n}\n.btnShrink.shrinkExt {\n  left: -16px;\n  margin-top: -25px;\n  background-image: url(~iframe/icons_rigth.png);\n  background-position: -7px 0;\n  background-repeat: no-repeat;\n  width: 23px;\n}\n```\n\n使用 cssnano 压缩后对比结果：\n\n```css\n.btnShrink {\n  background-position: 0 0;\n  width: 8px;\n  height: 80px;\n  position: absolute;\n  left: 0;\n  top: 50%;\n  margin: -40px 0 0;\n  overflow: hidden;\n  display: block;\n  cursor: pointer;\n}\n.btnShrink,\n.btnShrink.shrinkExt {\n  background-image: url(~iframe/icons_rigth.png);\n  background-repeat: no-repeat;\n}\n.btnShrink.shrinkExt {\n  left: -16px;\n  margin-top: -25px;\n  background-position: -7px 0;\n  width: 23px;\n}\n```\n\n结论：明显属性分离后可以更好的优化重复属性，尤其是在使用了 inline-image 后优化效\n果更加明显\n",
    "date": "2017-05-19",
    "id": 2,
    "slug": "css-optimize",
    "title": "CSS 压缩优化对比"
  },
  {
    "author": "Gao",
    "content": "# qladdict\n\n[QLAddict](https://github.com/tattali/QLAddict/)\n\nA QuickLook plugin that lets you view subtitles .srt files like Addic7ed.com on\nmac\n\n快速预览字幕文件\n\n# qlcolorcode\n\n[QLColorCode](https://github.com/anthonygelibert/QLColorCode)\n\nQLColorCode Quick Look plugin for source code with syntax highlighting.\n\n带有代码高亮的代码预览\n\n# qldds\n\n[QuickLook DDS](https://github.com/Marginal/QLdds)\n\nThis package allows OSX Finder to display thumbnails, previews and metadata for\n\"DirectDraw Surface\" (DDS) texture files.\n\n快速预览 DDS 文件，DirectDraw Surface - 大约是微软的 DriectX 的东西\n\n# qlgradle\n\n[qlgradle](https://github.com/Urucas/QLGradle)\n\nQuicklook plugin for .gradle files\n\nGradle 是一个基于 Apache Ant 和 Apache Maven 概念的项目自动化构建工具。它使用一\n种基于 Groovy 的特定领域语言(DSL)来声明项目设置，抛弃了基于 XML 的各种繁琐配置。\n\n# qlimagesize\n\n[qlImageSize](https://github.com/Nyx0uf/qlImageSize)\n\nQuickLook plugin to display the dimensions and size of an image in the title bar\ninstead of the filename. Also preview some unsupported formats like WebP & bpg.\n\n在快速预览可以显示图片大小，并且提供预览不支持的图片如 webp 等\n\n# qlmarkdown\n\n[QLMarkdown](https://github.com/toland/qlmarkdown)\n\nQuickLook generator for Markdown files\n\nmarkdown 预览\n\n# qlmobi\n\n[QLMobi](https://github.com/bfabiszewski/QLMobi)\n\nQuick Look plugin for Kindle ebook formats\n\nkindle 电子书的快速预览\n\n# qlnetcdf\n\n[QLNetcdf](https://github.com/tobeycarman/QLNetcdf/)\n\nA QuickLook Plugin for previewing NetCDF files.\n\n[Network Common Data Form (NetCDF)](http://www.unidata.ucar.edu/software/netcdf/)\n\n- NetCDF is a set of software libraries and self-describing, machine-independent\n  data formats that support the creation, access, and sharing of array-oriented\n  scientific data.\n\n# qlplayground\n\n[qlplayground](https://github.com/norio-nomura/qlplayground)\n\n`qlplayground` is a QuickLook plugin for Swift files.\n\n快速预览 swift 文件(.swift, .playground)\n\n# qlprettypatch\n\n[QLPrettyPatch](https://github.com/atnan/QLPrettyPatch)\n\nQuickLook generator for patch files\n\npatch 文件快速预览\n\n# qlrest\n\n[QLRest](https://github.com/cluther/qlrest)\n\nQLRest is a simple QuickLook generator for reStructuredText files. It renders a\npreview of the selected ReST file using Python, Docutils and Pygments.\n\n# qlstephen\n\n[QLStephen](https://whomwah.github.io/qlstephen/)\n\nA QuickLook plugin that lets you view plain text files without a file extension\n\n快速预览纯文本文件，如：\n\n- README\n- INSTALL\n- CHANGELOG\n- Makefile\n- Rakefile\n- CapFile\n\n# qlswift\n\n[QLSwift](https://github.com/lexrus/QLSwift)\n\nA Quick Look plugin for Swift files. Inspired by QLMarkdown.\n\nswift 快速预览 sublime 的默认色调\n\n# qlvideo\n\n[QuickLook Video](https://github.com/Marginal/QLVideo)\n\nThis package allows macOS Finder to display thumbnails, static previews, cover\nart and metadata for most types of video files.\n\nQuickLook and Spotlight on macOS 10.9 and later understand a limited number of\nmedia files - mostly only MPEG audio and video codecs within MPEG container\nfiles. This package adds support for wide range of other codecs and \"non-native\"\nmedia file types, including .asf, .avi, .flv, .mkv, .rm, .webm, .wmf etc.\n\n支持更多格式的视频预览\n\n# emin-webpquicklook\n\n[WebPQuickLook](https://github.com/emin/WebPQuickLook)\n\nMac OS X QuickLook plugin for WebP image files\n\n# epubquicklook\n\n[EPUB QuickLook](https://github.com/jaketmp/ePub-quicklook)\n\nThe epub.qlgenerator plugin is designed to extract the cover images from EPUB\nfiles to use as the file icon, and present a nice overview of the EPUB in\nQuickLook.\n\nThe epub.mdimporter plugin is designed to extract information from EPUB files\n(metadata as well as text content) and index it so that Spotlight can search it.\n\n快速预览 epub 和 spotlight（mdfind）搜索 epub 内容\n\n# quicklook-csv\n\n[QuickLookCSV](https://github.com/p2/quicklook-csv)\n\nQuick look CSV files for Mac OS X 10.5 and newer. Supports files separated by\ncomma (,), tabs (⇥), semicolons (;) pipes (|). The plugin will generate Icons\nand show a preview, along with some information (like num rows/columns). Many\nthanks to Ted Fischer for valuable input and testing of version 1.1!\n\n快速预览 CSV\n\n# quicklook-json\n\n[quick look JSON](http://www.sagtau.com/quicklookjson.html)\n\nquick look json is a useful quick look plugin to preview JSON files. It will\nrender files with a colorful view, and will allow to expand or compress nodes in\nthe JSON tree.\n\nJSON 文件快速预览\n\n# quicklook-pat\n\n[Adobe Photoshop Patterns Quicklook Plugin](https://github.com/pixelrowdies/quicklook-pat)\n\nQuicklook plugin to view Adobe Photoshop pattern files in Apple's Finder\napplication.\n\n# quicklook-pfm\n\n[quicklook-pfm](https://github.com/lnxbil/quicklook-pfm)\n\nApple QuickLook Plugin for PPM, PGM, PFM and PBM files\n\nThis piece of code enables Apple QuickLook to open\n\n- PPM (3-channel 8-bit) files\n- PFM (1/3 channel 32-bit ) files\n- PGM (1-channel 8-bit) files\n- PBM (1-channel 1-bit) files\n\n# quicklookapk\n\n[QuickLookAPK](https://github.com/hezi/QuickLookAPK)\n\nA Quick Look plugin for Android packages\n\nAndroid APK 文件预览\n\n# quicklookase\n\n[QuickLookASE](https://github.com/rsodre/QuickLookASE)\n\nMac QuickLook for ASE files (Adobe Swatch Exchange)\n\nASE are color palettes that can be exported from Adobe Photoshop, Adobe\nIllustrator, Adobe Color CC, Spectrum, COLOURlovers, Prisma, among many others.\n\nBased on Apple's QuickLookSketch.\n\n# receiptquicklook\n\n[ReceiptQuickLook](https://github.com/letiemble/ReceiptQuickLook)\n\nA QuickLook plugin to inspect App Store receipts.\n\nThis quick look plugin provides a way to visualize cryptographic receipt\ngenerated by the App Stores (iOS and OS X). This is quite useful for iOS\napplication as there is no way to visualize them on the device.\n\n# ttscoff-mmd-quicklook\n\n[MMD-QuickLook](https://github.com/ttscoff/mmd-quicklook)\n\nImproved QuickLook generator for MultiMarkdown files\n\nThis is a quick fork of Fletcher Penney's MMD Quicklook project. It adds some\nstyling to the default Quick Look preview (based on GitHub CSS) and allows for\ncustomization via a .mdqlstyle.css file in your home folder.\n",
    "date": "2017-05-17",
    "id": 1,
    "slug": "quicklook",
    "title": "macOS QuickLook 插件介绍"
  }
]